{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimPy Tutorial\n",
    "https://towardsdatascience.com/introduction-to-simulation-with-simpy-322606d4ba0c\n",
    "\n",
    "https://simpy.readthedocs.io/en/latest/simpy_intro/basic_concepts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car(env):\n",
    "     while True:\n",
    "         print('Start parking at %d' % env.now)\n",
    "         parking_duration = 5\n",
    "         yield env.timeout(parking_duration)\n",
    "         print('Start driving at %d' % env.now)\n",
    "         trip_duration = 2\n",
    "         yield env.timeout(trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parking at 0\n",
      "Start driving at 5\n",
      "Start parking at 7\n",
      "Start driving at 12\n",
      "Start parking at 14\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "env.process(car(env))\n",
    "\n",
    "env.run(until=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(object):\n",
    "     def __init__(self, env):\n",
    "         self.env = env\n",
    "         # Start the run process everytime an instance is created.\n",
    "         self.action = env.process(self.run())\n",
    "\n",
    "     def run(self):\n",
    "         while True:\n",
    "             print('Start parking and charging at %d' % self.env.now)\n",
    "             charge_duration = 5\n",
    "             # We yield the process that process() returns\n",
    "             # to wait for it to finish\n",
    "             yield self.env.process(self.charge(charge_duration))\n",
    "\n",
    "             # The charge process has finished and\n",
    "             # we can start driving again.\n",
    "             print('Start driving at %d' % self.env.now)\n",
    "             trip_duration = 2\n",
    "             yield self.env.timeout(trip_duration)\n",
    "\n",
    "     def charge(self, duration):\n",
    "         yield self.env.timeout(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parking and charging at 0\n",
      "Start driving at 5\n",
      "Start parking and charging at 7\n",
      "Start driving at 12\n",
      "Start parking and charging at 14\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "car = Car(env)\n",
    "#env.process(car(env))\n",
    "\n",
    "env.run(until=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimPy: interrupting processes via interruption handling (interrupted object/class/process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(env, car):\n",
    "     yield env.timeout(3)\n",
    "     car.action.interrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(object):\n",
    "     def __init__(self, env):\n",
    "         self.env = env\n",
    "         # Start the run process everytime an instance is created.\n",
    "         self.action = env.process(self.run())\n",
    "\n",
    "     def run(self):\n",
    "         while True:\n",
    "             print('Start parking and charging at %d' % self.env.now)\n",
    "             charge_duration = 5\n",
    "            # We may get interrupted while charging the battery\n",
    "             try:\n",
    "                 yield self.env.process(self.charge(charge_duration))\n",
    "             except simpy.Interrupt:\n",
    "                 # When we received an interrupt, we stop charging and\n",
    "                 # switch to the \"driving\" state\n",
    "                 print(f'Was interrupted at {env.now}. Hope, the battery is full enough ...')\n",
    "\n",
    "             # The charge process has finished and\n",
    "             # we can start driving again.\n",
    "             print('Start driving at %d' % self.env.now)\n",
    "             trip_duration = 2\n",
    "             yield self.env.timeout(trip_duration)\n",
    "\n",
    "     def charge(self, duration):\n",
    "         yield self.env.timeout(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parking and charging at 0\n",
      "Was interrupted at 3. Hope, the battery is full enough ...\n",
      "Start driving at 3\n",
      "Start parking and charging at 5\n",
      "Start driving at 10\n",
      "Start parking and charging at 12\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "car = Car(env)\n",
    "env.process(driver(env, car))\n",
    "\n",
    "env.run(until=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "- basic resources: FIFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car(env, name, bcs, driving_time, charge_duration):\n",
    "     \"\"\"BCS: battery charging station\"\"\"\n",
    "     # Simulate driving to the BCS\n",
    "     yield env.timeout(driving_time)\n",
    "\n",
    "     # Request one of its charging spots\n",
    "     print('%s arriving at %d' % (name, env.now))\n",
    "     # with statement automatically releases resources\n",
    "     # otherwise release() needs to be called separately\n",
    "     with bcs.request() as req:\n",
    "         yield req\n",
    "\n",
    "         # Charge the battery\n",
    "         print('%s starting to charge at %s' % (name, env.now))\n",
    "         yield env.timeout(charge_duration)\n",
    "         print('%s leaving the bcs at %s' % (name, env.now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "bcs = simpy.Resource(env, capacity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "     env.process(car(env, 'Car %d' % i, bcs, i*2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car 0 arriving at 0\n",
      "Car 0 starting to charge at 0\n",
      "Car 1 arriving at 2\n",
      "Car 1 starting to charge at 2\n",
      "Car 2 arriving at 4\n",
      "Car 0 leaving the bcs at 5\n",
      "Car 2 starting to charge at 5\n",
      "Car 3 arriving at 6\n",
      "Car 1 leaving the bcs at 7\n",
      "Car 3 starting to charge at 7\n",
      "Car 2 leaving the bcs at 10\n",
      "Car 3 leaving the bcs at 12\n"
     ]
    }
   ],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import simpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Machine shop example\n",
    "\n",
    "Covers:\n",
    "\n",
    "- Interrupts\n",
    "- Resources: PreemptiveResource\n",
    "\n",
    "Scenario:\n",
    "  A workshop has *n* identical machines. A stream of jobs (enough to\n",
    "  keep the machines busy) arrives. Each machine breaks down\n",
    "  periodically. Repairs are carried out by one repairman. The repairman\n",
    "  has other, less important tasks to perform, too. Broken machines\n",
    "  preempt theses tasks. The repairman continues them when he is done\n",
    "  with the machine repair. The workshop works continuously.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "PT_MEAN = 10.0         # Avg. processing time in minutes\n",
    "PT_SIGMA = 2.0         # Sigma of processing time\n",
    "MTTF = 300.0           # Mean time to failure in minutes\n",
    "BREAK_MEAN = 1 / MTTF  # Param. for expovariate distribution\n",
    "REPAIR_TIME = 30.0     # Time it takes to repair a machine in minutes\n",
    "JOB_DURATION = 30.0    # Duration of other jobs in minutes\n",
    "NUM_MACHINES = 10      # Number of machines in the machine shop\n",
    "WEEKS = 4              # Simulation time in weeks\n",
    "SIM_TIME = WEEKS * 7 * 24 * 60  # Simulation time in minutes\n",
    "\n",
    "\n",
    "def time_per_part():\n",
    "    \"\"\"Return actual processing time for a concrete part.\"\"\"\n",
    "    return random.normalvariate(PT_MEAN, PT_SIGMA)\n",
    "\n",
    "\n",
    "def time_to_failure():\n",
    "    \"\"\"Return time until next failure for a machine.\"\"\"\n",
    "    return random.expovariate(BREAK_MEAN)\n",
    "\n",
    "\n",
    "class Machine(object):\n",
    "    \"\"\"A machine produces parts and my get broken every now and then.\n",
    "\n",
    "    If it breaks, it requests a *repairman* and continues the production\n",
    "    after the it is repaired.\n",
    "\n",
    "    A machine has a *name* and a numberof *parts_made* thus far.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, env, name, repairman):\n",
    "        self.env = env\n",
    "        self.name = name\n",
    "        self.parts_made = 0\n",
    "        self.broken = False\n",
    "\n",
    "        # Start \"working\" and \"break_machine\" processes for this machine.\n",
    "        self.process = env.process(self.working(repairman))\n",
    "        env.process(self.break_machine())\n",
    "\n",
    "    def working(self, repairman):\n",
    "        \"\"\"Produce parts as long as the simulation runs.\n",
    "\n",
    "        While making a part, the machine may break multiple times.\n",
    "        Request a repairman when this happens.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Start making a new part\n",
    "            done_in = time_per_part()\n",
    "            while done_in:\n",
    "                try:\n",
    "                    # Working on the part\n",
    "                    start = self.env.now\n",
    "                    yield self.env.timeout(done_in)\n",
    "                    done_in = 0  # Set to 0 to exit while loop.\n",
    "\n",
    "                except simpy.Interrupt:\n",
    "                    self.broken = True\n",
    "                    done_in -= self.env.now - start  # How much time left?\n",
    "\n",
    "                    # Request a repairman. This will preempt its \"other_job\".\n",
    "                    with repairman.request(priority=1) as req:\n",
    "                        yield req\n",
    "                        yield self.env.timeout(REPAIR_TIME)\n",
    "\n",
    "                    self.broken = False\n",
    "\n",
    "            # Part is done.\n",
    "            self.parts_made += 1\n",
    "\n",
    "    def break_machine(self):\n",
    "        \"\"\"Break the machine every now and then.\"\"\"\n",
    "        while True:\n",
    "            yield self.env.timeout(time_to_failure())\n",
    "            if not self.broken:\n",
    "                # Only break the machine if it is currently working.\n",
    "                self.process.interrupt()\n",
    "\n",
    "\n",
    "def other_jobs(env, repairman):\n",
    "    \"\"\"The repairman's other (unimportant) job.\"\"\"\n",
    "    while True:\n",
    "        # Start a new job\n",
    "        done_in = JOB_DURATION\n",
    "        while done_in:\n",
    "            # Retry the job until it is done.\n",
    "            # It's priority is lower than that of machine repairs.\n",
    "            with repairman.request(priority=2) as req:\n",
    "                yield req\n",
    "                try:\n",
    "                    start = env.now\n",
    "                    yield env.timeout(done_in)\n",
    "                    done_in = 0\n",
    "                except simpy.Interrupt:\n",
    "                    done_in -= env.now - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine shop\n",
      "Machine shop results after 4 weeks\n",
      "Machine 0 made 3251 parts.\n",
      "Machine 1 made 3273 parts.\n",
      "Machine 2 made 3242 parts.\n",
      "Machine 3 made 3343 parts.\n",
      "Machine 4 made 3387 parts.\n",
      "Machine 5 made 3244 parts.\n",
      "Machine 6 made 3269 parts.\n",
      "Machine 7 made 3185 parts.\n",
      "Machine 8 made 3302 parts.\n",
      "Machine 9 made 3279 parts.\n"
     ]
    }
   ],
   "source": [
    "# Setup and start the simulation\n",
    "print('Machine shop')\n",
    "random.seed(RANDOM_SEED)  # This helps reproducing the results\n",
    "\n",
    "# Create an environment and start the setup process\n",
    "env = simpy.Environment()\n",
    "repairman = simpy.PreemptiveResource(env, capacity=1)\n",
    "machines = [Machine(env, 'Machine %d' % i, repairman)\n",
    "            for i in range(NUM_MACHINES)]\n",
    "env.process(other_jobs(env, repairman))\n",
    "\n",
    "# Execute!\n",
    "env.run(until=SIM_TIME)\n",
    "\n",
    "# Analyis/results\n",
    "print('Machine shop results after %s weeks' % WEEKS)\n",
    "for machine in machines:\n",
    "    print('%s made %d parts.' % (machine.name, machine.parts_made))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3192211945238288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normalvariate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSSP instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import simpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rnd_JSSP_inst(\n",
    "    n_jobs: int,\n",
    "    n_machines: int,\n",
    "    seed: int = 42,\n",
    ") -> tuple[int, int, int, npt.NDArray[np.uint16], npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "    \"\"\"\n",
    "    Generates random job shop instance with given number of jobs and machines'\n",
    "    - each job on all machines\n",
    "    - max processing time = 9\n",
    "    \n",
    "    Output:\n",
    "        - n_jobs: number of jobs\n",
    "        - n_machines: number of machines\n",
    "        - n_tasks: number of tasks\n",
    "        - mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        - mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        - mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "    \"\"\"\n",
    "    # generate random process time matrix shape=(n_jobs, n_machines)\n",
    "    np_rnd_gen = np.random.default_rng(seed=seed)\n",
    "    mat_ProcTimes = np_rnd_gen.integers(1, 10, size=(n_jobs,n_machines), dtype=np.uint16)\n",
    "    \n",
    "    # generate randomly shuffled job machine combinations\n",
    "    # machine IDs from 1 to n_machines\n",
    "    temp = np.arange(0, (n_machines), step=1, dtype=np.uint16)\n",
    "    temp = np.expand_dims(temp, axis=0)\n",
    "    # repeat dummy line until number n_jobs is reached\n",
    "    temp = np.repeat(temp, n_jobs, axis=0)\n",
    "    # randomly permute the machine indices job-wise\n",
    "    mat_JobMachID = np_rnd_gen.permuted(temp, axis=1)\n",
    "    \n",
    "    # generate operation ID matrix\n",
    "    n_ops = n_jobs * n_machines\n",
    "    temp2 = np.arange(0, (n_ops), step=1, dtype=np.uint16)\n",
    "    mat_OpID = temp2.reshape(n_jobs, -1)\n",
    "    \n",
    "    return n_jobs, n_machines, n_ops, mat_ProcTimes, mat_JobMachID, mat_OpID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_jobs, n_machines, n_ops, \n",
    " mat_ProcTimes, mat_JobMachID, mat_OpID) = gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [0, 1, 2]], dtype=uint16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brainstorming of ways to import machine names and IDs\n",
    "*Case 1: only names are given*\n",
    "- read machine names and assert IDs to them\n",
    "- build data structure with name and ID bundled (maybe as property of a machine class)\n",
    "\n",
    "*Case 2: IDs are given*\n",
    "- only building data structure with name and ID bundled\n",
    "\n",
    "*Data Structure:*\n",
    "- if only mapping of two pairs in each direction (lookup ID or lookup machine name)\n",
    "    - bi-directional dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import simpy\n",
    "from typing import TypeAlias\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from functools import lru_cache\n",
    "\n",
    "# type aliases\n",
    "SimPyEnv: TypeAlias = simpy.core.Environment\n",
    "EnvID: TypeAlias = int\n",
    "JobID: TypeAlias = int\n",
    "CustomID: TypeAlias = str | int | None\n",
    "InfstructObj: TypeAlias = object # better naming in future\n",
    "\n",
    "# forward reference, referenced before assignment\n",
    "#Job: TypeAlias = 'Job'\n",
    "#Dispatcher: TypeAlias = 'Dispatcher'\n",
    "\n",
    "# logging\n",
    "# IPython compatibility\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#LOGGING_LEVEL = 'DEBUG'\n",
    "logger = logging.getLogger('base')\n",
    "#logger.setLevel(LOGGING_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set(['test', 'test2', 'test3', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test', 'test2', 'test3'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dedicated environment class with information on associated resources and jobs\n",
    "- maybe add possibility of using subsystems (bundle of resources with unique identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD LEGACY CODE\n",
    "class SimulationEnvironment(simpy.core.Environment):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # resource data base as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'env_id': int,\n",
    "            'custom_id': object,\n",
    "            'object': object,\n",
    "            'name': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db: DataFrame = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_lookup_props: set[str] = set(['env_id', 'custom_id', 'name'])\n",
    "        \n",
    "        ############## LEGACY CODE\n",
    "        ### legacy code, changed approach to tabular data structure\n",
    "        \"\"\"\n",
    "        self.id_counter: EnvID = 0\n",
    "        self.resources: dict[EnvID, object] = dict()\n",
    "        self._custom_identifiers: set[CustomID] = set()\n",
    "        self._custom_from_env_ids: dict[EnvID, CustomID] = dict()\n",
    "        self._custom_to_env_ids: dict[CustomID, EnvID] = dict()\n",
    "        \"\"\"\n",
    "    \n",
    "    def register_object(\n",
    "        self,\n",
    "        custom_identifier: CustomID,\n",
    "        obj: InfstructObj,\n",
    "        name: str | None,\n",
    "    ) -> tuple[EnvID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # obtain env_id and set counter up\n",
    "        env_id = self.id_counter\n",
    "        self.id_counter += 1\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'M_env_{env_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'env_id': [env_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'object': [obj],\n",
    "                                'name': [name]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._infstruct_prop)\n",
    "        self._res_db = pd.concat([self._res_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        ############### OLD\n",
    "        self.resources[env_id] = obj\n",
    "        logger.info(f\"Successfully registered object with EnvID {env_id} and name {name}\")\n",
    "        \n",
    "        return env_id, name\n",
    "    \n",
    "    def get_resource_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered objects in the environment\n",
    "        \"\"\"\n",
    "        return self._res_db\n",
    "\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "    ) -> InfstructObj:\n",
    "        \"\"\"\n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise KeyError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise ValueError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._res_db.loc[self._res_db[property] == val, 'object']\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise KeyError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.at[0]\n",
    "    \n",
    "    \n",
    "    ############## LEGACY CODE\n",
    "    ### legacy code, changed approach to tabular data structure\n",
    "    ############# NECESSARY???\n",
    "    ### new way of data table with all registered infrastructure objects\n",
    "    ### custom identifier for user interface to transfer object information\n",
    "    ### out of the model itself (together with object's name)\n",
    "    ### duplicate check convenient, but not necessary\n",
    "    ### uniqeness of env_ids is guaranteed by the inner logic\n",
    "\n",
    "    def register_custom_identifier(\n",
    "        self,\n",
    "        env_ID: EnvID,\n",
    "        custom_identifier: CustomID,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        maps custom identifiers of resources to env_id and vice versa\n",
    "        \"\"\"\n",
    "        self._custom_from_env_ids[env_ID] = custom_identifier\n",
    "        # check if custom identifier is a duplicate\n",
    "        if custom_identifier not in self._custom_identifiers:\n",
    "            self._custom_identifiers.add(custom_identifier)\n",
    "            self._custom_to_env_ids[custom_identifier] = env_ID\n",
    "        elif self._custom_to_env_ids[custom_identifier] == env_ID:\n",
    "            logger.info(\"Custom identifier already associated with given environment ID.\")\n",
    "        # ambigious, custom_identifier is a duplicate\n",
    "        else:\n",
    "            logger.warning(\"The custom identifier is ambigous and was already used before for another environment ID. \\\n",
    "                This object can only be uniquely identified by its environment ID, not by the custom identifier provided.\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_custom_from_env_id(\n",
    "        self,\n",
    "        env_ID: EnvID,\n",
    "    ) -> CustomID:\n",
    "        \"\"\"\n",
    "        #get custom ID by an object's environment id\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self._custom_from_env_ids[env_ID]\n",
    "        except KeyError as error:\n",
    "            logger.error(f\"The provided key {error} does not exist!\")\n",
    "            raise\n",
    "    \n",
    "    def get_custom_to_env_id(\n",
    "        self,\n",
    "        custom_identifier: CustomID,\n",
    "    ) -> EnvID:\n",
    "        \"\"\"\n",
    "        #get environment ID by an object's custom identifier\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self._custom_to_env_ids[custom_identifier]\n",
    "        except KeyError as error:\n",
    "            logger.error(f\"The provided key {error} does not exist!\")\n",
    "            raise\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationEnvironment(simpy.core.Environment):\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # resource data base as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'env_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db: DataFrame = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_lookup_props: set[str] = set(['env_id', 'custom_id', 'name'])\n",
    "        \n",
    "        # env identifiers\n",
    "        self.id_counter: EnvID = 0\n",
    "        \n",
    "        # job dispatcher\n",
    "        self._dispatcher_registered: bool = False\n",
    "        self._dispatcher: Dispatcher = None\n",
    "        \n",
    "        ############## LEGACY CODE\n",
    "        ### legacy code, changed approach to tabular data structure\n",
    "        \"\"\"\n",
    "        self.id_counter: EnvID = 0\n",
    "        self.resources: dict[EnvID, object] = dict()\n",
    "        self._custom_identifiers: set[CustomID] = set()\n",
    "        self._custom_from_env_ids: dict[EnvID, CustomID] = dict()\n",
    "        self._custom_to_env_ids: dict[CustomID, EnvID] = dict()\n",
    "        \"\"\"\n",
    "        \n",
    "    def _obtain_env_id(self) -> EnvID:\n",
    "        \"\"\"Simple counter function for managing environment IDs\"\"\"\n",
    "        # assign env_id and set counter up\n",
    "        env_id = self.id_counter\n",
    "        self.id_counter += 1\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    def register_dispatcher(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "    ) -> EnvID:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        if not self._dispatcher_registered:\n",
    "            self._dispatcher = dispatcher\n",
    "            self._dispatcher_registered = True\n",
    "        else:\n",
    "            raise AssertionError(\"There is already a registered dispatcher instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        \"\"\"obtain the current registered dispatcher instance of the environment\"\"\"\n",
    "        return self._dispatcher\n",
    "    \n",
    "    def register_resource(\n",
    "        self,\n",
    "        custom_identifier: CustomID,\n",
    "        obj: InfstructObj,\n",
    "        name: str | None,\n",
    "    ) -> tuple[EnvID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'M_env_{env_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'env_id': [env_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'resource': [obj],\n",
    "                                'name': [name],\n",
    "                                'res_type': [obj.res_type]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._infstruct_prop)\n",
    "        self._res_db = pd.concat([self._res_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered object with EnvID {env_id} and name {name}\")\n",
    "        \n",
    "        return env_id, name\n",
    "    \n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        \"\"\"obtain a current overview of registered objects in the environment\"\"\"\n",
    "        return self._res_db\n",
    "\n",
    "    @lru_cache(maxsize=200)\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "        target_prop: str = 'resource',\n",
    "    ) -> InfstructObj:\n",
    "        \"\"\"\n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._res_db.loc[self._res_db[property] == val, target_prop]\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.iat[0]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(simpy.resources.resource.Resource):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        custom_identifier: CustomID = None,\n",
    "        name: str | None = None,\n",
    "        num_slots: int = 1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env:        SimPy Environment in which machine is embedded\n",
    "        num_slots:  capacity of the machine, if multiple processing \n",
    "                    slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        # intialize base class\n",
    "        super().__init__(env=env, capacity=num_slots)\n",
    "        \n",
    "        ############# custom identifiers only over env_id\n",
    "        ### associate env_id with custom_id in env\n",
    "        ### lookup env_id of object in environment and obtain custom_id\n",
    "        \n",
    "        \n",
    "        ############# CHECK IF NECESSARY IN FUTURE\n",
    "        \"\"\"\n",
    "        if custom_identifier is not None:\n",
    "            ret = env.register_custom_identifier(\n",
    "                    env_ID=self.env_id, custom_identifier=custom_identifier)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # assert machine information and register object in the environment\n",
    "        self.env = env\n",
    "        self.custom_identifier = custom_identifier\n",
    "        self.res_type: str = 'Machine'\n",
    "        self.env_id, self.name = env.register_resource(\n",
    "                                custom_identifier=self.custom_identifier,\n",
    "                                obj=self, name=name)\n",
    "        \n",
    "        \n",
    "        # currently processed job\n",
    "        self.current_job_ID: int | None = None\n",
    "        self.current_job: Job | None = None\n",
    "        \n",
    "        # machine state parameters\n",
    "        self.is_occupied: bool = False\n",
    "        self.is_waiting: bool = False\n",
    "        self.is_blocked: bool = False\n",
    "        self.is_failed: bool = False\n",
    "        # maybe for future, curently no working time calendars planned\n",
    "        self.is_paused: bool = False\n",
    "        \n",
    "        # time in state parameters\n",
    "        self.time_occupied: float = 0.\n",
    "        self.time_waiting: float = 0.\n",
    "        self.time_blocked: float = 0.\n",
    "        self.time_failed: float = 0.\n",
    "        \n",
    "        # number of inputs/outputs\n",
    "        self.num_jobs_input: int = 0\n",
    "        self.num_jobs_output: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_jobs, n_machines, n_ops, \n",
    " mat_ProcTimes, mat_JobMachID, mat_OpID) = gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [0, 1, 2]], dtype=uint16)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]], dtype=uint16)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_OpID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:base:Successfully registered object with EnvID 0 and name M_env_0\n",
      "INFO:base:Successfully registered object with EnvID 1 and name M_env_1\n",
      "INFO:base:Successfully registered object with EnvID 2 and name M_env_2\n"
     ]
    }
   ],
   "source": [
    "env = SimulationEnvironment()\n",
    "\n",
    "for machine in np.unique(mat_JobMachID):\n",
    "    MachInst = Machine(env=env, custom_identifier=machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;__main__.Machine object at 0x0000025C679D22D0&gt;</td>\n",
       "      <td>M_env_0</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;__main__.Machine object at 0x0000025C680E0090&gt;</td>\n",
       "      <td>M_env_1</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;__main__.Machine object at 0x0000025C680C14D0&gt;</td>\n",
       "      <td>M_env_2</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_id custom_id                                         resource     name   \n",
       "0       0         0  <__main__.Machine object at 0x0000025C679D22D0>  M_env_0  \\\n",
       "1       1         1  <__main__.Machine object at 0x0000025C680E0090>  M_env_1   \n",
       "2       2         2  <__main__.Machine object at 0x0000025C680C14D0>  M_env_2   \n",
       "\n",
       "  res_type  \n",
       "0  Machine  \n",
       "1  Machine  \n",
       "2  Machine  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_db = env.res_db\n",
    "res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = env.get_res_obj_by_prop(property='env_id', val=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Machine at 0x25c680c14d0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- job sets as own class currently not necessary, use standard OrderedDict instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobSet(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mat_ProcTimes: npt.NDArray[np.uint16],\n",
    "        mat_JobMachID: npt.NDArray[np.uint16],\n",
    "        mat_OpID: npt.NDArray[np.uint16],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "        \n",
    "        self._jobs = OrderedDict()\n",
    "        \n",
    "        for job_id in range(len(mat_ProcTimes)):\n",
    "            temp1 = mat_ProcTimes[job_id].tolist()\n",
    "            temp2 = mat_JobMachID[job_id].tolist()\n",
    "            temp3 = mat_OpID[job_id].tolist()\n",
    "            job = Job(\n",
    "                identifier=job_id,\n",
    "                proc_times=temp1,\n",
    "                machine_order=temp2,\n",
    "                operation_identifiers=temp3,\n",
    "            )\n",
    "            self._jobs[job_id] = job\n",
    "            \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        job_id: int,\n",
    "    ):\n",
    "        return self._jobs[job_id]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Adding database approach also to the job dispatcher**\n",
    "**properties**:\n",
    "- job_id\n",
    "- custom_id\n",
    "- job instance\n",
    "- name\n",
    "- product_type (for later implementation of different product types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher(object):\n",
    "    Job: TypeAlias = 'Job'\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dispatcher class for given environment (only one dispatcher for each environment)\n",
    "        - different functions to monitor all jobs in the environment\n",
    "        - jobs report back their states to the JobWatcher\n",
    "        \"\"\"\n",
    "                \n",
    "        # job data base as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'job_id': int,\n",
    "            'custom_id': object,\n",
    "            'job': object,\n",
    "            'name': str,\n",
    "            'job_type': str,\n",
    "        }\n",
    "        self._job_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._job_db: DataFrame = self._job_db.astype(self._infstruct_prop)\n",
    "        self._job_lookup_props: set[str] = set(['job_id', 'custom_id', 'name'])\n",
    "        \n",
    "        self.disposable_jobs: dict[int, Job] = dict()\n",
    "        self.job_pool: OrderedDict[JobID, Job] = OrderedDict()\n",
    "        self.id_counter: JobID = 0\n",
    "    \n",
    "    def gen_job_pool_generic(\n",
    "        self,\n",
    "        mat_ProcTimes: npt.NDArray[np.uint16],\n",
    "        mat_JobMachID: npt.NDArray[np.uint16],\n",
    "        mat_OpID: npt.NDArray[np.uint16],\n",
    "    ) -> OrderedDict[JobID, Job]:\n",
    "        \"\"\"\n",
    "        function to build a integrated job pool if generic JxM JSSP instances are used\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "            \n",
    "        for job_id in range(len(mat_ProcTimes)):\n",
    "            temp1 = mat_ProcTimes[job_id].tolist()\n",
    "            temp2 = mat_JobMachID[job_id].tolist()\n",
    "            temp3 = mat_OpID[job_id].tolist()\n",
    "            JobInst = Job(\n",
    "                identifier=job_id,\n",
    "                proc_times=temp1,\n",
    "                machine_order=temp2,\n",
    "                operation_identifiers=temp3,\n",
    "                dispatcher=self,\n",
    "            )\n",
    "            ######### ADD TO JOB (bottom-up approach) #######################\n",
    "            ### jobs add themselves to job pool\n",
    "            self.job_pool[job_id] = JobInst\n",
    "            \n",
    "        return self.job_pool\n",
    "     \n",
    "    @property\n",
    "    def job_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered objects in the environment\n",
    "        \"\"\"\n",
    "        return self._job_db\n",
    "\n",
    "    @lru_cache(maxsize=200)\n",
    "    def get_job_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "        target_prop: str = 'job',\n",
    "    ) -> InfstructObj:\n",
    "        \"\"\"\n",
    "        obtain a job object from the dispatcher by its property and corresponding value\n",
    "        properties: job_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._job_db.loc[self._job_db[property] == val, target_prop]\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.iat[0]\n",
    "    \n",
    "    ################# REWORK ##################\n",
    "    def get_disposable_jobs(\n",
    "        self,\n",
    "        job_set: OrderedDict,\n",
    "    ) -> tuple[list[JobID], list[Job]]:\n",
    "        \"\"\"\n",
    "        function needs to be reworked, jobs should report back information to a dispatcher instance\n",
    "        (bottom-up instead of top-down)\n",
    "        \"\"\"\n",
    "        #########################################\n",
    "        self._disposable_jobs_ID: list[int] = list()\n",
    "        self._disposable_jobs: list[Job] = list()\n",
    "        \n",
    "        for job_id, job in job_set.items():\n",
    "            if job.is_disposable:\n",
    "                self._disposable_jobs_ID.append(job_id)\n",
    "                self._disposable_jobs.append(job)\n",
    "                \n",
    "        return self._disposable_jobs_ID, self._disposable_jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind simulation model approach\n",
    "*Model of Resource and Load*:\n",
    "- system consists of physical objects, also called infrastructure\n",
    "    - each element can be considered as encapsulated resource\n",
    "- stress can be put on each system by occupying resources, also called load\n",
    "    - definition of load depends on system type and modelling, e.g. production jobs for production systems or customers for cashiers in a shop\n",
    "\n",
    "*Guiding Priciples*:\n",
    "- **load objects** can only be spatially and temporally modified by **resources**\n",
    "    - whole **routing logic is implemented in the resources**: no load object can change its state without a associated resource\n",
    "    - load objects **contain the necessary information** which is essential for their further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        identifier: int,\n",
    "        proc_times: float,\n",
    "        machine_identifier: int,\n",
    "        name: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        identifier:         operation's ID\n",
    "        proc_times:         operation's processing times\n",
    "        machine_identifier: ID of machine on which operation is processed\n",
    "        \"\"\"\n",
    "        # !!!!!!!!! perhaps processing times in future multiple entries depending on associated machine\n",
    "        # change of input format necessary, currently only one machine for each operation\n",
    "        # no groups, no differing processing times for different machines \n",
    "\n",
    "        # assert operation information\n",
    "        self.identifier = identifier\n",
    "        # custom name\n",
    "        if name is not None:\n",
    "            self.name = name\n",
    "        else:\n",
    "            self.name = f'O{identifier}'\n",
    "            \n",
    "        # process information\n",
    "        self.proc_time = proc_times\n",
    "        ########### adding machine instances\n",
    "        ### perhaps adding machine sets if multiple machines possible (machine groups)\n",
    "        self.target_machine = machine_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(object):\n",
    "    Job: TypeAlias = 'Job'\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        identifier: JobID,\n",
    "        proc_times: list[float],\n",
    "        machine_order: list[int],\n",
    "        operation_identifiers: list[int],\n",
    "        dispatcher: Dispatcher,\n",
    "        name: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        identifier:             job's ID\n",
    "        proc_times:             list of processing times for each operation\n",
    "        machine_order:          list of machine IDs\n",
    "        operation_identifiers:  list of operation IDs\n",
    "        \"\"\"\n",
    "        # intialize base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ### BASIC INFORMATION ###\n",
    "        # assert job information\n",
    "        self.identifier = identifier\n",
    "        # custom name\n",
    "        if name is not None:\n",
    "            self.name = name\n",
    "        else:\n",
    "            self.name = f'J{identifier}'\n",
    "        self.Dispatcher = dispatcher\n",
    "        \n",
    "        \n",
    "        ### OPERATIONS ##\n",
    "        self.operations = list()\n",
    "        \n",
    "        for idx, op_ID in enumerate(operation_identifiers):\n",
    "            Op = Operation(\n",
    "                identifier=op_ID,\n",
    "                proc_times=proc_times[idx],\n",
    "                machine_identifier=machine_order[idx],\n",
    "            )\n",
    "            self.operations.append(Op)\n",
    "            \n",
    "        self.total_num_ops: int = len(self.operations)\n",
    "        self.num_finished_ops: int = 0\n",
    "        self.current_op: Operation = self.operations[0]\n",
    "        \n",
    "        ### STATE ###\n",
    "        # intra-process job state parameters\n",
    "        # job is being processed, maybe better naming in future\n",
    "        self.is_occupied: bool = False\n",
    "        # waiting state only when released\n",
    "        self.is_waiting: bool = False\n",
    "        # if lying on failed machine\n",
    "        self.is_failed: bool = False\n",
    "        \n",
    "        # intra-process time characteristics\n",
    "        self.time_occupied: float = 0.\n",
    "        self.time_waiting: float = 0.\n",
    "        self.time_failed: float = 0.\n",
    "        \n",
    "        # inter-process job state parameters\n",
    "        # first operation scheduled --> released job\n",
    "        self.is_released: bool = False\n",
    "        # job's next operation is disposable\n",
    "        # true for each new job, maybe reworked in future for jobs with\n",
    "        # a start date later than creation date\n",
    "        self.is_disposable: bool = True\n",
    "        self.Dispatcher.disposable_jobs[self.identifier] = self\n",
    "        # last operation ended --> finished job\n",
    "        self.is_finished: bool = False\n",
    "        \n",
    "        # inter-process time characteristics\n",
    "        # time of first operation starting point\n",
    "        self.time_entry: float = 0.\n",
    "        # time of last operation ending point\n",
    "        self.time_exit: float = 0.\n",
    "        \n",
    "        # current resource location\n",
    "        self.current_resource: object | None = None # specify type if class definition finished\n",
    "        \n",
    "        \n",
    "    def obtain_current_op(self) -> Operation:\n",
    "        \"\"\"\n",
    "        returns the current operation of the job\n",
    "        If a job is currently being processed its current operation is \n",
    "        not changed until this operation is finished.\n",
    "        \"\"\"\n",
    "        return self.current_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_jobs, n_machines, n_ops, \n",
    " mat_ProcTimes, mat_JobMachID, mat_OpID) = gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [0, 1, 2]], dtype=uint16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]], dtype=uint16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_OpID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- job sets as own class currently not necessary, use standard OrderedDict instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobSet(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mat_ProcTimes: npt.NDArray[np.uint16],\n",
    "        mat_JobMachID: npt.NDArray[np.uint16],\n",
    "        mat_OpID: npt.NDArray[np.uint16],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "        \n",
    "        self._jobs = OrderedDict()\n",
    "        \n",
    "        for job_id in range(len(mat_ProcTimes)):\n",
    "            temp1 = mat_ProcTimes[job_id].tolist()\n",
    "            temp2 = mat_JobMachID[job_id].tolist()\n",
    "            temp3 = mat_OpID[job_id].tolist()\n",
    "            job = Job(\n",
    "                identifier=job_id,\n",
    "                proc_times=temp1,\n",
    "                machine_order=temp2,\n",
    "                operation_identifiers=temp3,\n",
    "            )\n",
    "            self._jobs[job_id] = job\n",
    "            \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        job_id: int,\n",
    "    ):\n",
    "        return self._jobs[job_id]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:base:Successfully registered object with EnvID 0 and name M_env_0\n",
      "INFO:base:Successfully registered object with EnvID 1 and name M_env_1\n",
      "INFO:base:Successfully registered object with EnvID 2 and name M_env_2\n"
     ]
    }
   ],
   "source": [
    "machine_infrastructure = OrderedDict()\n",
    "env = SimulationEnvironment()\n",
    "\n",
    "for machine in np.unique(mat_JobMachID):\n",
    "    MachInst = Machine(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.env_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DispatcherInst = Dispatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_pool = DispatcherInst.gen_job_pool_generic(\n",
    "    mat_ProcTimes=mat_ProcTimes,\n",
    "    mat_JobMachID=mat_JobMachID,\n",
    "    mat_OpID=mat_OpID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DispatcherInst.disposable_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <__main__.Job at 0x25c678b3450>, 1: <__main__.Job at 0x25c678bc290>}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import salabim as sim\n",
    "import simpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_time():\n",
    "    return random.normalvariate(mu=10., sigma=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process_put(env, store):\n",
    "    TIME = 10\n",
    "    counter = 10\n",
    "    while counter:\n",
    "        item = yield store.get()\n",
    "        print(f\"I got item {item} at {env.now}\")\n",
    "        yield env.timeout(TIME)\n",
    "        #yield env.timeout(TIME)\n",
    "        #print(f\"I got executed at {env.now}\")\n",
    "        counter -= 1\n",
    "        \n",
    "def placer_process(env, store):\n",
    "    TIME = 2\n",
    "    counter = 6\n",
    "    while counter:\n",
    "        yield env.timeout(TIME)\n",
    "        yield store.put(counter)\n",
    "        print(f\"Placed object {counter} in store\")\n",
    "        counter -= 1\n",
    "        \n",
    "def placer_process_machine(env, machine):\n",
    "    TIME = 2\n",
    "    counter = 6\n",
    "    PROCESSING_TIME = 10\n",
    "    while counter:\n",
    "        #yield env.timeout(TIME)\n",
    "        with machine.request() as req:\n",
    "            yield req\n",
    "        yield env.timeout(PROCESSING_TIME)\n",
    "        #yield machine.put(counter)\n",
    "        print(f\"Item processed on machine {machine} at {env.now}\")\n",
    "        counter -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Process(placer_process_machine) object at 0x25c67526b90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "store = simpy.Store(env=env)\n",
    "store.put(1)\n",
    "machine = simpy.resources.resource.Resource(env=env)\n",
    "#env.process(test_process_put(env=env, store=store))\n",
    "#env.process(placer_process(env=env, store=store))\n",
    "env.process(placer_process_machine(env=env, machine=machine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 10\n",
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 20\n",
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 30\n",
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 40\n",
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 50\n",
      "Item processed on machine <simpy.resources.resource.Resource object at 0x0000025C67896050> at 60\n"
     ]
    }
   ],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
