{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import simpy\n",
    "import salabim as sim\n",
    "from typing import TypeAlias\n",
    "from collections import OrderedDict\n",
    "from collections import deque\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from functools import lru_cache\n",
    "\n",
    "# type aliases\n",
    "SimPyEnv: TypeAlias = simpy.core.Environment\n",
    "SalabimEnv: TypeAlias = sim.Environment\n",
    "EnvID: TypeAlias = int\n",
    "JobID: TypeAlias = int\n",
    "OpID: TypeAlias = int\n",
    "MachineID: TypeAlias = int | str\n",
    "CustomID: TypeAlias = int | str\n",
    "InfstructObj: TypeAlias = object # better naming in future\n",
    "\n",
    "# forward reference, referenced before assignment\n",
    "#Job: TypeAlias = 'Job'\n",
    "#Dispatcher: TypeAlias = 'Dispatcher'\n",
    "\n",
    "# logging\n",
    "# IPython compatibility\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#LOGGING_LEVEL = 'DEBUG'\n",
    "logger = logging.getLogger('base')\n",
    "#logger.setLevel(LOGGING_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rnd_JSSP_inst(\n",
    "    n_jobs: int,\n",
    "    n_machines: int,\n",
    "    seed: int = 42,\n",
    ") -> tuple[int, int, int, npt.NDArray[np.uint16], npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "    \"\"\"\n",
    "    Generates random job shop instance with given number of jobs and machines'\n",
    "    - each job on all machines\n",
    "    - max processing time = 9\n",
    "    \n",
    "    Output:\n",
    "        - n_jobs: number of jobs\n",
    "        - n_machines: number of machines\n",
    "        - n_tasks: number of tasks\n",
    "        - mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        - mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        - mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "    \"\"\"\n",
    "    # generate random process time matrix shape=(n_jobs, n_machines)\n",
    "    np_rnd_gen = np.random.default_rng(seed=seed)\n",
    "    mat_ProcTimes = np_rnd_gen.integers(1, 10, size=(n_jobs,n_machines), dtype=np.uint16)\n",
    "    \n",
    "    # generate randomly shuffled job machine combinations\n",
    "    # machine IDs from 1 to n_machines\n",
    "    temp = np.arange(0, (n_machines), step=1, dtype=np.uint16)\n",
    "    temp = np.expand_dims(temp, axis=0)\n",
    "    # repeat dummy line until number n_jobs is reached\n",
    "    temp = np.repeat(temp, n_jobs, axis=0)\n",
    "    # randomly permute the machine indices job-wise\n",
    "    mat_JobMachID = np_rnd_gen.permuted(temp, axis=1)\n",
    "    \n",
    "    # generate operation ID matrix\n",
    "    n_ops = n_jobs * n_machines\n",
    "    temp2 = np.arange(0, (n_ops), step=1, dtype=np.uint16)\n",
    "    mat_OpID = temp2.reshape(n_jobs, -1)\n",
    "    \n",
    "    return n_jobs, n_machines, n_ops, mat_ProcTimes, mat_JobMachID, mat_OpID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_jobs, n_machines, n_ops, \n",
    " mat_ProcTimes, mat_JobMachID, mat_OpID) = gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [0, 1, 2]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brainstorming of ways to import machine names and IDs\n",
    "*Case 1: only names are given*\n",
    "- read machine names and assert IDs to them\n",
    "- build data structure with name and ID bundled (maybe as property of a machine class)\n",
    "\n",
    "*Case 2: IDs are given*\n",
    "- only building data structure with name and ID bundled\n",
    "\n",
    "*Data Structure:*\n",
    "- if only mapping of two pairs in each direction (lookup ID or lookup machine name)\n",
    "    - bi-directional dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for resource objects:**\n",
    "- CustomID may not be of type 'None' because the custom identifiers are the only interface to the end user (EnvID are solely handled inernally)\n",
    "- add checking for uniqueness of custom identifiers necessary, else the mapping of different objects could be ambiguous\n",
    "- jobs and operations can use ambiguous custom IDs --> custom IDs can still be None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dedicated environment class with information on associated resources and jobs\n",
    "- maybe add possibility of using subsystems (bundle of resources with unique identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationEnvironment(simpy.core.Environment):\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # resource data base as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'env_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db: DataFrame = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_lookup_props: set[str] = set(['env_id', 'custom_id', 'name'])\n",
    "        \n",
    "        # env identifiers\n",
    "        self._id_counter: EnvID = 0\n",
    "        self._res_custom_identifiers: set[str | int] = set()\n",
    "        \n",
    "        # job dispatcher\n",
    "        self._dispatcher_registered: bool = False\n",
    "        self._dispatcher: Dispatcher = None\n",
    "        \n",
    "        ############## LEGACY CODE\n",
    "        ### legacy code, changed approach to tabular data structure\n",
    "        \"\"\"\n",
    "        self.id_counter: EnvID = 0\n",
    "        self.resources: dict[EnvID, object] = dict()\n",
    "        self._custom_identifiers: set[CustomID] = set()\n",
    "        self._custom_from_env_ids: dict[EnvID, CustomID] = dict()\n",
    "        self._custom_to_env_ids: dict[CustomID, EnvID] = dict()\n",
    "        \"\"\"\n",
    "        \n",
    "    def _obtain_env_id(self) -> EnvID:\n",
    "        \"\"\"Simple counter function for managing environment IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        env_id = self._id_counter\n",
    "        self._id_counter += 1\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    def register_dispatcher(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "    ) -> EnvID:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        if not self._dispatcher_registered:\n",
    "            self._dispatcher = dispatcher\n",
    "            self._dispatcher_registered = True\n",
    "            logger.info(f\"Successfully registered dispatcher with EnvID {env_id}\")\n",
    "        else:\n",
    "            raise AssertionError(\"There is already a registered dispatcher instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        \"\"\"obtain the current registered dispatcher instance of the environment\"\"\"\n",
    "        if self._dispatcher is None:\n",
    "            raise ValueError(\"No Dipsatcher instance registered.\")\n",
    "        else:\n",
    "            return self._dispatcher\n",
    "    \n",
    "    def register_resource(\n",
    "        self,\n",
    "        obj: InfstructObj,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "    ) -> tuple[EnvID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in self._res_custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided already exists, \\\n",
    "                            but has to be unique.\")\n",
    "        else:\n",
    "            self._res_custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'M_env_{env_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'env_id': [env_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'resource': [obj],\n",
    "                                'name': [name],\n",
    "                                'res_type': [obj.res_type]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._infstruct_prop)\n",
    "        self._res_db = pd.concat([self._res_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered object with EnvID {env_id} and name {name}\")\n",
    "        \n",
    "        return env_id, name\n",
    "    \n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        \"\"\"obtain a current overview of registered objects in the environment\"\"\"\n",
    "        return self._res_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "        target_prop: str = 'resource',\n",
    "    ) -> InfstructObj:\n",
    "        \"\"\"\n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._res_db.loc[self._res_db[property] == val, target_prop]\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.iat[0]\n",
    "    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salabim Env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationEnvironment(sim.Environment):\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # resource data base as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'env_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db: DataFrame = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_lookup_props: set[str] = set(['env_id', 'custom_id', 'name'])\n",
    "        \n",
    "        # env identifiers\n",
    "        self._id_counter: EnvID = 0\n",
    "        self._res_custom_identifiers: set[str | int] = set()\n",
    "        \n",
    "        # job dispatcher\n",
    "        self._dispatcher_registered: bool = False\n",
    "        self._dispatcher: Dispatcher = None\n",
    "        \n",
    "        ############## LEGACY CODE\n",
    "        ### legacy code, changed approach to tabular data structure\n",
    "        \"\"\"\n",
    "        self.id_counter: EnvID = 0\n",
    "        self.resources: dict[EnvID, object] = dict()\n",
    "        self._custom_identifiers: set[CustomID] = set()\n",
    "        self._custom_from_env_ids: dict[EnvID, CustomID] = dict()\n",
    "        self._custom_to_env_ids: dict[CustomID, EnvID] = dict()\n",
    "        \"\"\"\n",
    "        self._ultimative_test = pd.DataFrame(columns=['test1', 'test2'])\n",
    "        \n",
    "    def _obtain_env_id(self) -> EnvID:\n",
    "        \"\"\"Simple counter function for managing environment IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        env_id = self._id_counter\n",
    "        self._id_counter += 1\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    def register_dispatcher(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "    ) -> EnvID:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        if not self._dispatcher_registered:\n",
    "            self._dispatcher = dispatcher\n",
    "            self._dispatcher_registered = True\n",
    "            logger.info(f\"Successfully registered dispatcher with EnvID {env_id}\")\n",
    "        else:\n",
    "            raise AssertionError(\"There is already a registered dispatcher instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        \"\"\"obtain the current registered dispatcher instance of the environment\"\"\"\n",
    "        if self._dispatcher is None:\n",
    "            raise ValueError(\"No Dipsatcher instance registered.\")\n",
    "        else:\n",
    "            return self._dispatcher\n",
    "    \n",
    "    def register_resource(\n",
    "        self,\n",
    "        obj: InfstructObj,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "    ) ->  tuple[EnvID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in self._res_custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided already exists, \\\n",
    "                            but has to be unique.\")\n",
    "        else:\n",
    "            self._res_custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'M_env_{env_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'env_id': [env_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'resource': [obj],\n",
    "                                'name': [name],\n",
    "                                'res_type': [obj.res_type]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._infstruct_prop)\n",
    "        self._res_db = pd.concat([self._res_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered object with EnvID {env_id} and name {name}\")\n",
    "        \n",
    "        return env_id, name\n",
    "    \n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        \"\"\"obtain a current overview of registered objects in the environment\"\"\"\n",
    "        return self._res_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "        target_prop: str = 'resource',\n",
    "    ) -> InfstructObj:\n",
    "        \"\"\"\n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._res_db.loc[self._res_db[property] == val, target_prop]\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.iat[0]\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(sim.Component):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None = None,\n",
    "        num_slots: int = 1,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env:        SimPy Environment in which machine is embedded\n",
    "        num_slots:  capacity of the machine, if multiple processing \n",
    "                    slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        ############# custom identifiers only over env_id\n",
    "        ### associate env_id with custom_id in env\n",
    "        ### lookup env_id of object in environment and obtain custom_id\n",
    "        \n",
    "        \n",
    "        ############# CHECK IF NECESSARY IN FUTURE\n",
    "        \"\"\"\n",
    "        if custom_identifier is not None:\n",
    "            ret = env.register_custom_identifier(\n",
    "                    env_ID=self.env_id, custom_identifier=custom_identifier)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # assert machine information and register object in the environment\n",
    "        #self._env = env\n",
    "        self.res_type: str = 'Machine'\n",
    "        self._env_id, name = env.register_resource(\n",
    "                                obj=self, custom_identifier=custom_identifier,\n",
    "                                name=name)\n",
    "        self.custom_identifier = custom_identifier\n",
    "        \n",
    "        # intialize base class\n",
    "        super().__init__(env=env, name=name, *args, **kwargs)\n",
    "        \n",
    "        # add (logical) buffer\n",
    "        # each resource uses an associated buffer, even if there is none physically available\n",
    "        buff_name = f\"buffer_{self.name()}\"\n",
    "        self.buffer = sim.Queue(name=buff_name, env=self.env)\n",
    "        \n",
    "        # currently processed job\n",
    "        self.current_job_ID: int | None = None\n",
    "        self.current_job: Job | None = None\n",
    "        \n",
    "        # machine state parameters\n",
    "        self.is_occupied: bool = False\n",
    "        self.is_waiting: bool = False\n",
    "        self.is_blocked: bool = False\n",
    "        self.is_failed: bool = False\n",
    "        # maybe for future, curently no working time calendars planned\n",
    "        self.is_paused: bool = False\n",
    "        \n",
    "        # time in state parameters\n",
    "        self.time_occupied: float = 0.\n",
    "        self.time_waiting: float = 0.\n",
    "        self.time_blocked: float = 0.\n",
    "        self.time_failed: float = 0.\n",
    "        \n",
    "        # number of inputs/outputs\n",
    "        self.num_jobs_input: int = 0\n",
    "        self.num_jobs_output: int = 0\n",
    "    \n",
    "    @property\n",
    "    def env_id(self) -> EnvID:\n",
    "        return self._env_id\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_jobs, n_machines, n_ops, \n",
    " mat_ProcTimes, mat_JobMachID, mat_OpID) = gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 9],\n",
       "       [7, 9, 6]], dtype=uint16)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1],\n",
       "       [0, 1, 2]], dtype=uint16)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]], dtype=uint16)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_OpID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:base:Successfully registered object with EnvID 0 and name M_env_0\n",
      "INFO:base:Successfully registered object with EnvID 1 and name M_env_1\n",
      "INFO:base:Successfully registered object with EnvID 2 and name M_env_2\n"
     ]
    }
   ],
   "source": [
    "env = SimulationEnvironment(name='base')\n",
    "\n",
    "for machine in np.unique(mat_JobMachID):\n",
    "    MachInst = Machine(env=env, custom_identifier=machine.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine (M_env_0)</td>\n",
       "      <td>M_env_0</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Machine (M_env_1)</td>\n",
       "      <td>M_env_1</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Machine (M_env_2)</td>\n",
       "      <td>M_env_2</td>\n",
       "      <td>Machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_id custom_id           resource     name res_type\n",
       "0       0         0  Machine (M_env_0)  M_env_0  Machine\n",
       "1       1         1  Machine (M_env_1)  M_env_1  Machine\n",
       "2       2         2  Machine (M_env_2)  M_env_2  Machine"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimulationEnvironment (base)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimulationEnvironment (base)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M_env_2'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queue (buffer_M_env_2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = env.get_res_obj_by_prop(property='env_id', val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M_env_0'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queue (buffer_M_env_0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.buffer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Adding database approach also to the job dispatcher**\n",
    "**properties**:\n",
    "- job_id\n",
    "- custom_id\n",
    "- job instance\n",
    "- name\n",
    "- product_type (for later implementation of different product types)\n",
    "\n",
    "#### To-Do:\n",
    "- [x] ~~register job object in dispatcher~~\n",
    "- [x] ~~register operations in dispatcher~~\n",
    "- [ ] self-marking as disposable by jobs\n",
    "    - includes demarking\n",
    "    - currently only addition implemented\n",
    "- [x] ~~add uniqueness check for custom IDs in resource objects (only interface to user)~~\n",
    "- [x] ~~operations list of jobs as deque~~\n",
    "- [ ] add status info to job DB? (waiting, processing, ...) (disposable = waiting?)\n",
    "    - advantage: \n",
    "        - one central DB with all information, no cluttered information\n",
    "        - simple filtering for jobs by current status incl. disposable jobs\n",
    "- [ ] tracking disjunctive graph model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher(object):\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    Job: TypeAlias = 'Job'\n",
    "    Operation: TypeAlias = 'Operation'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dispatcher class for given environment (only one dispatcher for each environment)\n",
    "        - different functions to monitor all jobs in the environment\n",
    "        - jobs report back their states to the dispatcher\n",
    "        \"\"\"\n",
    "                \n",
    "        # job data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._job_prop: dict[str, type] = {\n",
    "            'job_id': int,\n",
    "            'custom_id': object,\n",
    "            'job': object,\n",
    "            'name': str,\n",
    "            'job_type': str,\n",
    "            'status': str,\n",
    "        }\n",
    "        self._job_db: DataFrame = pd.DataFrame(columns=list(self._job_prop.keys()))\n",
    "        self._job_db: DataFrame = self._job_db.astype(self._job_prop)\n",
    "        self._job_lookup_props: set[str] = set(['job_id', 'custom_id', 'name'])\n",
    "        \n",
    "        # operation data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._op_prop: dict[str, type] = {\n",
    "            'op_id': int,\n",
    "            'job_id': int,\n",
    "            'custom_id': object,\n",
    "            'op': object,\n",
    "            'name': str,\n",
    "            'machine': object,\n",
    "            'status': str,\n",
    "        }\n",
    "        self._op_db: DataFrame = pd.DataFrame(columns=list(self._op_prop.keys()))\n",
    "        self._op_db: DataFrame = self._op_db.astype(self._op_prop)\n",
    "        self._op_lookup_props: set[str] = set(['op_id', 'job_id', 'custom_id', 'name', 'machine'])\n",
    "                \n",
    "        # register in environment and get EnvID\n",
    "        self._env = env\n",
    "        self._env_id: EnvID = self._env.register_dispatcher(self)\n",
    "        \n",
    "        self._disposable_jobs: dict[int, Job] = dict()\n",
    "        self.job_pool: OrderedDict[JobID, Job] = OrderedDict()\n",
    "        # managing IDs\n",
    "        self._id_types = set(['job', 'op'])\n",
    "        self._job_id_counter: JobID = 0\n",
    "        self._op_id_counter: OpID = 0\n",
    "    \n",
    "    @property\n",
    "    def env_id(self) -> EnvID:\n",
    "        return self._env_id\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    def _obtain_job_id(self) -> JobID:\n",
    "        \"\"\"Simple counter function for managing job IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        job_id = self._id_counter\n",
    "        self._id_counter += 1\n",
    "        \n",
    "        return job_id\n",
    "    \n",
    "    def _obtain_op_id(self) -> OpID:\n",
    "        \"\"\"Simple counter function for managing operation IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        op_id = self._op_id_counter\n",
    "        self._op_id_counter += 1\n",
    "        \n",
    "        return op_id\n",
    "    \n",
    "    def _obtain_load_obj_id(\n",
    "        self,\n",
    "        load_type: str,\n",
    "    ) -> JobID | OpID:\n",
    "        \"\"\"Simple counter function for managing operation IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        \n",
    "        if load_type not in self._id_types:\n",
    "            raise ValueError(f\"Given type {type} not valid. Choose from '{self._id_types}'\")\n",
    "        \n",
    "        match load_type:\n",
    "            case 'job':\n",
    "                ident_no = self._job_id_counter\n",
    "                self._job_id_counter += 1\n",
    "            case 'op':\n",
    "                ident_no = self._op_id_counter\n",
    "                self._op_id_counter += 1\n",
    "        \n",
    "        return ident_no\n",
    "    \n",
    "    ###################### common register function for load objects of different kind\n",
    "    ### perhaps not best way because complexity increases and readability suffers\n",
    "    def register_load_obj(\n",
    "        self,\n",
    "        load_type: str,\n",
    "        obj: Job,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "    ) -> tuple[JobID, str]:\n",
    "        \"\"\"\n",
    "        registers an load object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated DB of the dispatcher instance\n",
    "        allowed types: 'job', 'op'\n",
    "        \"\"\"\n",
    "        # check if load type is allowed\n",
    "        if load_type not in self._id_types:\n",
    "            raise ValueError(f\"Given type {type} not valid. Choose from '{self._id_types}'\")\n",
    "        \n",
    "        # obtain id\n",
    "        match load_type:\n",
    "            case 'job':\n",
    "                ident_no = self._obtain_load_obj_id(load_type=load_type)\n",
    "                # custom name\n",
    "                if name is None:\n",
    "                    name = f'J_gen_{job_id}'\n",
    "                # new entry for job data base\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'job_id': [ident_no],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'job': [obj],\n",
    "                                        'name': [name],\n",
    "                                        'job_type': [obj.job_type]})\n",
    "                new_entry: DataFrame = new_entry.astype(self._job_prop)\n",
    "                self._job_db = pd.concat([self._job_db, new_entry], ignore_index=True)\n",
    "                \n",
    "            case 'op':\n",
    "                ident_no = self._obtain_load_obj_id(load_type=load_type)\n",
    "                # custom name\n",
    "                if name is None:\n",
    "                    name = f'J_gen_{job_id}'\n",
    "                # new entry for job data base\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'job_id': [ident_no],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'job': [obj],\n",
    "                                        'name': [name],\n",
    "                                        'job_type': [obj.job_type]})\n",
    "                new_entry: DataFrame = new_entry.astype(self._job_prop)\n",
    "                self._job_db = pd.concat([self._job_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered load object of type {load_type} with ID {ident_no} and name {name}\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def register_job(\n",
    "        self,\n",
    "        obj: Job,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        status: str | None,\n",
    "    ) -> tuple[JobID, str]:\n",
    "        \"\"\"\n",
    "        registers an job object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated jobs\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # obtain id\n",
    "        job_id = self._obtain_load_obj_id(load_type='job')\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'J_gen_{job_id}'\n",
    "        \n",
    "        # new entry for job data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'job_id': [job_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'job': [obj],\n",
    "                                'name': [name],\n",
    "                                'job_type': [obj.job_type],\n",
    "                                'status': status})\n",
    "        new_entry: DataFrame = new_entry.astype(self._job_prop)\n",
    "        self._job_db: DataFrame = pd.concat([self._job_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered job with JobID {job_id} and name {name}\")\n",
    "        \n",
    "        return job_id, name\n",
    "    ################################################################\n",
    "    ### add OP database\n",
    "    def register_operation(\n",
    "        self,\n",
    "        obj: Operation,\n",
    "        machine_identifier: MachineID,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        status: str | None, ###### add status types later\n",
    "    ) -> tuple[OpID, str, Machine]: ##### add machine type later\n",
    "        \"\"\"\n",
    "        registers an operation object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated operations\n",
    "        \n",
    "        obj: operation to register\n",
    "        machine_identifier: custom ID of the associated machine (user interface)\n",
    "        custom_identifier: custom identifier of the operation \n",
    "            (kept for consistency reasons, perhaps remove later)\n",
    "        name: assigned name the operation\n",
    "        status: for future features if status of operations is tracked\n",
    "        \n",
    "        outputs:\n",
    "        op_id: assigned operation ID\n",
    "        name: assigned name\n",
    "        machine: corresponding machine infrastructure object\n",
    "        \"\"\"\n",
    "        # obtain id\n",
    "        op_id = self._obtain_load_obj_id(load_type='op')\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'O_gen_{op_id}'\n",
    "        \n",
    "        # corresponding machine object on which operation is performed\n",
    "        machine = self._env.get_res_obj_by_prop(property='custom_id', val=machine_identifier)\n",
    "        \n",
    "        # new entry for operation data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'op_id': [op_id],\n",
    "                                'job_id': [obj.job_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'op': [obj],\n",
    "                                'name': [name],\n",
    "                                'machine': [machine],\n",
    "                                'status': status})\n",
    "        new_entry: DataFrame = new_entry.astype(self._op_prop)\n",
    "        self._op_db: DataFrame = pd.concat([self._op_db, new_entry], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Successfully registered operation with OpID {op_id} and name {name}\")\n",
    "        \n",
    "        ################# return machine object\n",
    "        return op_id, name, machine\n",
    "    \n",
    "    # special function for custom random generator of JSSP instances\n",
    "    def gen_job_pool_generic(\n",
    "        self,\n",
    "        mat_ProcTimes: npt.NDArray[np.uint16],\n",
    "        mat_JobMachID: npt.NDArray[np.uint16],\n",
    "        mat_OpID: npt.NDArray[np.uint16],\n",
    "    ) -> OrderedDict[JobID, Job]:\n",
    "        \"\"\"\n",
    "        function to build a integrated job pool if generic JxM JSSP instances are used\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "            \n",
    "        for job_id in range(len(mat_ProcTimes)):\n",
    "            temp1 = mat_ProcTimes[job_id].tolist()\n",
    "            temp2 = mat_JobMachID[job_id].tolist()\n",
    "            temp3 = mat_OpID[job_id].tolist()\n",
    "            JobInst = Job(\n",
    "                dispatcher=self,\n",
    "                proc_times=temp1,\n",
    "                machine_order=temp2,\n",
    "                operation_identifiers=temp3,\n",
    "                custom_identifier=None,\n",
    "                name=None,\n",
    "            )\n",
    "            ######### ADD TO JOB (bottom-up approach) #######################\n",
    "            ### jobs add themselves to job pool\n",
    "            self.job_pool[job_id] = JobInst\n",
    "            \n",
    "        return self.job_pool\n",
    "     \n",
    "    @property\n",
    "    def job_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered jobs in the environment\n",
    "        \"\"\"\n",
    "        return self._job_db\n",
    "    \n",
    "    @property\n",
    "    def op_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered operations in the environment\n",
    "        \"\"\"\n",
    "        return self._op_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_job_obj_by_prop(\n",
    "        self,\n",
    "        property: str, \n",
    "        val: EnvID | CustomID | str,\n",
    "        target_prop: str = 'job',\n",
    "    ) -> Job:\n",
    "        \"\"\"\n",
    "        obtain a job object from the dispatcher by its property and corresponding value\n",
    "        properties: job_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        temp1: Series = self._job_db.loc[self._job_db[property] == val, target_prop]\n",
    "        # check for empty search result, at least one result necessary\n",
    "        if len(temp1) == 0:\n",
    "            raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                            with the value '{val}'\")\n",
    "        # check for multiple entries with same prop-value pair\n",
    "        ########### PERHAPS CHANGE NECESSARY\n",
    "        ### multiple entries but only one returned --> prone to errors\n",
    "        elif len(temp1) > 1:\n",
    "            # warn user\n",
    "            logger.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                        same value '{val}' for the property '{property}'. \\\n",
    "                        Only the first entry is returned.\")\n",
    "        \n",
    "        return temp1.iat[0]\n",
    "    \n",
    "    def add_disposable_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        add job to the disposable ones\n",
    "        \"\"\"\n",
    "        self._disposable_jobs[job.job_id] = job\n",
    "    \n",
    "    @property\n",
    "    def disposable_jobs(self) -> dict[int, Job]:\n",
    "        return self._disposable_jobs\n",
    "    \n",
    "    ################# REWORK ##################\n",
    "    ### maybe add a corresponding property in the job DB\n",
    "    def get_disposable_jobs(\n",
    "        self,\n",
    "        job_set: OrderedDict,\n",
    "    ) -> tuple[list[JobID], list[Job]]:\n",
    "        \"\"\"\n",
    "        function needs to be reworked, jobs should report back information to a dispatcher instance\n",
    "        (bottom-up instead of top-down)\n",
    "        \"\"\"\n",
    "        #########################################\n",
    "        self._disposable_jobs_ID: list[int] = list()\n",
    "        self._disposable_jobs: list[Job] = list()\n",
    "        \n",
    "        for job_id, job in job_set.items():\n",
    "            if job.is_disposable:\n",
    "                self._disposable_jobs_ID.append(job_id)\n",
    "                self._disposable_jobs.append(job)\n",
    "                \n",
    "        return self._disposable_jobs_ID, self._disposable_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind simulation model approach\n",
    "*Model of Resource and Load*:\n",
    "- system consists of physical objects, also called infrastructure\n",
    "    - each element can be considered as encapsulated resource\n",
    "- stress can be put on each system by occupying resources, also called load\n",
    "    - definition of load depends on system type and modelling, e.g. production jobs for production systems or customers for cashiers in a shop\n",
    "- load objects are called ***load unit***\n",
    "\n",
    "*Guiding Priciples*:\n",
    "- **load objects** can only be spatially and temporally modified by **resources**\n",
    "    - whole routing logic is implemented in a collaborative manner between resources and load objects\n",
    "        - each load object puts itself in a associated queue\n",
    "        - **but no load object can change its state without a associated resource**\n",
    "    - load objects **contain the necessary information** which is essential for their further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "    Job: TypeAlias = 'Job'\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        job: Job,\n",
    "        proc_time: float,\n",
    "        machine_identifier: MachineID,\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        status: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        identifier: operation's ID\n",
    "        proc_times: operation's processing times\n",
    "        machine_identifier: ID of machine on which operation is processed\n",
    "        \"\"\"\n",
    "        # !!!!!!!!! perhaps processing times in future multiple entries depending on associated machine\n",
    "        # change of input format necessary, currently only one machine for each operation\n",
    "        # no groups, no differing processing times for different machines \n",
    "\n",
    "        # assert operation information\n",
    "        self._dispatcher = dispatcher\n",
    "        self._job = job\n",
    "        self._job_id = job.job_id\n",
    "                \n",
    "        # from dispatcher: op_id, name, target_machine\n",
    "        self._op_id, self.name, self.target_machine = self.dispatcher.register_operation(\n",
    "                                                        obj=self, machine_identifier=machine_identifier,\n",
    "                                                        custom_identifier=custom_identifier, name=name, \n",
    "                                                        status=status)\n",
    "            \n",
    "        # process information\n",
    "        self.proc_time = proc_time\n",
    "        ########### adding machine instances\n",
    "        ### perhaps adding machine sets if multiple machines possible (machine groups)\n",
    "        ### assignment of machine instance by dispatcher\n",
    "        #self.target_machine = machine_identifier\n",
    "    \n",
    "    @property   \n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def op_id(self) -> OpID:\n",
    "        return self._op_id\n",
    "    \n",
    "    @property\n",
    "    def job(self) -> Job:\n",
    "        return self._job\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> JobID:\n",
    "        return self._job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(object):\n",
    "    Job: TypeAlias = 'Job'\n",
    "    Dispatcher: TypeAlias = 'Dispatcher'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        proc_times: list[float],\n",
    "        machine_order: list[int],\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        status: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ############## ADD DESCRIPTION\n",
    "        \"\"\"\n",
    "        # intialize base class\n",
    "        super().__init__()\n",
    "        \n",
    "        ### BASIC INFORMATION ###\n",
    "        # assert job information\n",
    "        self.custom_identifier = custom_identifier\n",
    "        self.job_type: str = 'Job'\n",
    "        self._dispatcher = dispatcher\n",
    "        \n",
    "        ### register job instance\n",
    "        self._job_id, self.name = self.dispatcher.register_job(\n",
    "                                    obj=self, custom_identifier=self.custom_identifier,\n",
    "                                    name=name, status=status)\n",
    "        \n",
    "        ### OPERATIONS ##\n",
    "        self.operations = deque()\n",
    "        \n",
    "        for idx, op_proc_time in enumerate(proc_times):\n",
    "            Op = Operation(\n",
    "                dispatcher=self.dispatcher,\n",
    "                job=self,\n",
    "                proc_time=op_proc_time,\n",
    "                machine_identifier=machine_order[idx],\n",
    "            )\n",
    "            self.operations.append(Op)\n",
    "            \n",
    "        self.open_operations = self.operations.copy()\n",
    "        self.total_num_ops: int = len(self.operations)\n",
    "        self.num_finished_ops: int = 0\n",
    "        self._current_op: Operation = self.operations[0]\n",
    "        \n",
    "        ### STATE ###\n",
    "        # intra-process job state parameters\n",
    "        # job is being processed, maybe better naming in future\n",
    "        self.is_occupied: bool = False\n",
    "        # waiting state only when released\n",
    "        self.is_waiting: bool = False\n",
    "        # if lying on failed machine\n",
    "        self.is_failed: bool = False\n",
    "        \n",
    "        # intra-process time characteristics\n",
    "        self.time_occupied: float = 0.\n",
    "        self.time_waiting: float = 0.\n",
    "        self.time_failed: float = 0.\n",
    "        \n",
    "        # inter-process job state parameters\n",
    "        # first operation scheduled --> released job\n",
    "        self.is_released: bool = False\n",
    "        # job's next operation is disposable\n",
    "        # true for each new job, maybe reworked in future for jobs with\n",
    "        # a start date later than creation date\n",
    "        self.is_disposable: bool = True\n",
    "        # add job to disposable ones\n",
    "        ret = self.dispatcher.add_disposable_job(self)\n",
    "        # last operation ended --> finished job\n",
    "        self.is_finished: bool = False\n",
    "        \n",
    "        # inter-process time characteristics\n",
    "        # time of first operation starting point\n",
    "        self.time_entry: float = 0.\n",
    "        # time of last operation ending point\n",
    "        self.time_exit: float = 0.\n",
    "        \n",
    "        # current resource location\n",
    "        self.current_resource: object | None = None # specify type if class definition finished\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> JobID:\n",
    "        return self._job_id\n",
    "    \n",
    "    @property\n",
    "    def current_op(self) -> Operation:\n",
    "        \"\"\"\n",
    "        returns the current operation of the job\n",
    "        If a job is currently being processed its current operation is \n",
    "        not changed until this operation is finished.\n",
    "        \"\"\"\n",
    "        return self._current_op\n",
    "    \n",
    "    def get_next_operation(self) -> Operation:\n",
    "        \"\"\"\n",
    "        get next operation\n",
    "        \"\"\"\n",
    "        op = self.open_operations.popleft()\n",
    "        self._current_op = op\n",
    "        \n",
    "        return op"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Test simulation logic\n",
    "- first main goal: execution of a generic example in a simple job shop with single machines and FIFO order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDispatcher():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def add_dicts(self, job_dict, machine_dict):\n",
    "        self.job_dict = job_dict\n",
    "        self.machine_dict = machine_dict\n",
    "        \n",
    "    def get_machine_instance_by_id(self, ident):\n",
    "        return self.machine_dict[ident]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buffer_M_env_2'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"buffer_{MachInst.name()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMachine(sim.Component):\n",
    "    def __init__(self, machine_id, environment, *args, **kwargs):\n",
    "        super().__init__(env=environment, *args, **kwargs)\n",
    "        self.machine_id = machine_id\n",
    "        self.buffer = sim.Queue(env=environment)\n",
    "        \n",
    "    def process(self):\n",
    "        while True:\n",
    "            #yield self.passivate\n",
    "            if len(self.buffer) == 0:\n",
    "                yield self.passivate\n",
    "            print(\"Machine is getting job from queue\")\n",
    "            # theoretically request to dispatcher possible\n",
    "            job = self.buffer.pop()\n",
    "            pro_time = job.pro_time\n",
    "            print(f\"Machine {self} got Job with ID {job.job_id} and ProcTime {pro_time}\")\n",
    "            #print(f\"Time is {self.env.now()}\")\n",
    "            # processing\n",
    "            self.hold(job.pro_time)\n",
    "            job.activate()\n",
    "    \n",
    "        \n",
    "class TestJob(sim.Component):\n",
    "    def __init__(self, job_id, ops_proc_times, ops_machine_list, dispatcher, environment, machine_list, *args, **kwargs):\n",
    "        super().__init__(env=environment, *args, **kwargs)\n",
    "        self.job_id = job_id\n",
    "        self.ops_proc_times = ops_proc_times.copy()\n",
    "        self.ops_machine_list = ops_machine_list.copy()\n",
    "        self.dispatcher = dispatcher\n",
    "        self.ops_counter = 0\n",
    "        self.pro_time = 5\n",
    "        self.machine_list = machine_list.copy()\n",
    "        \n",
    "    def add_dicts(self, machine_dict):\n",
    "        #self.job_dict = job_dict\n",
    "        self.machine_dict = machine_dict\n",
    "        \n",
    "    def process(self):\n",
    "        print(f\"Job-ID {self.job_id} starts {env.now()}\")\n",
    "        while self.ops_counter < (len(self.ops_proc_times) - 1):\n",
    "            print(\"Get Next operation...\")\n",
    "            #self.pro_time = self.ops_proc_times[self.ops_counter]\n",
    "            machine_id = self.ops_machine_list[self.ops_counter]\n",
    "            print(f\"Operation with ProTime {self.pro_time} on machine {machine_id}\")\n",
    "            print(\"Obtain machine instance...\")\n",
    "            machine = self.dispatcher.get_machine_instance_by_id(machine_id)\n",
    "            #machine = self.machine_dict[machine_id]\n",
    "            #machine = self.machine_list.pop(0)\n",
    "            print(f\"Machine instance is: {machine} and ispassive {machine.ispassive()}\")\n",
    "            \n",
    "            # now enter buffer\n",
    "            self.enter(machine.buffer)\n",
    "            # activate machine if passive\n",
    "            #if machine.ispassive():\n",
    "            machine.activate()\n",
    "            yield self.passivate()\n",
    "            \n",
    "            \n",
    "            self.ops_counter += 1\n",
    "            print(f\"Job-ID {self.job_id} ends {self.env.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dispatcher = TestDispatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ProcTimes = mat_ProcTimes.copy()\n",
    "#test_ProcTimes = np.expand_dims(test_ProcTimes, 0)\n",
    "\n",
    "test_JobMachID = mat_JobMachID.copy()\n",
    "#test_JobMachID = np.expand_dims(test_JobMachID, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMachine(sim.Component):\n",
    "    def __init__(self, machine_id, env, *args, **kwargs):\n",
    "        super().__init__(env=env, *args, **kwargs)\n",
    "        self.machine_id = machine_id\n",
    "        self.buffer = sim.Queue(env=env)\n",
    "    \n",
    "    def process(self):\n",
    "        while True:\n",
    "            if len(self.buffer) == 0:\n",
    "                yield self.passivate()\n",
    "            job = self.buffer.pop()\n",
    "            proc_time = job.proc_time\n",
    "            print(f\"[START] job ID {job.job_id} at {self.env.now()} on machine ID {self.machine_id} with proc time {job.proc_time}\")\n",
    "            yield self.hold(job.proc_time)\n",
    "            print(f\"[END] job ID {job.job_id} at {self.env.now()} on machine ID {self.machine_id}\")\n",
    "            job.activate()\n",
    "\n",
    "class TestJob(sim.Component):\n",
    "    def __init__(self, ident, machine_order, operation_procs, env, dispatcher, *args, **kwargs):\n",
    "        super().__init__(env=env, *args, **kwargs)\n",
    "        #self.machine_id = machine_id\n",
    "        self.machine_list = machine_list.copy()\n",
    "        self.proc_time = None\n",
    "        self.counter = 0\n",
    "        self.operation_procs = operation_procs.copy()\n",
    "        #self.machine_dict = machine_dict.copy()\n",
    "        #self.dict_keys = list(machine_dict.keys())\n",
    "        self.machine_order = machine_order.copy()\n",
    "        self.job_id = ident\n",
    "        self.dispatcher = dispatcher\n",
    "        \n",
    "    def process(self):\n",
    "        while len(self.operation_procs) != 0:\n",
    "            #print(f\"Job-ID {self.job_id} starts {env.now()}\")\n",
    "            print(f\"Job-ID {self.job_id} \\t Operation with ID {self.counter}\")\n",
    "            self.proc_time = self.operation_procs.pop(0)\n",
    "            #machine = machine_list.pop(0)\n",
    "            #machine = self.machine_dict[self.dict_keys[self.counter]]\n",
    "            machine_id = self.machine_order.pop(0)\n",
    "            machine = self.dispatcher.get_machine_instance_by_id(machine_id)\n",
    "            #print(f\"Machine instance is {machine}\")\n",
    "            #print(f\"Machine instance is: {machine} and ispassive {machine.ispassive()}\")\n",
    "            self.enter(machine.buffer)\n",
    "            if machine.ispassive():\n",
    "                machine.activate()\n",
    "            yield self.passivate()\n",
    "            #print(f\"[END] Time now Job-ID {self.job_id} is {self.env.now()}\")\n",
    "            self.counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = sim.Environment(trace=False)\n",
    "machine_db = dict()\n",
    "job_db = dict()\n",
    "machine_list_inst = list()\n",
    "\n",
    "for machine_id in np.unique(mat_JobMachID):\n",
    "    machine = TestMachine(machine_id=machine_id.item(), env=env)\n",
    "    machine_db[machine_id.item()] = machine\n",
    "    machine_list_inst.append(machine)\n",
    "\n",
    "for job_id, (proc_list, machine_list) in enumerate(zip(test_ProcTimes, test_JobMachID)):\n",
    "    job = TestJob(ident=job_id, machine_order=machine_list.tolist(), operation_procs=proc_list.tolist(), \n",
    "                  dispatcher=test_dispatcher, env=env)\n",
    "    #job.add_dicts(machine_db)\n",
    "    job_db[job_id] = job\n",
    "\"\"\"\n",
    "proc_list = [10,8,6]\n",
    "machine_list = [0,1,2]\n",
    "job_id = 0\n",
    "job = TestJob(ident=job_id, machine_dict=machine_db, operation_procs=proc_list,\n",
    "                  dispatcher=test_dispatcher, env=env)\n",
    "\"\"\"\n",
    "   \n",
    "test_dispatcher.add_dicts(job_db, machine_db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
