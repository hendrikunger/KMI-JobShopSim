{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Table of contents\n",
    "- [Random Generator](#randomgenerator)\n",
    "- [Environment](#environment)\n",
    "- [Infrastructure Object](#infrastructureobject)\n",
    "- [Processing Station](#processingstation)\n",
    "- [Machine](#machine)\n",
    "- [Buffer](#buffer)\n",
    "- [Source](#source)\n",
    "- [Dispatcher](#dispatcher)\n",
    "- [Operation](#operation)\n",
    "- [Job](#job)\n",
    "- [Logic Test](#logic_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do:\n",
    "- [ ] add machine groups (parallel machines)\n",
    "    - logic behind communicating machine groups\n",
    "    - registration of machines in groups\n",
    "- [ ] additional 'Production Areas' necessary because each of these areas can contain multiple station groups\n",
    "    - Routing: production area --> station group --> processing station\n",
    "    - Example KSG: drilling range --> 4 station groups --> different number of processing stations\n",
    "- [ ] add setup times\n",
    "- [ ] machine groups: add different allocation rules\n",
    "    - currently: ``Random, Lowest Utilisation, Lowest WIP Time, Lowest WIP number jobs``\n",
    "- [ ] capacity deadlocks between buffers and machines\n",
    "    - [ ] resolve necessary! otherwise no information about blockages\n",
    "    - [x] ~~remove deadlocks by counting the associated machines and comparing the counter to the buffer's capacity~~ (**no capacities > 1 for processing stations**)\n",
    "    - **problem persists: if predecessor systems produce faster than the target processing stations, they fill the buffer until it is filled --> result == deadlock again if buffer is shared between processing station**\n",
    "    - shared buffers: if only used for machine groups --> no problem because there are no circles between these machines\n",
    "    - [ ] look into problems where processing stations have a capacity greater than 1\n",
    "- [ ] add feasibility check\n",
    "    - since agents can choose actions which are not feasible a feasiblity check is necessary\n",
    "    - describe learning flow if a non-feasible action was chosen\n",
    "- [ ] add logistic objective values:\n",
    "    - [x] ~~WIP~~\n",
    "    - [x] ~~lead time~~\n",
    "    - [x] ~~utilisation~~\n",
    "    - [ ] rank\n",
    "- [ ] add Gantt chart visualisation for debugging\n",
    "    - [x] ~~after simulation run~~\n",
    "    - [ ] during simulation run\n",
    "- [ ] logic/ interface for generation of multiple jobs\n",
    "    - using dispatcher or source?\n",
    "    - interface: design + properties\n",
    "- [ ] add priority rules\n",
    "    - currently: ``FIFO, LIFO, SPT, LPT``\n",
    "- [ ] tracking disjunctive graph model\n",
    "    - **[QUESTION] Working with parallel machines?**\n",
    "- [ ] initialisation of the model with pre-defined state information\n",
    "    - [x] ~~build base by implementing a pre-process method (initialisation) before the simulation starts~~\n",
    "    - [x] ~~initialise/create objects with pre-defined states~~\n",
    "- [ ] add machine breakdowns\n",
    "    - vide **[Check Interruption](#MachineBreakdownTest)**\n",
    "\n",
    "- [x] ~~description of process logic for generation and entry of jobs~~\n",
    "- [x] ~~add setting of job/machine states in machine logic~~\n",
    "    - using state update function which combine all necessary state update calls\n",
    "- [x] ~~add status info to job DB? (waiting, processing, ...) (disposable = waiting?)~~\n",
    "    - advantage:\n",
    "        - one central DB with all information, no cluttered information\n",
    "        - simple filtering for jobs by current status incl. disposable jobs\n",
    "- [x] ~~add sources and sinks~~\n",
    "    - [x] source: generates new job with given intervals\n",
    "    - [x] sink: destroys jobs and finalises data collection\n",
    "- [x] ~~add physical buffers~~\n",
    "\n",
    "- [x] ~~add bar charts for time components~~\n",
    "- [x] ~~add monitor class to unitise data collection~~\n",
    "- [x] ~~I/O functions for elements~~\n",
    "\n",
    "- [ ] self-marking as disposable by jobs\n",
    "    - ==*check if still necessary*==\n",
    "    - includes demarking\n",
    "    - currently only addition implemented\n",
    "- [x] ~~register job object in dispatcher~~\n",
    "- [x] ~~register operations in dispatcher~~\n",
    "- [x] ~~add uniqueness check for custom IDs in resource objects (only interface to user)~~\n",
    "- [x] ~~operations list of jobs as deque~~\n",
    "- [x] ~~add generic infrastructure class from which infrastructure objects are derived~~\n",
    "- [x] ~~implement routing logic in objects~~\n",
    "- [x] ~~add operation starting and end points~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind simulation model approach\n",
    "*Model of Resource and Load*:\n",
    "- system consists of physical objects, also called infrastructure\n",
    "    - each element can be considered as encapsulated resource\n",
    "- stress can be put on each system by occupying resources, also called load\n",
    "    - definition of load depends on system type and modelling, e.g. production jobs for production systems or customers for cashiers in a shop\n",
    "- load objects are called ***load unit***\n",
    "\n",
    "*Guiding Priciples*:\n",
    "- **load objects** can only be spatially and temporally modified by **resources**\n",
    "    - only resource objects can put load objects on other resources and change their state\n",
    "    - load objects **contain the necessary information** which is essential for their further processing\n",
    "\n",
    "################\n",
    "\n",
    "Logic of ``Lang et al.: Modeling Production Scheduling Problems as Reinforcement Learning Environments based on Discrete-Event Simulation and OpenAI Gym``\n",
    "- whole routing logic is implemented in a collaborative manner between resources and load objects\n",
    "    - each load object puts itself in a associated queue\n",
    "    - therefore load objects can change their *states* and *location* by theirown\n",
    "- **violates resource-load model: no load object can change its state without a associated resource**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from numpy.random._generator import Generator\n",
    "import random\n",
    "import simpy\n",
    "import salabim as sim\n",
    "from salabim import Queue, State\n",
    "from typing import TypeAlias, Iterable, Iterator, Any\n",
    "from collections import OrderedDict, deque\n",
    "from operator import attrgetter\n",
    "from functools import lru_cache\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import plotly.express as px\n",
    "from plotly.graph_objs._figure import Figure\n",
    "\n",
    "sim.yieldless(False)\n",
    "\n",
    "# type aliases\n",
    "NPRandomGenerator: TypeAlias = Generator\n",
    "SimPyEnv: TypeAlias = simpy.core.Environment\n",
    "SalabimEnv: TypeAlias = sim.Environment\n",
    "EnvID: TypeAlias = int\n",
    "SubsystemType: TypeAlias = 'StationGroup | InfrastructureObject'\n",
    "#JobID: TypeAlias = int\n",
    "#OpID: TypeAlias = int\n",
    "ObjectID: TypeAlias = int\n",
    "### [CHANGE] Replace MachineID as CustomID\n",
    "MachineID: TypeAlias = int | str\n",
    "CustomID: TypeAlias = int | str\n",
    "#InfstructObj: TypeAlias = object # better naming in future\n",
    "PlotlyFigure: TypeAlias = Figure\n",
    "\n",
    "# forward reference, referenced before assignment\n",
    "#Job: TypeAlias = 'Job'\n",
    "#Dispatcher: TypeAlias = 'Dispatcher'\n",
    "\n",
    "# logging\n",
    "# IPython compatibility\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "LOGGING_LEVEL = 'DEBUG'\n",
    "LOGGING_LEVEL_ENV = 'ERROR'\n",
    "LOGGING_LEVEL_DISPATCHER = 'DEBUG'\n",
    "LOGGING_LEVEL_SOURCES = 'ERROR'\n",
    "LOGGING_LEVEL_SINKS = 'ERROR'\n",
    "LOGGING_LEVEL_PRODSTATIONS = 'ERROR'\n",
    "LOGGING_LEVEL_JOBS = 'ERROR'\n",
    "LOGGING_LEVEL_OPERATIONS = 'ERROR'\n",
    "LOGGING_LEVEL_BUFFERS = 'ERROR'\n",
    "LOGGING_LEVEL_MONITORS = 'ERROR'\n",
    "\n",
    "\n",
    "logger = logging.getLogger('base')\n",
    "logger.setLevel(LOGGING_LEVEL)\n",
    "logger_env = logging.getLogger('env')\n",
    "logger_env.setLevel(LOGGING_LEVEL_ENV)\n",
    "logger_dispatcher = logging.getLogger('dispatcher')\n",
    "logger_dispatcher.setLevel(LOGGING_LEVEL_DISPATCHER)\n",
    "logger_sources = logging.getLogger('sources')\n",
    "logger_sources.setLevel(LOGGING_LEVEL_SOURCES)\n",
    "logger_sinks = logging.getLogger('sinks')\n",
    "logger_sinks.setLevel(LOGGING_LEVEL_SINKS)\n",
    "logger_prodStations = logging.getLogger('prodStations')\n",
    "logger_prodStations.setLevel(LOGGING_LEVEL_PRODSTATIONS)\n",
    "logger_buffers = logging.getLogger('buffers')\n",
    "logger_buffers.setLevel(LOGGING_LEVEL_BUFFERS)\n",
    "logger_monitors = logging.getLogger('monitors')\n",
    "logger_monitors.setLevel(LOGGING_LEVEL_MONITORS)\n",
    "\n",
    "logger_jobs = logging.getLogger('jobs')\n",
    "logger_jobs.setLevel(LOGGING_LEVEL_JOBS)\n",
    "logger_operations = logging.getLogger('operations')\n",
    "logger_operations.setLevel(LOGGING_LEVEL_OPERATIONS)\n",
    "\n",
    "\n",
    "\n",
    "INF = float('inf')\n",
    "FAIL_DELAY = 20 # time after a store request is failed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='randomgenerator'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomJobGenerator(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        seed: int = 42,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        seed: seed value for random number generator\n",
    "        \"\"\"\n",
    "        self._np_rnd_gen: NPRandomGenerator = np.random.default_rng(seed=seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "    def gen_rnd_JSSP_inst(\n",
    "        self,\n",
    "        n_jobs: int,\n",
    "        n_machines: int,\n",
    "    ) -> tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "        \"\"\"\n",
    "        Generates random job shop instance with given number of and machines\n",
    "        - each job on all machines\n",
    "        - max processing time = 9\n",
    "        \n",
    "        Output:\n",
    "        n_jobs: number of jobs\n",
    "        n_machines: number of machines\n",
    "        n_tasks: number of tasks\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "        # generate random process time matrix shape=(n_jobs, n_machines)\n",
    "        mat_ProcTimes = self._np_rnd_gen.integers(1, 10, size=(n_jobs,n_machines), dtype=np.uint16)\n",
    "        \n",
    "        # generate randomly shuffled job machine combinations\n",
    "        # machine IDs from 1 to n_machines\n",
    "        temp = np.arange(0, n_machines, step=1, dtype=np.uint16)\n",
    "        temp = np.expand_dims(temp, axis=0)\n",
    "        # repeat dummy line until number n_jobs is reached\n",
    "        temp = np.repeat(temp, n_jobs, axis=0)\n",
    "        # randomly permute the machine indices job-wise\n",
    "        mat_JobMachID = self._np_rnd_gen.permuted(temp, axis=1)\n",
    "        \n",
    "        # generate operation ID matrix\n",
    "        # not mandatory because operations are registered in the environment's dispatcher\n",
    "        n_ops = n_jobs * n_machines\n",
    "        temp2 = np.arange(0, (n_ops), step=1, dtype=np.uint16)\n",
    "        mat_OpID = temp2.reshape(n_jobs, -1)\n",
    "        \n",
    "        return mat_ProcTimes, mat_JobMachID\n",
    "    \n",
    "    def gen_rnd_job(\n",
    "        self,\n",
    "        n_machines: int,\n",
    "    ) -> tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "        \"\"\"generates random job with machine IDs\n",
    "        [OUTDATED] Should be replaced by the more generic 'gen_rnd_job_by_ids' method\n",
    "        which uses any IDs provided as NumPy array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_machines : int\n",
    "            _description_\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        # generate random process time matrix shape=(n_machines)\n",
    "        mat_ProcTimes = self._np_rnd_gen.integers(1, 10, size=n_machines, dtype=np.uint16)\n",
    "        \n",
    "        # generate randomly shuffled job machine combinations\n",
    "        # machine IDs from 1 to n_machines\n",
    "        temp = np.arange(0, n_machines, step=1, dtype=np.uint16)\n",
    "        # randomly permute the machine indices job-wise\n",
    "        mat_JobMachID = self._np_rnd_gen.permuted(temp)\n",
    "        \n",
    "        return mat_ProcTimes, mat_JobMachID\n",
    "    \n",
    "    def gen_rnd_job_by_ids(\n",
    "        self,\n",
    "        ids: list[CustomID],\n",
    "        min_proc_time: int = 1,\n",
    "        max_proc_time: int = 10,\n",
    "    ) -> tuple[list[int], list[CustomID]]:\n",
    "        \"\"\"Generic function to generate processing times and execution flow of a job object\n",
    "        - permute the given NumPy array of IDs with shape(1,n) along the columns\n",
    "        - generate random processing times in the range of ``min_proc_time`` to ``max_proc_time``\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ids : npt.NDArray[np.uint16]\n",
    "            _description_\n",
    "        min_proc_time : int, optional\n",
    "            _description_, by default 1\n",
    "        max_proc_time : int, optional\n",
    "            _description_, by default 10\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        n_objects: int = len(ids)\n",
    "        \n",
    "        # generate random process time matrix shape=(n_objects)\n",
    "        #mat_ProcTimes = random.choices(range(min_proc_time, (max_proc_time+1)), k=n_objects)\n",
    "        \n",
    "        mat_ProcTimes = self._np_rnd_gen.integers(\n",
    "                                            min_proc_time, \n",
    "                                            max_proc_time, \n",
    "                                            size=n_objects, \n",
    "                                            dtype=np.uint16).tolist()\n",
    "        \n",
    "        \n",
    "        # randomly permute the object indices\n",
    "        mat_JobMachID = self._np_rnd_gen.permuted(ids).tolist()\n",
    "        #mat_JobMachID = ids.copy()\n",
    "        #random.shuffle(mat_JobMachID)\n",
    "        \n",
    "        return mat_ProcTimes, mat_JobMachID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_generator = RandomJobGenerator(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 1, 9], ['cust01', 'cust03', 'cust02'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_generator.gen_rnd_job_by_ids(ids=['cust01', 'cust02', 'cust03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_ProcTimes, mat_JobMachID = job_generator.gen_rnd_JSSP_inst(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 1],\n",
       "       [8, 5, 1]], dtype=uint16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ProcTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [2, 0, 1]], dtype=uint16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_JobMachID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brainstorming of ways to import machine names and IDs\n",
    "*Case 1: only names are given*\n",
    "- read machine names and assert IDs to them\n",
    "- build data structure with name and ID bundled (maybe as property of a machine class)\n",
    "\n",
    "*Case 2: IDs are given*\n",
    "- only building data structure with name and ID bundled\n",
    "\n",
    "*Data Structure:*\n",
    "- if only mapping of two pairs in each direction (lookup ID or lookup machine name)\n",
    "    - bi-directional dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for resource objects:**\n",
    "- CustomID may not be of type 'None' because the custom identifiers are the only interface to the end user (EnvID are solely handled inernally)\n",
    "- add checking for uniqueness of custom identifiers necessary, else the mapping of different objects could be ambiguous\n",
    "- jobs and operations can use ambiguous custom IDs --> custom IDs can still be None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dedicated environment class with information on associated resources and jobs\n",
    "- maybe add possibility of using subsystems (bundle of resources with unique identifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='environment'></a>\n",
    "**Salabim Env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationEnvironment(sim.Environment):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \"\"\"\n",
    "        # resource database as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'env_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_db = self._res_db.set_index('env_id')\n",
    "        self._res_lookup_props: set[str] = set(['env_id', 'custom_id', 'name'])\n",
    "        \n",
    "        # station group database as simple Pandas DataFrame\n",
    "        self._station_group_prop: dict[str, type] = {\n",
    "            'station_group_id': int,\n",
    "            'custom_group_id': object,\n",
    "            'station_group_name': str,\n",
    "            'station_group': object,\n",
    "        }\n",
    "        self._station_group_db: DataFrame = pd.DataFrame(columns=list(self._station_group_prop.keys()))\n",
    "        self._station_group_db = self._station_group_db.astype(self._station_group_prop)\n",
    "        self._station_group_db = self._station_group_db.set_index('station_group_id')\n",
    "        self._station_group_lookup_props: set[str] = set(['station_group_id', 'custom_group_id', 'station_group_name'])\n",
    "        # station group identifiers\n",
    "        self._station_group_counter: ObjectID = 0\n",
    "        self._station_groups_custom_identifiers: set[CustomID] = set()\n",
    "        \n",
    "        # env identifiers\n",
    "        self._id_counter: EnvID = 0\n",
    "        self._res_custom_identifiers: set[CustomID] = set()\n",
    "        \"\"\"\n",
    "        \n",
    "        # [RESOURCE] infrastructure manager\n",
    "        self._infstruct_mgr_registered: bool = False\n",
    "        self._infstruct_mgr: InfrastructureManager | None = None\n",
    "        \n",
    "        # [LOAD] job dispatcher\n",
    "        self._dispatcher_registered: bool = False\n",
    "        self._dispatcher: Dispatcher | None = None\n",
    "        \n",
    "        \"\"\"\n",
    "        # sink: pool of sinks possible to allow multiple sinks in one environment\n",
    "        # [PERHAPS CHANGED LATER] \n",
    "        # currently only one sink out of the pool is chosen because jobs do not contain \n",
    "        # information about a target sink\n",
    "        self._sink_registered: bool = False\n",
    "        self._sinks: set[Sink] = set()\n",
    "        \n",
    "        # counter for processing stations (machines, assembly, etc.)\n",
    "        self.num_proc_stations: int = 0\n",
    "        \"\"\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \"\"\"\n",
    "    def _obtain_env_id(self) -> EnvID:\n",
    "        Simple counter function for managing environment IDs\n",
    "        # assign id and set counter up\n",
    "        env_id = self._id_counter\n",
    "        self._id_counter += 1\n",
    "        \n",
    "        return env_id\n",
    "    \n",
    "    def _obtain_station_group_id(self) -> ObjectID:\n",
    "        Simple counter function for managing station group IDs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ObjectID\n",
    "            unique station group ID\n",
    "        \n",
    "        st_group_id = self._station_group_counter\n",
    "        self._station_group_counter += 1\n",
    "        \n",
    "        return st_group_id\n",
    "    \"\"\"\n",
    "    \n",
    "    def register_infrastructure_manager(\n",
    "        self,\n",
    "        infstruct_mgr: InfrastructureManager,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        if not self._infstruct_mgr_registered and isinstance(infstruct_mgr, InfrastructureManager):\n",
    "            self._infstruct_mgr = infstruct_mgr\n",
    "            self._infstruct_mgr_registered = True\n",
    "            logger_env.info(f\"Successfully registered Infrastructure Manager in Env = {self.name()}\")\n",
    "        elif not isinstance(infstruct_mgr, InfrastructureManager):\n",
    "            raise TypeError(f\"The object must be of type >>InfrastructureManager<< but is type >>{type(infstruct_mgr)}<<\")\n",
    "        else:\n",
    "            raise AssertionError(\"There is already a registered Infrastructure Manager instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def register_dispatcher(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        if not self._dispatcher_registered and isinstance(dispatcher, Dispatcher):\n",
    "            self._dispatcher = dispatcher\n",
    "            self._dispatcher_registered = True\n",
    "            logger_env.info(f\"Successfully registered Dispatcher in Env = {self.name()}\")\n",
    "        elif not isinstance(dispatcher, Dispatcher):\n",
    "            raise TypeError(f\"The object must be of type >>Dispatcher<< but is type >>{type(dispatcher)}<<\")\n",
    "        else:\n",
    "            raise AssertionError(\"There is already a registered Dispatcher instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def infstruct_mgr(self) -> InfrastructureManager:\n",
    "        \"\"\"obtain the current registered Infrastructure Manager instance of the environment\"\"\"\n",
    "        if self._infstruct_mgr is None:\n",
    "            raise ValueError(\"No Infrastructure Manager instance registered.\")\n",
    "        else:\n",
    "            return self._infstruct_mgr\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        \"\"\"obtain the current registered Dispatcher instance of the environment\"\"\"\n",
    "        if self._dispatcher is None:\n",
    "            raise ValueError(\"No Dipsatcher instance registered.\")\n",
    "        else:\n",
    "            return self._dispatcher\n",
    "    \"\"\"\n",
    "    def register_resource(\n",
    "        self,\n",
    "        obj: InfrastructureObject,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) ->  tuple[EnvID, str]:\n",
    "        \n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        obj: env resource = instance of a subclass of InfrastructureObject\n",
    "        custom_identifier: user defined identifier\n",
    "        name: custom name of the object, \\\n",
    "            default: None\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in self._res_custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided already exists, \\\n",
    "                            but has to be unique.\")\n",
    "        else:\n",
    "            self._res_custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain env_id\n",
    "        env_id = self._obtain_env_id()\n",
    "        \n",
    "        # register sinks\n",
    "        if isinstance(obj, Sink):\n",
    "            if not self._sink_registered:\n",
    "                self._sink_registered = True\n",
    "            self._sinks.add(obj)\n",
    "        \n",
    "        # count number of machines\n",
    "        if isinstance(obj, ProcessingStation):\n",
    "            self.num_proc_stations += 1\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'{type(obj).__name__}_env_{env_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'env_id': [env_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'resource': [obj],\n",
    "                                'name': [name],\n",
    "                                'res_type': [obj.res_type],\n",
    "                                'state': [state]})\n",
    "        new_entry = new_entry.astype(self._infstruct_prop)\n",
    "        new_entry = new_entry.set_index('env_id')\n",
    "        self._res_db = pd.concat([self._res_db, new_entry])\n",
    "        \n",
    "        logger_env.info(f\"Successfully registered object with EnvID {env_id} and name {name}\")\n",
    "        \n",
    "        return env_id, name\n",
    "\n",
    "    def register_station_group(\n",
    "        self,\n",
    "        processing_station: ProcessingStation,\n",
    "        custom_group_id: CustomID | None,\n",
    "        station_group_name: str | None,\n",
    "    ) -> tuple[ObjectID, StationGroup]:\n",
    "        registers an processing station in the corresponding station group\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        processing_station : ProcessingStation\n",
    "            _description_\n",
    "        station_group_identifier : CustomID | None\n",
    "            _description_\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        StationGroup\n",
    "            _description_\n",
    "        \n",
    "        # type security\n",
    "        # object to be registered\n",
    "        if not isinstance(processing_station, ProcessingStation):\n",
    "            raise TypeError(f\"{processing_station} is not of type >>ProcessingStation<<, but it has to be.\")\n",
    "        \n",
    "        # custom identifier\n",
    "        if custom_group_id is None:\n",
    "            # assign station group name by the corresponding processing station\n",
    "            custom_group_id = f'station_group_{processing_station.name()}'\n",
    "        elif not isinstance(custom_group_id, (str, int)):\n",
    "            raise TypeError(\"Provided custom identifier for station group must be of type STR or INT\")\n",
    "        \n",
    "        # create check value\n",
    "        if isinstance(custom_group_id, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_group_id.lower()\n",
    "        else:\n",
    "            check_val = custom_group_id\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        if check_val in self._station_groups_custom_identifiers:\n",
    "            # already exists, add to this station group\n",
    "            # lookup in station group DB\n",
    "            station_group = self.get_station_group_by_prop(\n",
    "                                                    val=custom_group_id, \n",
    "                                                    property='custom_group_id')\n",
    "            station_group_id = station_group.group_id\n",
    "            # add proc station to associated ones\n",
    "            station_group.add_processing_station(processing_station=processing_station)\n",
    "        else:\n",
    "            self._station_groups_custom_identifiers.add(check_val)\n",
    "        \n",
    "            ### [CREATION+ASSIGN] station group does not exist\n",
    "            # obtain station group ID\n",
    "            station_group_id = self._obtain_station_group_id()\n",
    "            # create new station group\n",
    "            station_group = StationGroup(\n",
    "                                        env=self, group_id=station_group_id, \n",
    "                                        custom_identifier=custom_group_id, \n",
    "                                        name=station_group_name)\n",
    "            # add proc station to associated ones\n",
    "            station_group.add_processing_station(processing_station=processing_station)\n",
    "            \n",
    "            # new entry for station group database\n",
    "            new_entry: DataFrame = pd.DataFrame({\n",
    "                                    'station_group_id': [station_group_id],\n",
    "                                    'custom_group_id': [custom_group_id],\n",
    "                                    'station_group_name': [station_group_name],\n",
    "                                    'station_group': [station_group]})\n",
    "            new_entry = new_entry.astype(self._station_group_prop)\n",
    "            new_entry = new_entry.set_index('station_group_id')\n",
    "            self._station_group_db = pd.concat([self._station_group_db, new_entry])\n",
    "            \n",
    "        logger_env.info(f\"Successfully registered processing station {processing_station} \\\n",
    "            with station group {station_group}\")\n",
    "            \n",
    "        return station_group_id, station_group\n",
    "    \n",
    "    \n",
    "    def get_station_group_by_prop(\n",
    "        self,\n",
    "        val: CustomID | str,\n",
    "        property: str = 'station_group_id',\n",
    "        target_prop: str = 'station_group',\n",
    "    ) -> StationGroup:\n",
    "        \n",
    "        obtain a station group by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._station_group_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._station_group_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'station_group_id':\n",
    "            # direct indexing for ID property; env_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: StationGroup = self._station_group_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._station_group_db.loc[self._station_group_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_env.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def sinks(self) -> set[Sink]:\n",
    "        registered sinks\n",
    "        return self._sinks\n",
    "    \n",
    "    def update_res_state(\n",
    "        self,\n",
    "        obj: InfrastructureObject,\n",
    "        state: str,\n",
    "        reset_temp: bool = False,\n",
    "    ) -> None:\n",
    "        method to update the state of a resource object in the resource database\n",
    "        # update resource database\n",
    "        logger_env.debug(f\"Set state of {obj} to {state}\")\n",
    "        # update state tracking of the job instance\n",
    "        logger_env.debug(f\"[Object:{self}]: Monitor is {obj.stat_monitor}\")\n",
    "        \n",
    "        # check if 'TEMP' state should be reset\n",
    "        if reset_temp:\n",
    "            # special reset method, calls state setting to previous state\n",
    "            obj.stat_monitor.reset_temp_state()\n",
    "            state = obj.stat_monitor.state_current\n",
    "        else:\n",
    "            obj.stat_monitor.set_state(state=state)\n",
    "        \n",
    "        self._res_db.at[obj.env_id, 'state'] = state\n",
    "        logger_env.debug(f\"Executed state setting of {obj} to {state}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        obtain a current overview of registered objects in the environment\n",
    "        return self._res_db\n",
    "    \n",
    "    @property\n",
    "    def station_group_db(self) -> DataFrame:\n",
    "        return self._station_group_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        val: EnvID | CustomID | str,\n",
    "        property: str = 'env_id',\n",
    "        target_prop: str = 'resource',\n",
    "    ) -> InfrastructureObject:\n",
    "        \n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: env_id, custom_id, name\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'env_id':\n",
    "            # direct indexing for ID property; env_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: InfrastructureObject = self._res_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._res_db.loc[self._res_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_env.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    \"\"\"\n",
    "        \n",
    "    def check_integrity(self) -> None:\n",
    "        \"\"\"\n",
    "        method to evaluate if certain criteria for the simulation run are satisfied\n",
    "        checks for:\n",
    "        - registered dispatcher (min: 1, max: 1)\n",
    "        - registered sink (min: 1, max: INF)\n",
    "        \"\"\"\n",
    "        if not self._infstruct_mgr_registered:\n",
    "            raise ValueError(\"No Infrastructure Manager instance registered.\")\n",
    "        elif not self._dispatcher_registered:\n",
    "            raise ValueError(\"No Dispatcher instance registered.\")\n",
    "        elif not self._infstruct_mgr.sink_registered:\n",
    "            raise ValueError(\"No Sink instance registered.\")\n",
    "        \n",
    "        logger_env.info(f\"Integrity check for Environment {self.name()} successful.\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \"\"\"\n",
    "    def res_objs_temp_state(\n",
    "        self,\n",
    "        res_objs: Iterable[InfrastructureObject],\n",
    "        reset_temp: bool,\n",
    "    ) -> None:\n",
    "        Sets/resets given resource objects from the 'TEMP' state\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        res_objs : tuple[InfrastructureObject]\n",
    "            objects for which the TEMP state should be changed\n",
    "        set_temp : bool\n",
    "            indicates if the temp state should be set or reset\n",
    "        \n",
    "        for obj in res_objs:\n",
    "            self.update_res_state(obj=obj, state='TEMP', reset_temp=reset_temp)\n",
    "            # calculate KPIs if 'TEMP' state is set\n",
    "            if not reset_temp:\n",
    "                obj.stat_monitor.calc_KPI()\n",
    "        \n",
    "        return None\n",
    "    \"\"\"\n",
    "    \n",
    "    def finalise_sim(self) -> None:\n",
    "        \"\"\"\n",
    "        Function which should be executed at the end of the simulation.\n",
    "        Can be used for finalising data collection, other related tasks or further processing pipelines\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # set end state for each resource object to calculate the right time amounts\n",
    "        for res_obj in self._res_db['resource']:\n",
    "            res_obj.finalise()\n",
    "        logger_env.info(\"Finalisation of the state information for all resource objects successful.\")\n",
    "        \"\"\"\n",
    "        \n",
    "        # infrastructure manager instance\n",
    "        self._infstruct_mgr.finalise()\n",
    "        \n",
    "        # dispatcher instance\n",
    "        self._dispatcher.finalise()\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Infrastructure Manager**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfrastructureManager(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        # init base class, even if not available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # [COMMON]\n",
    "        self._env = env\n",
    "        self._env.register_infrastructure_manager(infstruct_mgr=self)\n",
    "        # subsystem types\n",
    "        self._subsystem_types: set[str] = set([\n",
    "            'ProductionArea',\n",
    "            'StationGroup',\n",
    "            'Resource',\n",
    "        ])\n",
    "        \n",
    "        # [PRODUCTION AREAS] database as simple Pandas DataFrame\n",
    "        self._prod_area_prop: dict[str, type] = {\n",
    "            'prod_area_id': int,\n",
    "            'custom_id': object,\n",
    "            'name': str,\n",
    "            'prod_area': object,\n",
    "        }\n",
    "        self._prod_area_db: DataFrame = pd.DataFrame(columns=list(self._prod_area_prop.keys()))\n",
    "        self._prod_area_db = self._prod_area_db.astype(self._prod_area_prop)\n",
    "        self._prod_area_db = self._prod_area_db.set_index('prod_area_id')\n",
    "        self._prod_area_lookup_props: set[str] = set(['prod_area_id', 'custom_id', 'name'])\n",
    "        # [PRODUCTION AREAS] identifiers\n",
    "        self._prod_area_counter: ObjectID = 0\n",
    "        self._prod_area_custom_identifiers: set[CustomID] = set()\n",
    "        \n",
    "        # [STATION GROUPS] database as simple Pandas DataFrame\n",
    "        self._station_group_prop: dict[str, type] = {\n",
    "            'station_group_id': int,\n",
    "            'custom_id': object,\n",
    "            'name': str,\n",
    "            'station_group': object,\n",
    "        }\n",
    "        self._station_group_db: DataFrame = pd.DataFrame(columns=list(self._station_group_prop.keys()))\n",
    "        self._station_group_db = self._station_group_db.astype(self._station_group_prop)\n",
    "        self._station_group_db = self._station_group_db.set_index('station_group_id')\n",
    "        self._station_group_lookup_props: set[str] = set(['station_group_id', 'custom_id', 'name'])\n",
    "        # [STATION GROUPS] identifiers\n",
    "        self._station_group_counter: ObjectID = 0\n",
    "        self._station_groups_custom_identifiers: set[CustomID] = set()\n",
    "        \n",
    "        # [RESOURCES] database as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'res_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_db = self._res_db.set_index('res_id')\n",
    "        self._res_lookup_props: set[str] = set(['res_id', 'custom_id', 'name'])\n",
    "        # [RESOURCES] custom identifiers\n",
    "        self._res_counter: ObjectID = 0\n",
    "        self._res_custom_identifiers: set[CustomID] = set()\n",
    "        # [RESOURCES] sink: pool of sinks possible to allow multiple sinks in one environment\n",
    "        # [PERHAPS CHANGED LATER] \n",
    "        # currently only one sink out of the pool is chosen because jobs do not contain \n",
    "        # information about a target sink\n",
    "        self._sink_registered: bool = False\n",
    "        self._sinks: set[Sink] = set()\n",
    "        \n",
    "        # counter for processing stations (machines, assembly, etc.)\n",
    "        self.num_proc_stations: int = 0\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    # [PRODUCTION AREAS]\n",
    "    @property\n",
    "    def prod_area_db(self) -> DataFrame:\n",
    "        return self._prod_area_db\n",
    "    \n",
    "    # [STATION GROUPS]\n",
    "    @property\n",
    "    def station_group_db(self) -> DataFrame:\n",
    "        return self._station_group_db\n",
    "    \n",
    "    ### START LEGACY ###\n",
    "    \"\"\"\n",
    "    ### REWORK TO MULTIPLE SUBSYSTEMS\n",
    "    def _obtain_station_group_id(self) -> ObjectID:\n",
    "        Simple counter function for managing station group IDs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ObjectID\n",
    "            unique station group ID\n",
    "        \n",
    "        st_group_id = self._station_group_counter\n",
    "        self._station_group_counter += 1\n",
    "        \n",
    "        return st_group_id\n",
    "    \n",
    "    def register_station_group(\n",
    "        self,\n",
    "        processing_station: ProcessingStation,\n",
    "        custom_group_id: CustomID | None,\n",
    "        station_group_name: str | None,\n",
    "    ) -> tuple[ObjectID, StationGroup]:\n",
    "        registers an processing station in the corresponding station group\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        processing_station : ProcessingStation\n",
    "            _description_\n",
    "        station_group_identifier : CustomID | None\n",
    "            _description_\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        StationGroup\n",
    "            _description_\n",
    "        \n",
    "        # type security\n",
    "        # object to be registered\n",
    "        if not isinstance(processing_station, ProcessingStation):\n",
    "            raise TypeError(f\"{processing_station} is not of type >>ProcessingStation<<, but it has to be.\")\n",
    "        \n",
    "        # custom identifier\n",
    "        if custom_group_id is None:\n",
    "            # assign station group name by the corresponding processing station\n",
    "            custom_group_id = f'station_group_{processing_station.name()}'\n",
    "        elif not isinstance(custom_group_id, (str, int)):\n",
    "            raise TypeError(\"Provided custom identifier for station group must be of type STR or INT\")\n",
    "        \n",
    "        # create check value\n",
    "        if isinstance(custom_group_id, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_group_id.lower()\n",
    "        else:\n",
    "            check_val = custom_group_id\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        if check_val in self._station_groups_custom_identifiers:\n",
    "            # already exists, add to this station group\n",
    "            # lookup in station group DB\n",
    "            station_group = self.lookup_subsystem_info(\n",
    "                                                    subsystem_type='StationGroup',\n",
    "                                                    lookup_property='custom_id',\n",
    "                                                    lookup_val=custom_group_id)\n",
    "            station_group_id = station_group.group_id\n",
    "            # add proc station to associated ones\n",
    "            station_group.add_processing_station(processing_station=processing_station)\n",
    "        else:\n",
    "            self._station_groups_custom_identifiers.add(check_val)\n",
    "        \n",
    "            ### [CREATION+ASSIGN] station group does not exist\n",
    "            # obtain station group ID\n",
    "            station_group_id = self._obtain_station_group_id()\n",
    "            # create new station group\n",
    "            station_group = StationGroup(\n",
    "                                        env=self, group_id=station_group_id, \n",
    "                                        custom_identifier=custom_group_id, \n",
    "                                        name=station_group_name)\n",
    "            # add proc station to associated ones\n",
    "            station_group.add_processing_station(processing_station=processing_station)\n",
    "            \n",
    "            # new entry for station group database\n",
    "            new_entry: DataFrame = pd.DataFrame({\n",
    "                                    'station_group_id': [station_group_id],\n",
    "                                    'custom_id': [custom_group_id],\n",
    "                                    'name': [station_group_name],\n",
    "                                    'station_group': [station_group]})\n",
    "            new_entry = new_entry.astype(self._station_group_prop)\n",
    "            new_entry = new_entry.set_index('station_group_id')\n",
    "            self._station_group_db = pd.concat([self._station_group_db, new_entry])\n",
    "            \n",
    "        logger_env.info(f\"Successfully registered processing station {processing_station} \\\n",
    "            with station group {station_group}\")\n",
    "            \n",
    "        return station_group_id, station_group\n",
    "    \"\"\"\n",
    "    ### END LEGACY ###\n",
    "    \n",
    "    ####################################################################################\n",
    "    ## BEHAVIOUR CHANGE NECESSARY\n",
    "    # station groups are created and processing stations added after creation\n",
    "    # each supersystem has a dedicated function to add a subsystem \n",
    "    \n",
    "    ## REWORK TO WORK WITH DIFFERENT SUBSYSTEMS\n",
    "    # only one register method by analogy with 'lookup_subsystem_info'\n",
    "    # currently checking for existence and registration implemented, split into different methods\n",
    "    # one to check whether such a subsystem already exists\n",
    "    # another one registers a new subsystem\n",
    "    # if check positive: return subsystem by 'lookup_subsystem_info'\n",
    "    ### REWORK TO MULTIPLE SUBSYSTEMS\n",
    "    def _obtain_system_id(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "    ) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing system IDs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ObjectID\n",
    "            unique system ID\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                system_id = self._prod_area_counter\n",
    "                self._prod_area_counter += 1\n",
    "            case 'StationGroup':\n",
    "                system_id = self._station_group_counter\n",
    "                self._station_group_counter += 1\n",
    "            case 'Resource':\n",
    "                system_id = self._res_custom_identifiers\n",
    "                self._res_custom_identifiers += 1\n",
    "        \n",
    "        return system_id\n",
    "    \n",
    "    def register_subsystem(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        obj: SubsystemType,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "        state: str | None = None,\n",
    "    ) ->  tuple[ObjectID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        obj: env resource = instance of a subclass of InfrastructureObject\n",
    "        custom_identifier: user defined identifier\n",
    "        name: custom name of the object, \\\n",
    "            default: None\n",
    "        returns:\n",
    "            ObjectID: assigned resource ID\n",
    "            str: assigned resource's name\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                custom_identifiers = self._prod_area_custom_identifiers\n",
    "            case 'StationGroup':\n",
    "                custom_identifiers = self._station_groups_custom_identifiers\n",
    "            case 'Resource':\n",
    "                custom_identifiers = self._res_custom_identifiers\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided for subsystem type {subsystem_type} \\\n",
    "                already exists, but has to be unique.\")\n",
    "        else:\n",
    "            custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain system ID\n",
    "        system_id = self._obtain_system_id(subsystem_type=subsystem_type)\n",
    "        \n",
    "        # [RESOURCES] resource related data\n",
    "        # register sinks\n",
    "        if isinstance(obj, Sink):\n",
    "            if not self._sink_registered:\n",
    "                self._sink_registered = True\n",
    "            self._sinks.add(obj)\n",
    "        # count number of machines\n",
    "        if isinstance(obj, ProcessingStation):\n",
    "            self.num_proc_stations += 1\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'{type(obj).__name__}_env_{system_id}'\n",
    "        \n",
    "        # new entry for corresponding database\n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'prod_area_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'name': [name],\n",
    "                                        'prod_area': [obj]})\n",
    "                new_entry = new_entry.astype(self._prod_area_prop)\n",
    "                new_entry = new_entry.set_index('prod_area_id')\n",
    "                self._prod_area_db = pd.concat([self._prod_area_db, new_entry])\n",
    "            case 'StationGroup':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'station_group_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'name': [name],\n",
    "                                        'station_group': [obj]})\n",
    "                new_entry = new_entry.astype(self._station_group_prop)\n",
    "                new_entry = new_entry.set_index('station_group_id')\n",
    "                self._station_group_db = pd.concat([self._station_group_db, new_entry])\n",
    "            case 'Resource':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'res_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'resource': [obj],\n",
    "                                        'name': [name],\n",
    "                                        'res_type': [obj.res_type],\n",
    "                                        'state': [state]})\n",
    "                new_entry = new_entry.astype(self._infstruct_prop)\n",
    "                new_entry = new_entry.set_index('res_id')\n",
    "                self._res_db = pd.concat([self._res_db, new_entry])\n",
    "        \n",
    "        logger_env.info(f\"Successfully registered object with SystemID {system_id} and name {name}\")\n",
    "        \n",
    "        return system_id, name\n",
    "    \n",
    "    def lookup_subsystem_info(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        lookup_property: str,\n",
    "        lookup_val: CustomID,\n",
    "        target_property: str | None = None,\n",
    "    ) -> Any:\n",
    "        \"\"\"\n",
    "        obtain a subsystem by its property and corresponding value\n",
    "        properties: Subsystem ID, Custom ID, Name\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                allowed_lookup_props = self._prod_area_lookup_props\n",
    "                lookup_db = self._prod_area_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'prod_area'\n",
    "                id_prop: str = 'prod_area_id'\n",
    "            case 'StationGroup':\n",
    "                allowed_lookup_props = self._station_group_lookup_props\n",
    "                lookup_db = self._station_group_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'station_group'\n",
    "                id_prop: str = 'station_group_id'\n",
    "            case 'Resource':\n",
    "                allowed_lookup_props = self._res_lookup_props\n",
    "                lookup_db = self._res_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'resource'\n",
    "                id_prop: str = 'res_id'\n",
    "        \n",
    "        # allowed target properties\n",
    "        allowed_target_props: set[str] = set(lookup_db.columns.to_list())\n",
    "        # lookup property can not be part of the target properties\n",
    "        if lookup_property in allowed_target_props:\n",
    "            allowed_target_props.remove(lookup_property)\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if lookup_property not in allowed_lookup_props:\n",
    "            raise IndexError(f\"Lookup Property '{lookup_property}' is not allowed for subsystem type {subsystem_type}. Choose from {allowed_lookup_props}\")\n",
    "        # check if target property is allowed\n",
    "        if target_property not in allowed_target_props:\n",
    "            raise IndexError(f\"Target Property >>{target_property}<< is not allowed for subsystem type {subsystem_type}. Choose from {allowed_target_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if lookup_val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type >>None<<.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if lookup_property == id_prop:\n",
    "            # direct indexing for ID property: always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: SubsystemType = lookup_db.at[lookup_val, target_property]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                with the value >>{lookup_val}<<\")\n",
    "        else:\n",
    "            try:\n",
    "                temp1: Series = lookup_db.loc[lookup_db[lookup_property] == lookup_val, target_property]\n",
    "                # check for empty search result, at least one result necessary\n",
    "                if len(temp1) == 0:\n",
    "                    raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                    with the value >>{lookup_val}<<\")\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                with the value >>{lookup_val}<<\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            if len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_env.warning(f\"CAUTION: There are multiple subsystems which share the \\\n",
    "                            same value >>{lookup_val}<< for the lookup property >>{lookup_property}<<. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    ####################################################################\n",
    "    \n",
    "    ### REWORK NECESSARY\n",
    "    ### START LEGACY ###\n",
    "    \"\"\"\n",
    "    def get_station_group_by_prop(\n",
    "        self,\n",
    "        val: CustomID | str,\n",
    "        property: str = 'station_group_id',\n",
    "        target_prop: str = 'station_group',\n",
    "    ) -> StationGroup:\n",
    "        \n",
    "        obtain a station group by its property and corresponding value\n",
    "        properties: station_group_id, custom_id, name\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._station_group_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._station_group_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'station_group_id':\n",
    "            # direct indexing for ID property; station_group_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: StationGroup = self._station_group_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._station_group_db.loc[self._station_group_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_env.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    \"\"\"\n",
    "    ### END LEGACY ###\n",
    "    \n",
    "    # [RESOURCES]\n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        \"\"\"obtain a current overview of registered objects in the environment\"\"\"\n",
    "        return self._res_db\n",
    "    \n",
    "    @property\n",
    "    def sinks(self) -> set[Sink]:\n",
    "        \"\"\"registered sinks\"\"\"\n",
    "        return self._sinks\n",
    "    \n",
    "    @property\n",
    "    def sink_registered(self) -> bool:\n",
    "        return self._sink_registered\n",
    "    \n",
    "    ### START LEGACY ###\n",
    "    \"\"\"\n",
    "    def _obtain_res_id(self) -> ObjectID:\n",
    "        Simple counter function for managing resource IDs\n",
    "        # assign id and set counter up\n",
    "        res_id = self._res_counter\n",
    "        self._res_counter += 1\n",
    "        \n",
    "        return res_id\n",
    "    \n",
    "    def register_resource(\n",
    "        self,\n",
    "        obj: InfrastructureObject,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) ->  tuple[ObjectID, str]:\n",
    "        \n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        obj: env resource = instance of a subclass of InfrastructureObject\n",
    "        custom_identifier: user defined identifier\n",
    "        name: custom name of the object, \\\n",
    "            default: None\n",
    "        returns:\n",
    "            ObjectID: assigned resource ID\n",
    "            str: assigned resource's name\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in self._res_custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided already exists, \\\n",
    "                            but has to be unique.\")\n",
    "        else:\n",
    "            self._res_custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain res_id\n",
    "        res_id = self._obtain_res_id()\n",
    "        \n",
    "        # register sinks\n",
    "        if isinstance(obj, Sink):\n",
    "            if not self._sink_registered:\n",
    "                self._sink_registered = True\n",
    "            self._sinks.add(obj)\n",
    "        \n",
    "        # count number of machines\n",
    "        if isinstance(obj, ProcessingStation):\n",
    "            self.num_proc_stations += 1\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'{type(obj).__name__}_env_{res_id}'\n",
    "        \n",
    "        # new entry for resource data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'res_id': [res_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'resource': [obj],\n",
    "                                'name': [name],\n",
    "                                'res_type': [obj.res_type],\n",
    "                                'state': [state]})\n",
    "        new_entry = new_entry.astype(self._infstruct_prop)\n",
    "        new_entry = new_entry.set_index('res_id')\n",
    "        self._res_db = pd.concat([self._res_db, new_entry])\n",
    "        \n",
    "        logger_env.info(f\"Successfully registered object with ResID {res_id} and name {name}\")\n",
    "        \n",
    "        return res_id, name\n",
    "    \n",
    "    \n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_res_obj_by_prop(\n",
    "        self,\n",
    "        val: ObjectID | CustomID | str,\n",
    "        property: str = 'res_id',\n",
    "        target_prop: str = 'resource',\n",
    "    ) -> InfrastructureObject:\n",
    "        \n",
    "        obtain a resource object from the environment by its property and corresponding value\n",
    "        properties: res_id, custom_id, name\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._res_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._res_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'res_id':\n",
    "            # direct indexing for ID property; res_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: InfrastructureObject = self._res_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._res_db.loc[self._res_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no resources found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_env.warning(f\"CAUTION: There are multiple resources which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    ### END LEGACY ###\n",
    "    \"\"\"\n",
    "    \n",
    "    def update_res_state(\n",
    "        self,\n",
    "        obj: InfrastructureObject,\n",
    "        state: str,\n",
    "        reset_temp: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a resource object in the resource database\"\"\"\n",
    "        # update resource database\n",
    "        logger_env.debug(f\"Set state of {obj} to {state}\")\n",
    "        # update state tracking of the job instance\n",
    "        logger_env.debug(f\"[Object:{self}]: Monitor is {obj.stat_monitor}\")\n",
    "        \n",
    "        # check if 'TEMP' state should be reset\n",
    "        if reset_temp:\n",
    "            # special reset method, calls state setting to previous state\n",
    "            obj.stat_monitor.reset_temp_state()\n",
    "            state = obj.stat_monitor.state_current\n",
    "        else:\n",
    "            obj.stat_monitor.set_state(state=state)\n",
    "        \n",
    "        self._res_db.at[obj.res_id, 'state'] = state\n",
    "        logger_env.debug(f\"Executed state setting of {obj} to {state}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def res_objs_temp_state(\n",
    "        self,\n",
    "        res_objs: Iterable[InfrastructureObject],\n",
    "        reset_temp: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"Sets/resets given resource objects from the 'TEMP' state\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        res_objs : tuple[InfrastructureObject]\n",
    "            objects for which the TEMP state should be changed\n",
    "        set_temp : bool\n",
    "            indicates if the temp state should be set or reset\n",
    "        \"\"\"\n",
    "        for obj in res_objs:\n",
    "            self.update_res_state(obj=obj, state='TEMP', reset_temp=reset_temp)\n",
    "            # calculate KPIs if 'TEMP' state is set\n",
    "            if not reset_temp:\n",
    "                obj.stat_monitor.calc_KPI()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \n",
    "        # set end state for each resource object to calculate the right time amounts\n",
    "        for res_obj in self._res_db['resource']:\n",
    "            res_obj.finalise()\n",
    "        logger_env.info(\"Finalisation of the state information for all resource objects successful.\")\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Monitors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='infrastructureobject'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monitor(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        obj: InfrastructureObject | Job | Operation,\n",
    "        init_state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'WAITING', \n",
    "            'PROCESSING', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Class to monitor associated objects (load and resource)\n",
    "        \"\"\"\n",
    "        # initialise parent class if available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # [REGISTRATION]\n",
    "        self._env = env\n",
    "        self._target_object = obj\n",
    "        \n",
    "        # [STATE] state parameters\n",
    "        # all possible/allowed states\n",
    "        self.states_possible: set[str] = set(possible_states)\n",
    "        # always add states 'INIT', 'FINISH', 'TEMP' for control flow\n",
    "        if not 'INIT' in self.states_possible:\n",
    "            self.states_possible.add('INIT')\n",
    "        if not 'FINISH' in self.states_possible:\n",
    "            self.states_possible.add('FINISH')\n",
    "        if not 'TEMP' in self.states_possible:\n",
    "            self.states_possible.add('TEMP')\n",
    "            \n",
    "        # check integrity of the given state\n",
    "        if init_state in self.states_possible:\n",
    "            self.state_current: str = init_state\n",
    "        else:\n",
    "            raise ValueError(f\"The state {state} is not allowed. Must be one of {self.states_possible}\")\n",
    "        \n",
    "        # boolean indicator if a state is set\n",
    "        self.state_status: dict[str, bool] = dict()\n",
    "        # time counter for each state\n",
    "        self.state_times: dict[str, float] = dict()\n",
    "        # starting time variable indicating when the last state assignment took place\n",
    "        self.state_starting_time: float = self._env.now()\n",
    "        \n",
    "        for state in self.states_possible:\n",
    "            # init state time dictionary\n",
    "            self.state_times[state] = 0.\n",
    "            # init state is set to True\n",
    "            if state == self.state_current:\n",
    "                self.state_status[state] = True\n",
    "            else:\n",
    "                self.state_status[state] = False\n",
    "                \n",
    "        # DataFrame to further analyse state durations\n",
    "        self.state_durations: DataFrame | None = None\n",
    "\n",
    "        # availability indicator\n",
    "        self._availability_states: set[str] = set([\n",
    "            'WAITING',\n",
    "        ])\n",
    "        if self.state_current in self._availability_states:\n",
    "            self.is_available: bool = True\n",
    "        else:\n",
    "            self.is_available: bool = False\n",
    "        \n",
    "        # additional 'TEMP' state information\n",
    "        # indicator if state was 'TEMP'\n",
    "        self._is_temp: bool = False\n",
    "        # state before 'TEMP' was set\n",
    "        self._state_before_temp: str = self.state_current\n",
    "        # time components\n",
    "        self.time_active: float = 0.\n",
    "        \"\"\"\n",
    "        self.time_occupied: float = 0.\n",
    "        \n",
    "        # resource KPIs\n",
    "        self.utilisation: float = 0.\n",
    "        \n",
    "        # logistic objective values\n",
    "        self.WIP_load_time: float = 0.\n",
    "        self.WIP_load_num_jobs: int = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "        \n",
    "    def get_current_state(self) -> str:\n",
    "        \"\"\"get the current state of the associated resource\"\"\"\n",
    "        return self.state_current\n",
    "        \n",
    "    def set_state(\n",
    "        self,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        function to set the object in the given state\n",
    "        state: name of the state in which the object should be placed, must be part \\\n",
    "            of the object's possible states\n",
    "        \"\"\"\n",
    "        # eliminate lower-case letter\n",
    "        target_state = state.upper()\n",
    "        \n",
    "        # check if state is allowed\n",
    "        if target_state not in self.states_possible:\n",
    "            raise ValueError(f\"The state {target_state} is not allowed. Must be one of {self.states_possible}\")\n",
    "        \n",
    "        # check if state is already set\n",
    "        if self.state_status[target_state] == True and target_state != 'TEMP':\n",
    "            logger_monitors.info(f\"Tried to set state of {self._target_object} to >>{target_state}<<, but this state was already set.\\\n",
    "                The object's state was not changed.\")\n",
    "        # check if the 'TEMP' state was already set, this should never happen\n",
    "        # if it happens raise an error to catch wrong behaviour\n",
    "        elif self.state_status[target_state] == True and target_state != 'TEMP':\n",
    "            raise RuntimeError(f\"Tried to set state of {self._target_object} to >>TEMP<<, but this state was already set.\")\n",
    "        \n",
    "        # calculate time for which the object was in the current state before changing it\n",
    "        current_state_start = self.state_starting_time\n",
    "        current_time = self._env.now()\n",
    "        current_state_duration = current_time - current_state_start\n",
    "        # add time to the time counter for the current state\n",
    "        current_state = self.state_current\n",
    "        self.state_times[current_state] += current_state_duration\n",
    "        \n",
    "        # check if 'TEMP' state shall be set\n",
    "        if target_state == 'TEMP':\n",
    "            # set 'TEMP' state indicator to true\n",
    "            self._is_temp = True\n",
    "            # save current state for the state reset\n",
    "            self._state_before_temp = current_state\n",
    "        \n",
    "        # set old state to False and new state to True\n",
    "        self.state_status[current_state] = False\n",
    "        self.state_status[target_state] = True\n",
    "        # assign new state as current one\n",
    "        self.state_current = target_state\n",
    "        # set state starting time to current time\n",
    "        self.state_starting_time = current_time\n",
    "        # availability\n",
    "        if self.state_current in self._availability_states:\n",
    "            self.is_available: bool = True\n",
    "        elif self.state_current == 'TEMP':\n",
    "            # 'TEMP' state shall not change the availability indicator\n",
    "            pass\n",
    "        else:\n",
    "            self.is_available: bool = False\n",
    "        \n",
    "        logger_monitors.debug(f\"Duration for state {current_state} on {self._target_object} was {current_state_duration}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def reset_temp_state(self) -> None:\n",
    "        \"\"\"Reset from 'TEMP' state\n",
    "        \"\"\"\n",
    "        # check if object was in TEMP state, raise error if not\n",
    "        if not self._is_temp:\n",
    "            raise RuntimeError(f\"Tried to reset {self._target_object} from 'TEMP' state but \\\n",
    "                the current state is >>{self.state_current}<<\")\n",
    "        else:\n",
    "            self._is_temp = False\n",
    "            self.set_state(state=self._state_before_temp)\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def calc_KPI(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"calculates different KPIs at any point in time\n",
    "        \"\"\"\n",
    "        \n",
    "        # state durations for analysis\n",
    "        if not is_finalise:\n",
    "            self.state_durations = self.state_durations_as_df()\n",
    "        \n",
    "        # [TOTAL ACTIVATE TIME]\n",
    "        self.time_active = self.state_durations.loc[:, 'abs [timesteps]'].sum()\n",
    "        \n",
    "        \"\"\"\n",
    "        # PROCESSING STATIONS ONLY\n",
    "        if isinstance(self._target_object, ProcessingStation):\n",
    "            # [OCCUPATION]\n",
    "            # properties which count as occupied\n",
    "            # paused counts in because pausing the processing station is an external factor\n",
    "            util_props = ['PROCESSING', 'PAUSED']\n",
    "            self.time_occupied = state_durations.loc[util_props, 'abs [timesteps]'].sum()\n",
    "            \n",
    "            # [UTILISATION]\n",
    "            # avoid division by 0\n",
    "            if self.time_active > 0.:\n",
    "                self.utilisation = self.time_occupied / self.time_active\n",
    "        \"\"\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \"\"\"\n",
    "    def change_WIP(\n",
    "        self,\n",
    "        job: Job,\n",
    "        remove: bool,\n",
    "    ) -> None:\n",
    "        \n",
    "        # removing WIP\n",
    "        if remove:\n",
    "            # next operation of the job already assigned\n",
    "            self.WIP_load_time -= job.last_proc_time\n",
    "            self.WIP_load_num_jobs -= 1\n",
    "        else:\n",
    "            self.WIP_load_time += job.current_proc_time\n",
    "            self.WIP_load_num_jobs += 1\n",
    "        \n",
    "        return None\n",
    "    \"\"\"\n",
    "    \n",
    "    def state_durations_as_df(self) -> DataFrame:\n",
    "        \"\"\"Calculates absolute and relative state durations at the current time\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            State duration table with absolute and relative values\n",
    "        \"\"\"\n",
    "        # build state duration table\n",
    "        temp1: Series = pd.Series(data=self.state_times)\n",
    "        temp2: DataFrame = temp1.to_frame()\n",
    "        temp2.columns = ['abs [timesteps]']\n",
    "        temp2['rel [%]'] = temp2['abs [timesteps]'] / temp2.sum(axis=0)['abs [timesteps]'] * 100\n",
    "        temp2 = temp2.drop(labels=['INIT', 'FINISH', 'TEMP'], axis=0)\n",
    "        temp2 = temp2.sort_index(axis=0, ascending=True, kind='stable')\n",
    "        state_durations_df = temp2.copy()\n",
    "        \n",
    "        return state_durations_df\n",
    "    \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        \n",
    "        # assign state duration table\n",
    "        self.state_durations = self.state_durations_as_df()\n",
    "        \n",
    "        # calculate KPIs\n",
    "        self.calc_KPI(is_finalise=True)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_state_bar_chart(        \n",
    "        self,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'state_distribution',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"draws the collected state times of the object as bar chart\"\"\"\n",
    "        data = pd.DataFrame.from_dict(data=self.state_times, orient='index', columns=['total time'])\n",
    "        data.index = data.index.rename('state')\n",
    "        data = data.sort_index(axis=0, kind='stable')\n",
    "        \n",
    "        fig: PlotlyFigure = px.bar(data, text_auto='.2f')\n",
    "        fig.update_layout(title=f'State Time Distribution of {self._target_object}', showlegend=False)\n",
    "        fig.update_yaxes(title=dict({'text': 'total time'}))\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferMonitor(Monitor):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obj: Buffer,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # initialise parent class\n",
    "        super().__init__(obj=obj, **kwargs)\n",
    "        \n",
    "        # fill level tracking\n",
    "        self._level_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': int,\n",
    "        }\n",
    "        self._level_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., obj.start_fill_level]])\n",
    "        self._level_db = self._level_db.astype(self._level_db_types)\n",
    "        \n",
    "        self._current_fill_level = obj.start_fill_level\n",
    "        self._fill_level_starting_time: float = self.env.now()\n",
    "        self._wei_avg_fill_level: float | None = None\n",
    "        \n",
    "    @property\n",
    "    def wei_avg_fill_level(self) -> float:\n",
    "        return self._wei_avg_fill_level\n",
    "    \n",
    "    @property\n",
    "    def level_db(self) -> DataFrame:\n",
    "        return self._level_db\n",
    "    \n",
    "    def set_state(\n",
    "        self,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"additional level tracking functionality\"\"\"\n",
    "        super().set_state(state=state)\n",
    "        \n",
    "        is_finalise: bool = False\n",
    "        if self.state_current == 'FINISH':\n",
    "            is_finalise: bool = True\n",
    "        self.track_fill_level(is_finalise=is_finalise)\n",
    "        \n",
    "    # Buffer fill level tracking\n",
    "    def track_fill_level(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"adds an entry to the fill level database\"\"\"\n",
    "        # only calculate duration if buffer level changes\n",
    "        current_time = self.env.now()\n",
    "        duration = current_time - self._fill_level_starting_time\n",
    "        logger_buffers.debug(f\"[BUFFER: {self._target_object}] Current time is {current_time} with level {len(self._target_object)} and old level {self._current_fill_level}\")\n",
    "        #if ((self._current_fill_level != len(self)) and (duration > 0.0)) or is_finalise:\n",
    "        if (self._current_fill_level != len(self._target_object)) or is_finalise:\n",
    "            temp1: Series = pd.Series(\n",
    "                                    index=['sim_time', 'duration', 'level'],\n",
    "                                    data=[current_time, duration, self._current_fill_level])\n",
    "            temp2: DataFrame = temp1.to_frame().T.astype(self._level_db_types)\n",
    "            self._level_db = pd.concat([self._level_db, temp2], ignore_index=True)\n",
    "            self._current_fill_level = len(self._target_object)\n",
    "            self._fill_level_starting_time = current_time\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        # execute parent class function\n",
    "        super().finalise_stats()\n",
    "        \n",
    "        # finalise fill level tracking\n",
    "        self.track_fill_level(is_finalise=True)\n",
    "        \n",
    "        # weighted average fill level\n",
    "        self._level_db = self._level_db.loc[self._level_db['duration'] > 0., :].copy()\n",
    "        self._level_db = self._level_db.reset_index(drop=True)\n",
    "        temp1: DataFrame = self._level_db.copy()\n",
    "        temp1['mul'] = temp1['duration'] * temp1['level']\n",
    "        sums: Series = temp1.sum(axis=0)\n",
    "        self._wei_avg_fill_level: float = sums['mul'] / sums['duration']\n",
    "        \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_fill_level(\n",
    "        self,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'fill_level',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        method to draw and display the fill level expansion of the corresponding buffer\n",
    "        \"\"\"\n",
    "        # add starting point to start chart at t = init time\n",
    "        data = self.level_db.copy()\n",
    "        val1: float = data.at[0, 'sim_time'] - data.at[0, 'duration']\n",
    "        val2: float = 0.\n",
    "        val3: int = data.at[0, 'level']\n",
    "        temp1: DataFrame = pd.DataFrame(columns=data.columns, data=[[val1, val2, val3]])\n",
    "        temp1 = pd.concat([temp1, data], ignore_index=True)\n",
    "        \n",
    "        fig: PlotlyFigure = px.line(x=temp1['sim_time'], y=temp1['level'], line_shape=\"vh\")\n",
    "        fig.update_traces(line=dict(width=3))\n",
    "        fig.update_layout(title=f'Fill Level of {self._target_object}')\n",
    "        fig.update_yaxes(title=dict({'text': 'fill level [-]'}))\n",
    "        fig.update_xaxes(title=dict({'text': 'time'}))\n",
    "        # weighted average fill level\n",
    "        fig.add_hline(\n",
    "                    y=self.wei_avg_fill_level, line_width=3, \n",
    "                    line_dash='dot', line_color='orange')\n",
    "        # capacity\n",
    "        cap = self._target_object.capacity()\n",
    "        if cap < INF:\n",
    "            fig.add_hline(\n",
    "                        y=cap, line_width=3, \n",
    "                        line_dash='dash', line_color='red')\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcStationMonitor(Monitor):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obj: ProcessingStation,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # initialise parent class\n",
    "        super().__init__(obj=obj, **kwargs)\n",
    "        \n",
    "        # WIP tracking time load\n",
    "        self._WIP_time_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': float,\n",
    "        }\n",
    "        ###################### PERHAPS ADD STARTING LEVEL LATER\n",
    "        self._WIP_time_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., 0.]])\n",
    "        self._WIP_time_db = self._WIP_time_db.astype(self._WIP_time_db_types)\n",
    "        \n",
    "        # WIP tracking number of jobs\n",
    "        self._WIP_num_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': int,\n",
    "        }\n",
    "        ###################### PERHAPS ADD STARTING LEVEL LATER\n",
    "        self._WIP_num_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., 0]])\n",
    "        self._WIP_num_db = self._WIP_num_db.astype(self._WIP_num_db_types)\n",
    "        \n",
    "        #self._current_WIP_time: float = 0.\n",
    "        #self._last_WIP_time: float = 0.\n",
    "        #self._current_WIP_num: int = 0\n",
    "        #self._last_WIP_num: int = 0\n",
    "        \n",
    "        self._WIP_time_starting_time: float = self.env.now()\n",
    "        self._WIP_num_starting_time: float = self.env.now()\n",
    "        self._wei_avg_WIP_level_time: float | None = None\n",
    "        self._wei_avg_WIP_level_num: float | None = None\n",
    "        \n",
    "        # time components\n",
    "        self.time_occupied: float = 0.\n",
    "        \n",
    "        # resource KPIs\n",
    "        self.utilisation: float = 0.\n",
    "        \n",
    "        # logistic objective values\n",
    "        self.WIP_load_time: float = 0.\n",
    "        self._WIP_load_time_last: float = 0.\n",
    "        self.WIP_load_num_jobs: int = 0\n",
    "        self._WIP_load_num_jobs_last: int = 0\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_WIP_level_time(self) -> float:\n",
    "        return self._wei_avg_WIP_level_time\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_WIP_level_num(self) -> float:\n",
    "        return self._wei_avg_WIP_level_num\n",
    "    \n",
    "    @property\n",
    "    def WIP_time_db(self) -> DataFrame:\n",
    "        return self._WIP_time_db\n",
    "    \n",
    "    @property\n",
    "    def WIP_num_db(self) -> DataFrame:\n",
    "        return self.__WIP_num_db\n",
    "    \n",
    "    def track_WIP_level(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"adds an entry to the fill level database\"\"\"\n",
    "        # only calculate duration if buffer level changes\n",
    "        current_time = self.env.now()\n",
    "        \n",
    "        if (self._WIP_load_time_last != self.WIP_load_time) or is_finalise:\n",
    "            duration = current_time - self._WIP_time_starting_time\n",
    "            temp1: Series = pd.Series(\n",
    "                                    index=['sim_time', 'duration', 'level'],\n",
    "                                    data=[current_time, duration, self.WIP_load_time])\n",
    "            temp2: DataFrame = temp1.to_frame().T.astype(self._WIP_time_db_types)\n",
    "            self._WIP_time_db = pd.concat([self._WIP_time_db, temp2], ignore_index=True)\n",
    "            self._WIP_load_time_last = self.WIP_load_time\n",
    "            self._WIP_time_starting_time = current_time\n",
    "            \n",
    "        if (self._WIP_load_num_jobs_last != self.WIP_load_num_jobs) or is_finalise:\n",
    "            duration = current_time - self._WIP_num_starting_time\n",
    "            temp1: Series = pd.Series(\n",
    "                                    index=['sim_time', 'duration', 'level'],\n",
    "                                    data=[current_time, duration, self.WIP_load_num_jobs])\n",
    "            temp2: DataFrame = temp1.to_frame().T.astype(self._WIP_num_db_types)\n",
    "            self._WIP_num_db = pd.concat([self._WIP_num_db, temp2], ignore_index=True)\n",
    "            self._WIP_load_num_jobs_last = self.WIP_load_num_jobs\n",
    "            self._WIP_num_starting_time = current_time\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def calc_KPI(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \n",
    "        super().calc_KPI()\n",
    "        \n",
    "        # [OCCUPATION]\n",
    "        # properties which count as occupied\n",
    "        # paused counts in because pausing the processing station is an external factor\n",
    "        util_props = ['PROCESSING', 'PAUSED']\n",
    "        self.time_occupied = self.state_durations.loc[util_props, 'abs [timesteps]'].sum()\n",
    "        \n",
    "        # [UTILISATION]\n",
    "        # avoid division by 0\n",
    "        if self.time_active > 0.:\n",
    "            self.utilisation = self.time_occupied / self.time_active\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def change_WIP(\n",
    "        self,\n",
    "        job: Job,\n",
    "        remove: bool,\n",
    "    ) -> None:\n",
    "        \n",
    "        # removing WIP\n",
    "        if remove:\n",
    "            # next operation of the job already assigned\n",
    "            self.WIP_load_time -= job.last_proc_time\n",
    "            self.WIP_load_num_jobs -= 1\n",
    "        else:\n",
    "            self.WIP_load_time += job.current_proc_time\n",
    "            self.WIP_load_num_jobs += 1\n",
    "            \n",
    "        self.track_WIP_level()\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        # execute parent class function\n",
    "        super().finalise_stats()\n",
    "        \n",
    "        # finalise WIP level tracking\n",
    "        self.track_WIP_level(is_finalise=True)\n",
    "        \n",
    "        # weighted average WIP time level\n",
    "        self._WIP_time_db = self._WIP_time_db.loc[self._WIP_time_db['duration'] > 0., :].copy()\n",
    "        self._WIP_time_db = self._WIP_time_db.reset_index(drop=True)\n",
    "        temp1: DataFrame = self._WIP_time_db.copy()\n",
    "        temp1['mul'] = temp1['duration'] * temp1['level']\n",
    "        sums: Series = temp1.sum(axis=0)\n",
    "        self._wei_avg_WIP_level_time: float = sums['mul'] / sums['duration']\n",
    "        # weighted average WIP num level\n",
    "        self._WIP_num_db = self._WIP_num_db.loc[self._WIP_num_db['duration'] > 0., :].copy()\n",
    "        self._WIP_num_db = self._WIP_num_db.reset_index(drop=True)\n",
    "        temp1: DataFrame = self._WIP_num_db.copy()\n",
    "        temp1['mul'] = temp1['duration'] * temp1['level']\n",
    "        sums: Series = temp1.sum(axis=0)\n",
    "        self._wei_avg_WIP_level_num: float = sums['mul'] / sums['duration']\n",
    "        \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_WIP_level(\n",
    "        self,\n",
    "        use_num_jobs_metric: bool = False,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'fill_level',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        method to draw and display the fill level expansion of the corresponding buffer\n",
    "        \"\"\"\n",
    "        # add starting point to start chart at t = init time\n",
    "        if use_num_jobs_metric:\n",
    "            data = self._WIP_num_db.copy()\n",
    "            title = f'WIP Level Num Jobs of {self._target_object}'\n",
    "            yaxis = 'WIP Level Number of Jobs [-]'\n",
    "            avg_WIP_level = self._wei_avg_WIP_level_num\n",
    "        else:\n",
    "            data = self._WIP_time_db.copy()\n",
    "            title = f'WIP Level Time of {self._target_object}'\n",
    "            yaxis = 'WIP Level Time [time units]'\n",
    "            avg_WIP_level = self._wei_avg_WIP_level_time\n",
    "        val1: float = data.at[0, 'sim_time'] - data.at[0, 'duration']\n",
    "        val2: float = 0.\n",
    "        val3: int = data.at[0, 'level']\n",
    "        temp1: DataFrame = pd.DataFrame(columns=data.columns, data=[[val1, val2, val3]])\n",
    "        temp1 = pd.concat([temp1, data], ignore_index=True)\n",
    "        \n",
    "        fig: PlotlyFigure = px.line(x=temp1['sim_time'], y=temp1['level'], line_shape=\"vh\")\n",
    "        fig.update_traces(line=dict(width=3))\n",
    "        fig.update_layout(title=title)\n",
    "        fig.update_yaxes(title=dict({'text': yaxis}))\n",
    "        fig.update_xaxes(title=dict({'text': 'time'}))\n",
    "        # weighted average WIP level\n",
    "        fig.add_hline(\n",
    "                    y=avg_WIP_level, line_width=3, \n",
    "                    line_dash='dot', line_color='orange')\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement an ABC to provide an interface for the simulation logic methods:**\n",
    "- *name: ResourceModule*\n",
    "- pre, main, post\n",
    "- finalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-Down Registration of Components or Subsystems\n",
    "- object-oriented way to add subssystems to supersystems\n",
    "- supersystems are sets:\n",
    "    - each supersystem can contain each subsystem only once\n",
    "    - but each subsystem can be part of multiple supersystems\n",
    "- supersystems contain a special method to add subsystems\n",
    "    - parameter to check or create subsystem\n",
    "    - call to InfrastructureManager:\n",
    "        - check if subsystem already created\n",
    "        - if check fails create subsystem with given parameters\n",
    "        - return subsystem\n",
    "    - add subsystem\n",
    "\n",
    "- **procedure:**\n",
    "    - supersystem creation:\n",
    "        - register in Infrastructure Manager --> assignment of unique system ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supersystem(set):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        subsystem_type: str,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        # assign basic information\n",
    "        self._env = env\n",
    "        # subsystem information\n",
    "        self._subsystem_type: str = subsystem_type\n",
    "        \n",
    "        infstruct_mgr = self._env.infstruct_mgr\n",
    "        self._system_id, self._name = infstruct_mgr.register_subsystem(\n",
    "                                        subsystem_type=self._subsystem_type,\n",
    "                                        obj=self, custom_identifier=custom_identifier,\n",
    "                                        name=name)\n",
    "        self._custom_identifier = custom_identifier\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'System (type: {self._subsystem_type}, custom_id: {self._custom_identifier}, name: {self._name})'\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def subsystem_type(self) -> str:\n",
    "        return self._subsystem_type\n",
    "    \n",
    "    @property\n",
    "    def system_id(self) -> ObjectID:\n",
    "        return self._system_id\n",
    "    \n",
    "    @property\n",
    "    def custom_identifier(self) -> CustomID:\n",
    "        return self._custom_identifier\n",
    "    \n",
    "    @property\n",
    "    def name(self) -> str | None:\n",
    "        return self._name\n",
    "    \n",
    "    def as_list(self) -> list[SubsystemType]:\n",
    "        \"\"\"output the associated subsystems as list\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[SubsystemType]\n",
    "            list of associated subsystems\n",
    "        \"\"\"\n",
    "        return list(self)\n",
    "    \n",
    "    def as_tuple(self) -> tuple[SubsystemType]:\n",
    "        \"\"\"output the associated subsystems as tuple\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[SubsystemType]\n",
    "            tuple of associated subsystems\n",
    "        \"\"\"\n",
    "        return tuple(self)\n",
    "    \n",
    "    def add_subsystem(\n",
    "        self,\n",
    "        subsystem: SubsystemType,\n",
    "    ) -> None:\n",
    "        \"\"\"adding a subsystem to the given supersystem\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subsystem : SubsystemType\n",
    "            subsystem object which shall be added to the supersystem\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        UserWarning\n",
    "            if a subsystem is already associated with the given supersystem\n",
    "        \"\"\"\n",
    "        if not subsystem in self:\n",
    "            self.add(subsystem)\n",
    "        else:\n",
    "            raise UserWarning(f\"Subsystem {subsystem} already was \\\n",
    "                in station group {self}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionArea(Supersystem):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Group of processing stations which are considered parallel machines\n",
    "        \"\"\"\n",
    "        \n",
    "        # initiliase base class\n",
    "        super().__init__(subsystem_type='ProductionArea', **kwargs)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationGroup(Supersystem):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Group of processing stations which are considered parallel machines\n",
    "        \"\"\"\n",
    "        \n",
    "        # initiliase base class\n",
    "        super().__init__(subsystem_type='StationGroup', **kwargs)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimulationEnvironment()\n",
    "infstruct_mgr = InfrastructureManager(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_area = ProductionArea(env=env, custom_identifier=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_group = StationGroup(env=env, custom_identifier=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System (type: ProductionArea, custom_id: 0, name: ProductionArea_env_0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System (type: StationGroup, custom_id: 0, name: StationGroup_env_0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>prod_area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prod_area_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ProductionArea_env_0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             custom_id                  name prod_area\n",
       "prod_area_id                                          \n",
       "0                    0  ProductionArea_env_0        {}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.prod_area_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>StationGroup_env_0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 custom_id                name station_group\n",
       "station_group_id                                            \n",
       "0                        0  StationGroup_env_0            {}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.station_group_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Infrastructure Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfrastructureObject(sim.Component):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None = None,\n",
    "        capacity: float = INF,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'WAITING', \n",
    "            'PROCESSING', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env: simulation environment in which the infrastructure object is embedded\n",
    "        custom_identifier: unique user-defined custom ID of the given object \\\n",
    "            necessary for user interfaces\n",
    "        capacity: capacity of the infrastructure object, if multiple processing \\\n",
    "            slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        # [SUBSYSTEM] subsystem information\n",
    "        # contrary to other system types no bucket because a processing station \n",
    "        # is the smallest unit in the system view/analysis\n",
    "        self._subsystem_type: str = 'Resource'\n",
    "        \n",
    "        # [STATS] Monitoring\n",
    "        # special monitors for some classes\n",
    "        if isinstance(self, Buffer):\n",
    "            self._stat_monitor = BufferMonitor(\n",
    "                                env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        elif isinstance(self, ProcessingStation):\n",
    "            self._stat_monitor = ProcStationMonitor(\n",
    "                                env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        else:\n",
    "            self._stat_monitor = Monitor(env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # assert machine information and register object in the environment\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        #self._res_id, name = env.infstruct_mgr.register_resource(\n",
    "        #                        obj=self, custom_identifier=custom_identifier,\n",
    "        #                        name=name, state=current_state)\n",
    "        self._res_id, name = env.infstruct_mgr.register_subsystem(\n",
    "                                subsystem_type=self._subsystem_type,\n",
    "                                obj=self, custom_identifier=custom_identifier,\n",
    "                                name=name, state=current_state)\n",
    "        self.custom_identifier = custom_identifier\n",
    "        self.cap = capacity\n",
    "        # intialize base class\n",
    "        process = 'main_logic'\n",
    "        super().__init__(env=env, name=name, process=process, **kwargs)\n",
    "        \n",
    "        # add logic queues\n",
    "        # each resource uses one associated logic queue, logic queues are not physically available\n",
    "        queue_name: str = f\"queue_{self.name()}\"\n",
    "        self.logic_queue: Queue = sim.Queue(name=queue_name, env=self.env)\n",
    "        \n",
    "        # currently available jobs on that resource\n",
    "        self.contents: OrderedDict[ObjectID, Job] = OrderedDict()\n",
    "        \n",
    "        # [STATS] additional information\n",
    "        # number of inputs/outputs\n",
    "        self.num_inputs: int = 0\n",
    "        self.num_outputs: int = 0\n",
    "    \n",
    "    @property\n",
    "    def res_id(self) -> ObjectID:\n",
    "        return self._res_id\n",
    "    \n",
    "    @property\n",
    "    def subsystem_type(self) -> str:\n",
    "        return self._subsystem_type\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    def add_content(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"add contents to the InfrastructureObject\"\"\"\n",
    "        job_id = job.job_id\n",
    "        if job_id not in self.contents:\n",
    "            self.contents[job_id] = job\n",
    "        else:\n",
    "            raise KeyError(f\"Job {job} already in contents of {self}\")\n",
    "    \n",
    "    def remove_content(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"remove contents from the InfrastructureObject\"\"\"\n",
    "        job_id = job.job_id\n",
    "        if job_id in self.contents:\n",
    "            del self.contents[job_id]\n",
    "        else:\n",
    "            raise KeyError(f\"Job {job} not in contents of {self}\")\n",
    "    \n",
    "    def put_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> InfrastructureObject | None:\n",
    "        \"\"\"\n",
    "        placing\n",
    "        \"\"\"\n",
    "        # ALLOCATION REQUEST\n",
    "        ## call dispatcher --> request for allocation\n",
    "        ## self._dispatcher.request_allocation ...\n",
    "        ### input job\n",
    "        #### LATER: LOGIC FOR RESOURCE ALLOCATION (AGENT)\n",
    "        ### - Dispatcher calls \"get_next_operation\"\n",
    "        ### - Dispatcher returns target_machine\n",
    "        ## ret: obtaining target machine\n",
    "        # ++++++++++ add later ++++++++++++\n",
    "        ## time component: given start date of operation\n",
    "        ## returning release date, waiting for release date or release early\n",
    "        dispatcher = self.env.dispatcher\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        target_station = dispatcher.request_job_allocation(job=job)\n",
    "        # get logic queue\n",
    "        logic_queue = target_station.logic_queue\n",
    "        # check if the target is a sink\n",
    "        if isinstance(target_station, Sink):\n",
    "            pass\n",
    "        else:\n",
    "            # check if associated buffers exist\n",
    "            logger_prodStations.debug(f\"[{self}] Check for buffers\")\n",
    "            buffers = target_station.buffers\n",
    "            \n",
    "            if buffers:\n",
    "                #logger_prodStations.debug(f\"[{self}] Buffer found\")\n",
    "                # [STATE:InfrStructObj] BLOCKED\n",
    "                infstruct_mgr.update_res_state(obj=self, state='BLOCKED')\n",
    "                # [STATE:Job] BLOCKED\n",
    "                dispatcher.update_job_state(job=job, state='BLOCKED')\n",
    "                yield self.to_store(store=buffers, item=job, fail_delay=FAIL_DELAY, fail_priority=1)\n",
    "                if self.failed():\n",
    "                    raise UserWarning(f\"Store placement failed after {FAIL_DELAY} time steps. \\\n",
    "                        There seems to be deadlock.\")\n",
    "                # [STATE:Buffer] trigger state setting for target buffer\n",
    "                buffer = self.to_store_store()\n",
    "                if not isinstance(buffer, Buffer):\n",
    "                    #logger_prodStations.debug(f\"To store store object: {buffer}\")\n",
    "                    raise TypeError(f\"From {self}: Job {job} Obj {buffer} is no buffer type at {self.env.now()}\")\n",
    "                buffer.activate()\n",
    "                # [CONTENT:Buffer] add content\n",
    "                buffer.add_content(job=job)\n",
    "                # [STATS:Buffer] count number of inputs\n",
    "                buffer.num_inputs += 1\n",
    "                logger_prodStations.debug(f\"obj = {self} \\t type of buffer >>{buffer}<< = {type(buffer)} at {self.env.now()}\")\n",
    "            else:\n",
    "                # adding request to machine\n",
    "                # currently not possible because machines are components,\n",
    "                # but resources which could be requested are not\n",
    "                pass\n",
    "        \n",
    "        # [Job] enter logic queue after physical placement\n",
    "        job.enter(logic_queue)\n",
    "        # [STATS:WIP] REMOVING WIP FROM CURRENT STATION\n",
    "        # remove only if it was added before, only case if the last operation exists\n",
    "        if job.last_op is not None:\n",
    "            self.stat_monitor.change_WIP(job=job, remove=True)\n",
    "        # [STATS:WIP] ADDING WIP TO TARGET STATION\n",
    "        # add only if there is a next operation, only case if the current operation exists\n",
    "        if job.current_op is not None:\n",
    "            target_station.stat_monitor.change_WIP(job=job, remove=False)\n",
    "        \n",
    "        # activate target processing station if passive\n",
    "        if target_station.ispassive():\n",
    "            target_station.activate()\n",
    "        \n",
    "        logger_prodStations.debug(f\"[{self}] Put Job {job} in queue {logic_queue}\")\n",
    "    \n",
    "        # [STATE:InfrStructObj] WAITING\n",
    "        #print(f\"-------> {target_station=}, {job=}, {type(target_station)=}\")\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "        # [STATE:Job] successfully placed --> WAITING\n",
    "        dispatcher.update_job_state(job=job, state='WAITING')\n",
    "        # [STATS:InfrStructObj] count number of ouputs\n",
    "        self.num_outputs += 1\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def get_job(self) -> tuple[Job, float]:\n",
    "        \"\"\"\n",
    "        getting jobs from associated predecessor resources\n",
    "        \"\"\"\n",
    "        # entering target machine (logic_buffer)\n",
    "        ## logic_buffer: job queue regardless of physical buffers\n",
    "        ### entity physically on machine, but no true holding resource object (violates load-resource model)\n",
    "        ### no capacity restrictions between resources, e.g. source can endlessly produce entities\n",
    "        ## --- logic ---\n",
    "        ## job enters logic queue of machine with unrestricted capacity\n",
    "        ## each machine can have an associated physical buffer\n",
    "        dispatcher = self.env.dispatcher\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # request job from associated queue\n",
    "        job, job_proc_time = dispatcher.request_job_sequencing(req_obj=self)\n",
    "        \n",
    "        # request and get job from associated buffer if it exists\n",
    "        if self._buffers:\n",
    "            yield self.from_store(store=self._buffers, filter=lambda item: item.job_id == job.job_id)\n",
    "            buffer = self.from_store_store()\n",
    "            # [STATS:Buffer] count number of outputs\n",
    "            buffer.num_outputs += 1\n",
    "            # [CONTENT:Buffer] remove content\n",
    "            buffer.remove_content(job=job)\n",
    "            # [STATE:Buffer] trigger state setting for target buffer\n",
    "            buffer.activate()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # [STATE:InfrStructObj] set state to processing\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "        # [STATE:Job] successfully taken --> PROCESSING\n",
    "        dispatcher.update_job_state(job=job, state='PROCESSING')\n",
    "        \n",
    "        # [STATS:InfrStructObj] count number of inputs\n",
    "        self.num_outputs += 1\n",
    "        \n",
    "        return job, job_proc_time\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    # each method of 'pre_process', 'sim_control', 'post_process' must be implemented in the child classes\n",
    "    def pre_process(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No pre-process method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No sim-control method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def post_process(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No post-process method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def main_logic(self) -> Iterator[Any]:\n",
    "        \"\"\"main logic loop for all resources in the simulation environment\"\"\"\n",
    "        logger.debug(f\"----> Process logic of {self}\")\n",
    "        # pre control logic\n",
    "        ret = self.pre_process()\n",
    "        # main control logic\n",
    "        if ret is not None:\n",
    "            ret = yield from self.sim_control(*ret)\n",
    "        else:\n",
    "            ret = yield from self.sim_control()\n",
    "        # post control logic\n",
    "        if ret is not None:\n",
    "            ret = self.post_process(*ret)\n",
    "        else:\n",
    "            ret = self.post_process()\n",
    "            \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # set finish state for each infrastructure object no matter of which child class\n",
    "        infstruct_mgr.update_res_state(obj=self, state='FINISH')\n",
    "        # finalise stat gathering\n",
    "        self._stat_monitor.finalise_stats()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processingstation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingStation(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        buffers: Iterable[Buffer] | None = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env: simulation environment in which the infrastructure object is embedded\n",
    "        capacity: capacity of the infrastructure object, if multiple processing \\\n",
    "            slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        # intialize base class\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # station groups\n",
    "        ## REWORK: NEW TOP-DOWN-APPROACH\n",
    "        ## the object must be created first and is added to the supersystem later\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        \"\"\"\n",
    "        (self._station_group_id, \n",
    "         self._station_group) = infstruct_mgr.register_station_group(\n",
    "                                                        processing_station=self,\n",
    "                                                        custom_group_id=station_group_custom_id,\n",
    "                                                        station_group_name=station_group_name)\n",
    "        \"\"\"\n",
    "        \n",
    "        # add physical buffers, more than one allowed\n",
    "        # contrary to logic queues buffers are infrastructure objects and exist physically\n",
    "        if buffers is None:\n",
    "            self._buffers: set[Buffer] = set()\n",
    "        else:\n",
    "            self._buffers: set[Buffer] = set(buffers).copy()\n",
    "        \n",
    "        # add processing station to the associated ones of each buffer\n",
    "        # necessary because if the number of resources for one buffer exceeds its capacity\n",
    "        # deadlocks are possible\n",
    "        for buffer in self._buffers:\n",
    "            buffer.add_prod_station(prod_station=self)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def station_group_id(self) -> ObjectID:\n",
    "        return self._station_group_id\n",
    "    \n",
    "    @property\n",
    "    def station_group(self) -> StationGroup:\n",
    "        return self._station_group\n",
    "    \n",
    "    @property\n",
    "    def buffers(self) -> set[Buffer]:\n",
    "        return self._buffers\n",
    "    \n",
    "    def add_buffer(\n",
    "        self,\n",
    "        buffer: Buffer,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        adding buffer to the current associated ones\n",
    "        \"\"\"\n",
    "        # only buffer types allowed\n",
    "        if not isinstance(buffer, Buffer):\n",
    "            raise TypeError(f\"Object is no Buffer type. Only objects of type Buffer can be added as buffers.\")\n",
    "        # check if already present\n",
    "        if buffer not in self._buffers:\n",
    "            self._buffers.add(buffer)\n",
    "            buffer.add_prod_station(prod_station=self)\n",
    "        else:\n",
    "            logger_prodStations.warning(f\"The Buffer >>{buffer}<< is already associated with the resource >>{self}<<. \\\n",
    "                Buffer was not added to the resource.\")\n",
    "\n",
    "    def remove_buffer(\n",
    "        self,\n",
    "        buffer: Buffer,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        removing buffer from the current associated ones\n",
    "        \"\"\"\n",
    "        if buffer in self._buffers:\n",
    "            self._buffers.remove(buffer)\n",
    "            buffer.remove_prod_station(prod_station=self)\n",
    "        else:\n",
    "            raise KeyError(f\"The buffer >>{buffer}<< is not associated with the resource >>{self}<< and \\\n",
    "                therefore could not be removed.\")\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "        return None\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        dispatcher = self.env.dispatcher\n",
    "        while True:\n",
    "            # initialise state by passivating machines\n",
    "            # resources are activated by other resources\n",
    "            if len(self.logic_queue) == 0:\n",
    "                yield self.passivate()\n",
    "            logger_prodStations.debug(f\"[MACHINE: {self}] is getting job from queue\")\n",
    "            \n",
    "            # get job function from PARENT CLASS\n",
    "            # ONLY PROCESSING STATIONS ARE ASKING FOR SEQUENCING\n",
    "            # state setting --> 'PROCESSING'\n",
    "            job, job_proc_time = yield from self.get_job()\n",
    "            # [STATS:ProdStation] count number of inputs\n",
    "            self.num_inputs += 1\n",
    "            # [CONTENT:ProdStation] add content\n",
    "            self.add_content(job=job)\n",
    "            \n",
    "            # RELEVANT INFORMATION BEFORE PROCESSING\n",
    "            dispatcher.update_job_process_info(job=job, preprocess=True)\n",
    "            logger_prodStations.debug(f\"[START] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier} \\\n",
    "                with proc time {job_proc_time}\")\n",
    "            # PROCESSING\n",
    "            yield self.hold(job_proc_time)\n",
    "            # RELEVANT INFORMATION AFTER PROCESSING\n",
    "            dispatcher.update_job_process_info(job=job, preprocess=False)\n",
    "            \n",
    "            logger_prodStations.debug(f\"[END] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier}\")\n",
    "            # only place job if there are open operations left\n",
    "            # maybe add to 'put_job' method\n",
    "            target_proc_station = yield from self.put_job(job=job)\n",
    "            # [CONTENT:ProdStation] remove content\n",
    "            self.remove_content(job=job)\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        return None\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        # each resource object class has dedicated finalise methods which \n",
    "        # must be called by children\n",
    "        super().finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(ProcessingStation):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        resource_type: str = 'Machine',\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ADD LATER\n",
    "        \"\"\"\n",
    "        # assert object information\n",
    "        self.res_type = resource_type\n",
    "        \n",
    "        # intialize base class\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='buffer'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer(sim.Store, InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity: float,\n",
    "        resource_type: str = 'Buffer',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'FULL',\n",
    "            'EMPTY',\n",
    "            'INTERMEDIATE',\n",
    "            'FAILED',\n",
    "            'PAUSED',\n",
    "        ),\n",
    "        fill_level: int = 0,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        capacity: capacity of the buffer, can be infinite\n",
    "        \"\"\"\n",
    "        # assert object information\n",
    "        self.res_type = resource_type\n",
    "        self.start_fill_level = fill_level\n",
    "        \n",
    "        # intialize base classes\n",
    "        # using hard-coded classes because salabim does not provide \n",
    "        # interfaces for multiple inheritance\n",
    "        sim.Store.__init__(self, capacity=capacity, env=env)\n",
    "        InfrastructureObject.__init__(\n",
    "                            self, capacity=capacity, \n",
    "                            possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # material flow relationships\n",
    "        self._associated_prod_stations: set[ProcessingStation] = set()\n",
    "        self._count_associated_prod_stations: int = 0\n",
    "    \n",
    "    @property\n",
    "    def level_db(self) -> DataFrame:\n",
    "        return self._stat_monitor.level_db\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_fill_level(self) -> float:\n",
    "        return self._stat_monitor.wei_avg_fill_level\n",
    "    \n",
    "    \n",
    "    ### MATERIAL FLOW RELATIONSHIP\n",
    "    def add_prod_station(\n",
    "        self,\n",
    "        prod_station: ProcessingStation\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        function to add processing stations which are associated with \n",
    "        \"\"\"\n",
    "        if not isinstance(prod_station, ProcessingStation):\n",
    "            raise TypeError(f\"Object is no ProcessingStation type. Only objects of type ProcessingStation can be added to a buffer.\")\n",
    "        \n",
    "        # check if adding a new resource exceeds the given capacity\n",
    "        # each associated processing station needs one storage place in the buffer\n",
    "        # else deadlocks are possible\n",
    "        if (self._count_associated_prod_stations + 1) > self.cap:\n",
    "            raise UserWarning(f\"Tried to add a new resource to buffer {self}, but the number of associated \\\n",
    "                resources exceeds its capacity which could result in deadlocks.\")\n",
    "        \n",
    "        # check if processing station can be added\n",
    "        if prod_station not in self._associated_prod_stations:\n",
    "            self._associated_prod_stations.add(prod_station)\n",
    "            self._count_associated_prod_stations += 1\n",
    "        else:\n",
    "            logger_buffers.warning(f\"The Processing Station >>{prod_station}<< is already associated with the resource >>{self}<<. \\\n",
    "                Processing Station was not added to the resource.\")\n",
    "        \n",
    "    def remove_prod_station(\n",
    "        self,\n",
    "        prod_station: ProcessingStation\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        removing a processing station from the current associated ones\n",
    "        \"\"\"\n",
    "        if prod_station in self._associated_prod_stations:\n",
    "            self._associated_prod_stations.remove(prod_station)\n",
    "            self._count_associated_prod_stations -= 1\n",
    "        else:\n",
    "            raise KeyError(f\"The processing station >>{prod_station}<< is not associated with the resource >>{self}<< and \\\n",
    "                therefore could not be removed.\")\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='EMPTY')\n",
    "        return None\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        while True:\n",
    "            logger_prodStations.debug(f\"[BUFFER: {self}] Invoking at {self.env.now()}\")\n",
    "            # full\n",
    "            if self.available_quantity() == 0:\n",
    "                # [STATE] FULL\n",
    "                infstruct_mgr.update_res_state(obj=self, state='FULL')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Set to 'FULL' at {self.env.now()}\")\n",
    "            # empty\n",
    "            elif self.available_quantity() == self.capacity():\n",
    "                # [STATE] EMPTY\n",
    "                infstruct_mgr.update_res_state(obj=self, state='EMPTY')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Set to 'EMPTY' at {self.env.now()}\")\n",
    "            else:\n",
    "                # [STATE] INTERMEDIATE\n",
    "                infstruct_mgr.update_res_state(obj=self, state='INTERMEDIATE')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Neither 'EMPTY' nor 'FULL' at {self.env.now()}\")\n",
    "            \n",
    "            yield self.passivate()\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        return None\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        # each resource object class has dedicated finalise methods which \n",
    "        # must be called by children\n",
    "        super().finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.490652683415727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normalvariate(10, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- entity generation:\n",
    "    - constant\n",
    "    - random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='source'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Source(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        resource_type: str = 'Source',\n",
    "        proc_time: float = 1.,\n",
    "        random_generation: bool = False,\n",
    "        job_generator: RandomJobGenerator | None = None,\n",
    "        num_gen_jobs: int = 5,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        num_gen_jobs: total number of jobs to be generated\n",
    "        \"\"\"\n",
    "        # assert object information and register object in the environment\n",
    "        self.res_type = resource_type\n",
    "        \n",
    "        # random generation\n",
    "        if random_generation and job_generator is None:\n",
    "            raise ValueError(\"Random job generator instance needed for random job generation\")\n",
    "        \n",
    "        self.random_generation = random_generation\n",
    "        self.job_generator = job_generator\n",
    "        \n",
    "        ### REWORK\n",
    "        # initialize component with necessary process function\n",
    "        random.seed(42)\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # parameters\n",
    "        self.proc_time = proc_time\n",
    "        self.num_gen_jobs = num_gen_jobs\n",
    "    \n",
    "    def _obtain_proc_time(self) -> float:\n",
    "        \"\"\"\n",
    "        function to generate a constant or random processing time\n",
    "        \"\"\"\n",
    "        if self.random_generation:\n",
    "            # random generation, add later\n",
    "            return self.proc_time\n",
    "        else:\n",
    "            return self.proc_time\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "        return None\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        # id counter for debugging, else endless generation\n",
    "        count = 0\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        dispatcher = self.env.dispatcher\n",
    "        \n",
    "        # use machine custom identifiers for generation\n",
    "        machines = infstruct_mgr.res_db.loc[infstruct_mgr.res_db['res_type']=='Machine']\n",
    "        machines_custom_ids = machines['custom_id'].to_list()\n",
    "        \n",
    "        # use station group custom identifiers for generation\n",
    "        station_groups_custom_ids = infstruct_mgr.station_group_db['custom_id'].to_list()\n",
    "        \n",
    "        while count < self.num_gen_jobs:\n",
    "            # start at t=0 with generation\n",
    "            # generate object\n",
    "            ## random job properties\n",
    "            ## currently: each job passes each machine, only one machine of each operation type\n",
    "            #mat_ProcTimes, mat_JobMachID = self.job_generator.gen_rnd_job(n_machines=self.env.num_proc_stations)\n",
    "            #job = Job(dispatcher=dispatcher, proc_times=mat_ProcTimes.tolist(), \n",
    "            #          machine_order=mat_JobMachID.tolist())\n",
    "            #mat_ProcTimes, mat_JobMachID = self.job_generator.gen_rnd_job_by_ids(ids=machines_custom_ids)\n",
    "            mat_ProcTimes, mat_JobExOrder = self.job_generator.gen_rnd_job_by_ids(ids=station_groups_custom_ids, min_proc_time=5)\n",
    "            job = Job(dispatcher=dispatcher, proc_times=mat_ProcTimes, \n",
    "                      station_group_ex_order=mat_JobExOrder)\n",
    "            # [Call:DISPATCHER]\n",
    "            dispatcher.release_job(job=job)\n",
    "            # [STATS:Source] count number of inputs (source: generation of jobs or entry in pipeline)\n",
    "            # implemented in 'get_job' method which is not executed by source objects\n",
    "            self.num_inputs += 1\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Generated {job} at {self.env.now()}\")\n",
    "            \n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Request allocation...\")\n",
    "            # put job via 'put_job' function, implemented in parent class 'InfrastructureObject'\n",
    "            target_proc_station = yield from self.put_job(job=job)\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] PUT JOB with ret = {target_proc_station}\")\n",
    "            # [STATE:Source] put in 'WAITING' by 'put_job' method but still processing\n",
    "            # only 'WAITING' if all jobs are generated\n",
    "            infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "            \n",
    "            # hold for defined generation time (constant or statistically distributed)\n",
    "            # if hold time elapsed start new generation\n",
    "            proc_time = self._obtain_proc_time()\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Hold for >>{proc_time}<< at {self.env.now()}\")\n",
    "            yield self.hold(proc_time)\n",
    "            # set counter up\n",
    "            count += 1\n",
    "        \n",
    "        # [STATE:Source] WAITING\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sink(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        resource_type: str = 'Sink',\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        num_gen_jobs: total number of jobs to be generated\n",
    "        \"\"\"\n",
    "        # assert object information and register object in the environment\n",
    "        self.res_type = resource_type\n",
    "        \n",
    "        # initialize parent class\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    \n",
    "    ### STATE SETTING\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        # currently sinks are 'PROCESSING' the whole time\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "        return None\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        dispatcher = self.env.dispatcher\n",
    "        while True:\n",
    "            # in analogy to ProcessingStations\n",
    "            if len(self.logic_queue) == 0:\n",
    "                yield self.passivate()\n",
    "            \n",
    "            logger_sinks.debug(f\"[SINK: {self}] is getting job from queue\")\n",
    "            # get job, simple FIFO\n",
    "            job: Job = self.logic_queue.pop()\n",
    "            # [Call:DISPATCHER] data collection: finalise job\n",
    "            dispatcher.finish_job(job=job)\n",
    "            #job.finalise()\n",
    "            # destroy job object ???\n",
    "            # if job object destroyed, unsaved information is lost\n",
    "            # if not destroyed memory usage could increase\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimulationEnvironment(name='base')\n",
    "job_generator = RandomJobGenerator(seed=2)\n",
    "infstruct_mgr = InfrastructureManager(env=env)\n",
    "dispatcher = Dispatcher(env=env, priority_rule='FIFO')\n",
    "#buffer = Buffer(capacity=10, env=env, custom_identifier=10)\n",
    "custom_id = 0\n",
    "# resources\n",
    "for machine in range(1):\n",
    "    buffer = Buffer(capacity=20, env=env, custom_identifier=(10+machine))\n",
    "    \n",
    "    if machine >= 2:\n",
    "        custom_id += 1\n",
    "    \n",
    "    MachInst = Machine(env=env, custom_identifier=machine, buffers=[buffer],\n",
    "                       station_group_custom_id=custom_id, station_group_name='Bohrerei')\n",
    "    \n",
    "    if machine == 0:\n",
    "        buffbuff = buffer\n",
    "        machmach = MachInst\n",
    "    #MachInst = Machine(env=env, custom_identifier=machine)\n",
    "\n",
    "source = Source(env=env, custom_identifier='source', proc_time=1, \n",
    "                random_generation=True, job_generator=job_generator, num_gen_jobs=5)\n",
    "sink = Sink(env=env, custom_identifier='sink')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "      <td>Buffer_env_0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Machine (Machine_env_1)</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>Machine</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source</td>\n",
       "      <td>Source (Source_env_2)</td>\n",
       "      <td>Source_env_2</td>\n",
       "      <td>Source</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sink</td>\n",
       "      <td>Sink (Sink_env_3)</td>\n",
       "      <td>Sink_env_3</td>\n",
       "      <td>Sink</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                 resource           name res_type state\n",
       "res_id                                                                 \n",
       "0             10                       ()   Buffer_env_0   Buffer  INIT\n",
       "1              0  Machine (Machine_env_1)  Machine_env_1  Machine  INIT\n",
       "2         source    Source (Source_env_2)   Source_env_2   Source  INIT\n",
       "3           sink        Sink (Sink_env_3)     Sink_env_3     Sink  INIT"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 custom_id      name              station_group\n",
       "station_group_id                                               \n",
       "0                        0  Bohrerei  {Machine (Machine_env_1)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.station_group_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationGroup(custom_id: 0, name: Bohrerei)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.lookup_subsystem_info(\n",
    "    subsystem_type='StationGroup',\n",
    "    lookup_property='custom_id',\n",
    "    lookup_val=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.check_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FIFO', 'LIFO', 'LPT', 'SPT'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.possible_prio_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RANDOM', 'UTILISATION', 'WIP_LOAD_JOBS', 'WIP_LOAD_TIME'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.possible_alloc_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dispatcher:Changed allocation rule to WIP_LOAD_TIME\n"
     ]
    }
   ],
   "source": [
    "#dispatcher.curr_prio_rule = 'SPT'\n",
    "dispatcher.curr_alloc_rule = 'WIP_LOAD_TIME'\n",
    "#dispatcher.curr_alloc_rule = 'UTILISATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "      <td>Buffer_env_0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Machine (Machine_env_1)</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>Machine</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source</td>\n",
       "      <td>Source (Source_env_2)</td>\n",
       "      <td>Source_env_2</td>\n",
       "      <td>Source</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sink</td>\n",
       "      <td>Sink (Sink_env_3)</td>\n",
       "      <td>Sink_env_3</td>\n",
       "      <td>Sink</td>\n",
       "      <td>INIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                 resource           name res_type state\n",
       "res_id                                                                 \n",
       "0             10                       ()   Buffer_env_0   Buffer  INIT\n",
       "1              0  Machine (Machine_env_1)  Machine_env_1  Machine  INIT\n",
       "2         source    Source (Source_env_2)   Source_env_2   Source  INIT\n",
       "3           sink        Sink (Sink_env_3)     Sink_env_3     Sink  INIT"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 custom_id      name              station_group\n",
       "station_group_id                                               \n",
       "0                        0  Bohrerei  {Machine (Machine_env_1)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.station_group_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:base:----> Process logic of Buffer (Buffer_env_0)\n",
      "DEBUG:base:----> Process logic of Machine (Machine_env_1)\n",
      "DEBUG:base:----> Process logic of Source (Source_env_2)\n",
      "INFO:dispatcher:Successfully registered job with JobID 0 and name J_gen_0\n",
      "INFO:dispatcher:Successfully registered operation with OpID 0 and name O_gen_0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 0.0 are [Machine (Machine_env_1)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=Machine (Machine_env_1) is 0.00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 6, StationGroupID: 0) with machine group (machine) Machine (Machine_env_1)\n",
      "DEBUG:base:----> Process logic of Sink (Sink_env_3)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 1 and name J_gen_1\n",
      "INFO:dispatcher:Successfully registered operation with OpID 1 and name O_gen_1\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 1.0 are [Machine (Machine_env_1)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=Machine (Machine_env_1) is 6.00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 5, StationGroupID: 0) with machine group (machine) Machine (Machine_env_1)\n",
      "INFO:dispatcher:Successfully registered job with JobID 2 and name J_gen_2\n",
      "INFO:dispatcher:Successfully registered operation with OpID 2 and name O_gen_2\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 2.0 are [Machine (Machine_env_1)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=Machine (Machine_env_1) is 11.00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 7, StationGroupID: 0) with machine group (machine) Machine (Machine_env_1)\n",
      "INFO:dispatcher:Successfully registered job with JobID 3 and name J_gen_3\n",
      "INFO:dispatcher:Successfully registered operation with OpID 3 and name O_gen_3\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 3.0 are [Machine (Machine_env_1)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=Machine (Machine_env_1) is 18.00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 9, StationGroupID: 0) with machine group (machine) Machine (Machine_env_1)\n",
      "INFO:dispatcher:Successfully registered job with JobID 4 and name J_gen_4\n",
      "INFO:dispatcher:Successfully registered operation with OpID 4 and name O_gen_4\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 4.0 are [Machine (Machine_env_1)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=Machine (Machine_env_1) is 27.00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 8, StationGroupID: 0) with machine group (machine) Machine (Machine_env_1)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 6, StationGroupID: 0) ID 0 with [(6.0, 6.0)]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) Sink (Sink_env_3)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 5, StationGroupID: 0) ID 1 with [(11.0, 10.0)]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) Sink (Sink_env_3)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 7, StationGroupID: 0) ID 2 with [(18.0, 16.0)]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) Sink (Sink_env_3)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 9, StationGroupID: 0) ID 3 with [(27.0, 24.0)]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) Sink (Sink_env_3)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 8, StationGroupID: 0) ID 4 with [(35.0, 31.0)]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) Sink (Sink_env_3)\n"
     ]
    }
   ],
   "source": [
    "env.run()\n",
    "env.finalise_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.cycle_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "      <td>Buffer_env_0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Machine (Machine_env_1)</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source</td>\n",
       "      <td>Source (Source_env_2)</td>\n",
       "      <td>Source_env_2</td>\n",
       "      <td>Source</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sink</td>\n",
       "      <td>Sink (Sink_env_3)</td>\n",
       "      <td>Sink_env_3</td>\n",
       "      <td>Sink</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                 resource           name res_type   state\n",
       "res_id                                                                   \n",
       "0             10                       ()   Buffer_env_0   Buffer  FINISH\n",
       "1              0  Machine (Machine_env_1)  Machine_env_1  Machine  FINISH\n",
       "2         source    Source (Source_env_2)   Source_env_2   Source  FINISH\n",
       "3           sink        Sink (Sink_env_3)     Sink_env_3     Sink  FINISH"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mch = infstruct_mgr.lookup_subsystem_info(\n",
    "                                            subsystem_type='Resource',\n",
    "                                            lookup_property='custom_id',\n",
    "                                            lookup_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mch.stat_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sim_time  duration  level\n",
       "0       1.0       1.0   11.0\n",
       "1       2.0       1.0   18.0\n",
       "2       3.0       1.0   27.0\n",
       "3       4.0       1.0   35.0\n",
       "4       6.0       2.0   29.0\n",
       "5      11.0       5.0   24.0\n",
       "6      18.0       7.0   17.0\n",
       "7      27.0       9.0    8.0\n",
       "8      35.0       8.0    0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.WIP_time_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.142857142857142"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.wei_avg_WIP_level_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid",
          "shape": "vh",
          "width": 3
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          6,
          11,
          18,
          27,
          35
         ],
         "xaxis": "x",
         "y": [
          11,
          11,
          18,
          27,
          35,
          29,
          24,
          17,
          8,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "orange",
           "dash": "dot",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 13.142857142857142,
          "y1": 13.142857142857142,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "WIP Level Time of Machine (Machine_env_1)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "WIP Level Time [time units]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret = m.draw_WIP_level(use_num_jobs_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff = list(mch.buffers)\n",
    "buff = buff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid",
          "shape": "vh",
          "width": 3
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          6,
          11,
          18,
          27,
          35
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          1,
          2,
          3,
          4,
          3,
          2,
          1,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "orange",
           "dash": "dot",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 1.4857142857142858,
          "y1": 1.4857142857142858,
          "yref": "y"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 20,
          "y1": 20,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Fill Level of Buffer (Buffer_env_0)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "fill level [-]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = buff.stat_monitor.draw_fill_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4857142857142858"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.wei_avg_fill_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.custom_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=total time<br>state=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "total time",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "total time",
         "offsetgroup": "total time",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "BLOCKED",
          "FAILED",
          "FINISH",
          "INIT",
          "PAUSED",
          "PROCESSING",
          "TEMP",
          "WAITING"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          0,
          35,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "State Time Distribution of Machine (Machine_env_1)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "state"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "total time"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = machmach.stat_monitor.draw_state_bar_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>job</th>\n",
       "      <th>name</th>\n",
       "      <th>job_type</th>\n",
       "      <th>total_proc_time</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_0)</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>Job</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_1)</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>Job</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_2)</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>Job</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_3)</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>Job</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_4)</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>Job</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id            job     name job_type  total_proc_time   \n",
       "job_id                                                               \n",
       "0           None  Job (J_gen_0)  J_gen_0      Job              6.0  \\\n",
       "1           None  Job (J_gen_1)  J_gen_1      Job              5.0   \n",
       "2           None  Job (J_gen_2)  J_gen_2      Job              7.0   \n",
       "3           None  Job (J_gen_3)  J_gen_3      Job              9.0   \n",
       "4           None  Job (J_gen_4)  J_gen_4      Job              8.0   \n",
       "\n",
       "        creation_date  release_date  entry_date  exit_date  lead_time   state  \n",
       "job_id                                                                         \n",
       "0                 0.0           0.0         0.0        6.0        6.0  FINISH  \n",
       "1                 1.0           1.0         0.0       11.0       10.0  FINISH  \n",
       "2                 2.0           2.0         0.0       18.0       16.0  FINISH  \n",
       "3                 3.0           3.0         0.0       27.0       24.0  FINISH  \n",
       "4                 4.0           4.0         0.0       35.0       31.0  FINISH  "
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.job_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>op</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "      <th>station_group_custom_id</th>\n",
       "      <th>station_group_name</th>\n",
       "      <th>target_station_custom_id</th>\n",
       "      <th>target_station_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 6, StationGroupID: 0)</td>\n",
       "      <td>O_gen_0</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 5, StationGroupID: 0)</td>\n",
       "      <td>O_gen_1</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 7, StationGroupID: 0)</td>\n",
       "      <td>O_gen_2</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9, StationGroupID: 0)</td>\n",
       "      <td>O_gen_3</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 8, StationGroupID: 0)</td>\n",
       "      <td>O_gen_4</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>0</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id job_name custom_id                                         op   \n",
       "op_id                                                                         \n",
       "0           0  J_gen_0      None  Operation(ProcTime: 6, StationGroupID: 0)  \\\n",
       "1           1  J_gen_1      None  Operation(ProcTime: 5, StationGroupID: 0)   \n",
       "2           2  J_gen_2      None  Operation(ProcTime: 7, StationGroupID: 0)   \n",
       "3           3  J_gen_3      None  Operation(ProcTime: 9, StationGroupID: 0)   \n",
       "4           4  J_gen_4      None  Operation(ProcTime: 8, StationGroupID: 0)   \n",
       "\n",
       "          name              station_group station_group_custom_id   \n",
       "op_id                                                               \n",
       "0      O_gen_0  {Machine (Machine_env_1)}                       0  \\\n",
       "1      O_gen_1  {Machine (Machine_env_1)}                       0   \n",
       "2      O_gen_2  {Machine (Machine_env_1)}                       0   \n",
       "3      O_gen_3  {Machine (Machine_env_1)}                       0   \n",
       "4      O_gen_4  {Machine (Machine_env_1)}                       0   \n",
       "\n",
       "      station_group_name target_station_custom_id target_station_name   \n",
       "op_id                                                                   \n",
       "0               Bohrerei                        0       Machine_env_1  \\\n",
       "1               Bohrerei                        0       Machine_env_1   \n",
       "2               Bohrerei                        0       Machine_env_1   \n",
       "3               Bohrerei                        0       Machine_env_1   \n",
       "4               Bohrerei                        0       Machine_env_1   \n",
       "\n",
       "       duration  creation_date  release_date  entry_date  exit_date   \n",
       "op_id                                                                 \n",
       "0           6.0            0.0           0.0         0.0        6.0  \\\n",
       "1           5.0            1.0           1.0         6.0       11.0   \n",
       "2           7.0            2.0           2.0        11.0       18.0   \n",
       "3           9.0            3.0           3.0        18.0       27.0   \n",
       "4           8.0            4.0           4.0        27.0       35.0   \n",
       "\n",
       "       lead_time   state  \n",
       "op_id                     \n",
       "0            6.0  FINISH  \n",
       "1           10.0  FINISH  \n",
       "2           16.0  FINISH  \n",
       "3           24.0  FINISH  \n",
       "4           31.0  FINISH  "
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.op_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = dispatcher.get_job_obj_by_prop(val=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs [timesteps]</th>\n",
       "      <th>rel [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLOCKED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAUSED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROCESSING</th>\n",
       "      <td>8.0</td>\n",
       "      <td>25.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAITING</th>\n",
       "      <td>23.0</td>\n",
       "      <td>74.193548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            abs [timesteps]    rel [%]\n",
       "BLOCKED                 0.0   0.000000\n",
       "FAILED                  0.0   0.000000\n",
       "PAUSED                  0.0   0.000000\n",
       "PROCESSING              8.0  25.806452\n",
       "WAITING                23.0  74.193548"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.stat_monitor.state_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = job.operations[0]\n",
    "#op2 = job.operations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WAITING': 23.0,\n",
       " 'BLOCKED': 0.0,\n",
       " 'PAUSED': 0.0,\n",
       " 'INIT': 0.0,\n",
       " 'FINISH': 0.0,\n",
       " 'TEMP': 0.0,\n",
       " 'PROCESSING': 8.0,\n",
       " 'FAILED': 0.0}"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op1.stat_monitor.state_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "      <td>Buffer_env_0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Machine (Machine_env_1)</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source</td>\n",
       "      <td>Source (Source_env_2)</td>\n",
       "      <td>Source_env_2</td>\n",
       "      <td>Source</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sink</td>\n",
       "      <td>Sink (Sink_env_3)</td>\n",
       "      <td>Sink_env_3</td>\n",
       "      <td>Sink</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                 resource           name res_type   state\n",
       "res_id                                                                   \n",
       "0             10                       ()   Buffer_env_0   Buffer  FINISH\n",
       "1              0  Machine (Machine_env_1)  Machine_env_1  Machine  FINISH\n",
       "2         source    Source (Source_env_2)   Source_env_2   Source  FINISH\n",
       "3           sink        Sink (Sink_env_3)     Sink_env_3     Sink  FINISH"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WAITING': 0.0,\n",
       " 'BLOCKED': 0.0,\n",
       " 'PAUSED': 0.0,\n",
       " 'INIT': 0.0,\n",
       " 'FINISH': 0.0,\n",
       " 'TEMP': 0.0,\n",
       " 'PROCESSING': 35.0,\n",
       " 'FAILED': 0.0}"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = infstruct_mgr.lookup_subsystem_info(\n",
    "                                        subsystem_type='Resource',\n",
    "                                        lookup_property='custom_id',\n",
    "                                        lookup_val=0)\n",
    "mach.stat_monitor.state_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bohrerei</td>\n",
       "      <td>{Machine (Machine_env_1)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 custom_id      name              station_group\n",
       "station_group_id                                               \n",
       "0                        0  Bohrerei  {Machine (Machine_env_1)}"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.station_group_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "base": [
          0
         ],
         "hovertemplate": "job_name=J_gen_0<br>entry_date=%{base}<br>exit_date=%{x}<br>target_station_custom_id=%{y}<extra></extra>",
         "legendgroup": "J_gen_0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_0",
         "offsetgroup": "J_gen_0",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6
         ],
         "xaxis": "x",
         "y": [
          0
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          6
         ],
         "hovertemplate": "job_name=J_gen_1<br>entry_date=%{base}<br>exit_date=%{x}<br>target_station_custom_id=%{y}<extra></extra>",
         "legendgroup": "J_gen_1",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_1",
         "offsetgroup": "J_gen_1",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          5
         ],
         "xaxis": "x",
         "y": [
          0
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          11
         ],
         "hovertemplate": "job_name=J_gen_2<br>entry_date=%{base}<br>exit_date=%{x}<br>target_station_custom_id=%{y}<extra></extra>",
         "legendgroup": "J_gen_2",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_2",
         "offsetgroup": "J_gen_2",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          7
         ],
         "xaxis": "x",
         "y": [
          0
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          18
         ],
         "hovertemplate": "job_name=J_gen_3<br>entry_date=%{base}<br>exit_date=%{x}<br>target_station_custom_id=%{y}<extra></extra>",
         "legendgroup": "J_gen_3",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_3",
         "offsetgroup": "J_gen_3",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          9
         ],
         "xaxis": "x",
         "y": [
          0
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          27
         ],
         "hovertemplate": "job_name=J_gen_4<br>entry_date=%{base}<br>exit_date=%{x}<br>target_station_custom_id=%{y}<extra></extra>",
         "legendgroup": "J_gen_4",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_4",
         "offsetgroup": "J_gen_4",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          8
         ],
         "xaxis": "x",
         "y": [
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "title": {
          "text": "job_name"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "target_station_custom_id"
         },
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = dispatcher.draw_gantt_chart(use_custom_proc_station_id=True, \n",
    "                                  sort_by_proc_station=True, \n",
    "                                  group_by_station_group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "      <td>Buffer_env_0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Machine (Machine_env_1)</td>\n",
       "      <td>Machine_env_1</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source</td>\n",
       "      <td>Source (Source_env_2)</td>\n",
       "      <td>Source_env_2</td>\n",
       "      <td>Source</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sink</td>\n",
       "      <td>Sink (Sink_env_3)</td>\n",
       "      <td>Sink_env_3</td>\n",
       "      <td>Sink</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                 resource           name res_type   state\n",
       "res_id                                                                   \n",
       "0             10                       ()   Buffer_env_0   Buffer  FINISH\n",
       "1              0  Machine (Machine_env_1)  Machine_env_1  Machine  FINISH\n",
       "2         source    Source (Source_env_2)   Source_env_2   Source  FINISH\n",
       "3           sink        Sink (Sink_env_3)     Sink_env_3     Sink  FINISH"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_gr = infstruct_mgr.lookup_subsystem_info(\n",
    "                                            subsystem_type='StationGroup',\n",
    "                                            lookup_property='custom_id',\n",
    "                                            lookup_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lst = stat_gr.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Machine (Machine_env_1)]"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = stat_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs [timesteps]</th>\n",
       "      <th>rel [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLOCKED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAUSED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROCESSING</th>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAITING</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            abs [timesteps]  rel [%]\n",
       "BLOCKED                 0.0      0.0\n",
       "FAILED                  0.0      0.0\n",
       "PAUSED                  0.0      0.0\n",
       "PROCESSING             35.0    100.0\n",
       "WAITING                 0.0      0.0"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.stat_monitor.state_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.custom_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Load Objects**\n",
    "\n",
    "*Changes for station groups:*\n",
    "- operations now contain station identifiers instead of machine identifiers\n",
    "- operation registration in the dispatcher now assigns station groups rather than specific machines\n",
    "- allocation request in the dispatcher now chooses between machines in the associated machine group; if there is only one (single-machine case) then there are no parallel machines\n",
    "- allocation request also returns associated buffers **--> buffer management implemented in Dispatcher**\n",
    "\n",
    "*Buffers:*\n",
    "\n",
    "~~3 ways to implement buffers with station groups~~:\n",
    "1. one buffer for the whole group\n",
    "1. one buffer for each machine\n",
    "1. mix case: buffer for each machine plus one station group buffer\n",
    "\n",
    "**Station groups are accessed to obtain processing stations which havee associated buffers --> nothin changes compared to the current behaviour**\n",
    "\n",
    "*Job creation:*\n",
    "- now each job must contain a list of station group identifiers instead of machine identifiers\n",
    "- for random generation there has to be information about the order of station groups and how many station groups exist\n",
    "    - currently implemented: each job passes each machine\n",
    "    - next step: each job passes each machine group, so the random order now consists of a permutation of the station group identifiers instead of the machine identifiers --> information available in the station group database of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dispatcher'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        priority_rule: str = 'FIFO',\n",
    "        allocation_rule: str = 'RANDOM',\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dispatcher class for given environment (only one dispatcher for each environment)\n",
    "        - different functions to monitor all jobs in the environment\n",
    "        - jobs report back their states to the dispatcher\n",
    "        \"\"\"\n",
    "        \n",
    "        # job data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._job_prop: dict[str, type] = {\n",
    "            'job_id': int,\n",
    "            'custom_id': object,\n",
    "            'job': object,\n",
    "            'name': str,\n",
    "            'job_type': str,\n",
    "            'total_proc_time': float,\n",
    "            'creation_date': float,\n",
    "            'release_date': float,\n",
    "            'entry_date': float,\n",
    "            'exit_date': float,\n",
    "            'lead_time': float,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._job_db: DataFrame = pd.DataFrame(columns=list(self._job_prop.keys()))\n",
    "        self._job_db: DataFrame = self._job_db.astype(self._job_prop)\n",
    "        self._job_db: DataFrame = self._job_db.set_index('job_id')\n",
    "        # properties by which a object can be obtained from the job database\n",
    "        self._job_lookup_props: set[str] = set(['job_id', 'custom_id', 'name'])\n",
    "        # properties which can be updated after creation\n",
    "        self._job_update_props: set[str] = set([\n",
    "            'creation_date',\n",
    "            'release_date',\n",
    "            'entry_date',\n",
    "            'exit_date',\n",
    "            'lead_time',\n",
    "            'state',\n",
    "        ])\n",
    "        \n",
    "        # operation data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._op_prop: dict[str, type] = {\n",
    "            'op_id': int,\n",
    "            'job_id': int,\n",
    "            'job_name': str,\n",
    "            'custom_id': object,\n",
    "            'op': object,\n",
    "            'name': str,\n",
    "            'station_group': object,\n",
    "            'station_group_custom_id': object,\n",
    "            'station_group_name': str,\n",
    "            'target_station_custom_id': object,\n",
    "            'target_station_name': str,\n",
    "            'duration': float,\n",
    "            'creation_date': float,\n",
    "            'release_date': float,\n",
    "            'entry_date': float,\n",
    "            'exit_date': float,\n",
    "            'lead_time': float,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._op_db: DataFrame = pd.DataFrame(columns=list(self._op_prop.keys()))\n",
    "        self._op_db: DataFrame = self._op_db.astype(self._op_prop)\n",
    "        self._op_db: DataFrame = self._op_db.set_index('op_id')\n",
    "        # properties by which a object can be obtained from the operation database\n",
    "        self._op_lookup_props: set[str] = set(['op_id', 'job_id', 'custom_id', 'name', 'machine'])\n",
    "        # properties which can be updated after creation\n",
    "        self._op_update_props: set[str] = set([\n",
    "            'target_station_custom_id',\n",
    "            'target_station_name',\n",
    "            'creation_date',\n",
    "            'release_date',\n",
    "            'entry_date',\n",
    "            'exit_date',\n",
    "            'lead_time',\n",
    "            'state',\n",
    "        ])\n",
    "        \n",
    "        # register in environment and get EnvID\n",
    "        self._env = env\n",
    "        self._env.register_dispatcher(self)\n",
    "        \n",
    "        ########## PERHAPS REWORK ##########\n",
    "        self._disposable_jobs: dict[int, Job] = dict()\n",
    "        self.job_pool: OrderedDict[ObjectID, Job] = OrderedDict()\n",
    "        ####################################\n",
    "        # managing IDs\n",
    "        self._id_types = set(['job', 'op'])\n",
    "        self._job_id_counter: ObjectID = 0\n",
    "        self._op_id_counter: ObjectID = 0\n",
    "        \n",
    "        # priority rules\n",
    "        self._priority_rules: set[str] = set([\n",
    "            'FIFO',\n",
    "            'LIFO',\n",
    "            'SPT',\n",
    "            'LPT',\n",
    "        ])\n",
    "        # set current priority rule\n",
    "        if priority_rule not in self._priority_rules:\n",
    "            raise ValueError(f\"Priority rule {priority_rule} unknown. Must be one of {self._priority_rules}\")\n",
    "        else:\n",
    "            self._curr_prio_rule = priority_rule\n",
    "            \n",
    "        # allocation rule\n",
    "        self._allocation_rules: set[str] = set([\n",
    "            'RANDOM',\n",
    "            'UTILISATION',\n",
    "            'WIP_LOAD_TIME',\n",
    "            'WIP_LOAD_JOBS',\n",
    "        ])\n",
    "        # set current allocation rule\n",
    "        if allocation_rule not in self._allocation_rules:\n",
    "            raise ValueError(f\"Allocation rule {allocation_rule} unknown. Must be one of {self._allocation_rules}\")\n",
    "        else:\n",
    "            self._curr_alloc_rule = allocation_rule\n",
    "            \n",
    "        # [STATS] cycle time\n",
    "        self._cycle_time: float = 0.\n",
    "    \n",
    "    ### DATA MANAGEMENT\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Dispatcher(env: {self.env.name()})\"\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def curr_prio_rule(self) -> str:\n",
    "        return self._curr_prio_rule\n",
    "    \n",
    "    @curr_prio_rule.setter\n",
    "    def curr_prio_rule(self, rule) -> None:\n",
    "        if rule not in self._priority_rules:\n",
    "            raise ValueError(f\"Priority rule {rule} unknown. Must be one of {self._priority_rules}\")\n",
    "        else:\n",
    "            self._curr_prio_rule = rule\n",
    "            logger_dispatcher.info(f\"Changed priority rule to {rule}\")\n",
    "            \n",
    "    def possible_prio_rules(self) -> set[str]:\n",
    "        return self._priority_rules\n",
    "    \n",
    "    @property\n",
    "    def curr_alloc_rule(self) -> str:\n",
    "        return self._curr_alloc_rule\n",
    "    \n",
    "    @curr_alloc_rule.setter\n",
    "    def curr_alloc_rule(self, rule) -> None:\n",
    "        if rule not in self._allocation_rules:\n",
    "            raise ValueError(f\"Allocation rule {rule} unknown. Must be one of {self._allocation_rules}\")\n",
    "        else:\n",
    "            self._curr_alloc_rule = rule\n",
    "            logger_dispatcher.info(f\"Changed allocation rule to {rule}\")\n",
    "            \n",
    "    def possible_alloc_rules(self) -> set[str]:\n",
    "        return self._allocation_rules\n",
    "    \n",
    "    def _obtain_job_id(self) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing job IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        job_id = self._id_counter\n",
    "        self._id_counter += 1\n",
    "        \n",
    "        return job_id\n",
    "    \n",
    "    def _obtain_op_id(self) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing operation IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        op_id = self._op_id_counter\n",
    "        self._op_id_counter += 1\n",
    "        \n",
    "        return op_id\n",
    "    \n",
    "    def _obtain_load_obj_id(\n",
    "        self,\n",
    "        load_type: str,\n",
    "    ) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing operation IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        \n",
    "        if load_type not in self._id_types:\n",
    "            raise ValueError(f\"Given type {type} not valid. Choose from '{self._id_types}'\")\n",
    "        \n",
    "        match load_type:\n",
    "            case 'job':\n",
    "                ident_no = self._job_id_counter\n",
    "                self._job_id_counter += 1\n",
    "            case 'op':\n",
    "                ident_no = self._op_id_counter\n",
    "                self._op_id_counter += 1\n",
    "        \n",
    "        return ident_no\n",
    "    \n",
    "    @property\n",
    "    def cycle_time(self) -> float:\n",
    "        return self._cycle_time\n",
    "    \n",
    "    def _calc_cycle_time(self) -> None:\n",
    "        \"\"\"Obtaining the current cycle time or maximum exit date of all operations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            maximum exit date of all operations at the time of execution\n",
    "        \"\"\"\n",
    "        self._cycle_time = self._op_db['exit_date'].max()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    ### JOBS ###\n",
    "    def register_job(\n",
    "        self,\n",
    "        obj: Job,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) -> tuple[SimulationEnvironment, ObjectID, str, float]:\n",
    "        \"\"\"\n",
    "        ######################## REWORK\n",
    "        registers an job object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated jobs\n",
    "        \n",
    "        object:     env resource\n",
    "        returns:\n",
    "            env_id: assigned env ID\n",
    "        \"\"\"\n",
    "        # obtain id\n",
    "        job_id = self._obtain_load_obj_id(load_type='job')\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'J_gen_{job_id}'\n",
    "        \n",
    "        # time of creation\n",
    "        creation_date = self.env.now()\n",
    "        \n",
    "        # new entry for job data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'job_id': [job_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'job': [obj],\n",
    "                                'name': [name],\n",
    "                                'job_type': [obj.job_type],\n",
    "                                'total_proc_time': [obj.total_proc_time],\n",
    "                                'creation_date': [creation_date],\n",
    "                                'release_date': [obj.time_release],\n",
    "                                'entry_date': [obj.time_entry],\n",
    "                                'exit_date': [obj.time_exit],\n",
    "                                'lead_time': [obj.lead_time],\n",
    "                                'state': [state]})\n",
    "        new_entry = new_entry.astype(self._job_prop)\n",
    "        new_entry = new_entry.set_index('job_id')\n",
    "        self._job_db = pd.concat([self._job_db, new_entry])\n",
    "        \n",
    "        logger_dispatcher.info(f\"Successfully registered job with JobID {job_id} and name {name}\")\n",
    "        \n",
    "        return self.env, job_id, name, creation_date\n",
    "    \n",
    "    def update_job_db(\n",
    "        self,\n",
    "        job: Job,\n",
    "        property: str,\n",
    "        val: float | str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        updates the information of a job for a given porperty\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_update_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_update_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        self._job_db.at[job.job_id, property] = val\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def release_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the release of the given job\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        current_time = self.env.now()\n",
    "        job.time_release = current_time\n",
    "        job.is_released = True\n",
    "        self.update_job_db(job=job, property='release_date', val=job.time_release)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def finish_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the exit of the given job\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        # [STATS]\n",
    "        current_time = self.env.now()\n",
    "        job.time_exit = current_time\n",
    "        job.is_finished = True\n",
    "        job.lead_time = job.time_exit - job.time_release\n",
    "        # update databases\n",
    "        self.update_job_state(job=job, state='FINISH')\n",
    "        self.update_job_db(job=job, property='exit_date', val=job.time_exit)\n",
    "        self.update_job_db(job=job, property='lead_time', val=job.lead_time)\n",
    "        # [MONITOR] finalise stats\n",
    "        job.stat_monitor.finalise_stats()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def update_job_process_info(\n",
    "        self,\n",
    "        job: Job,\n",
    "        preprocess: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        method to write necessary information of the current operation before and after processing,\n",
    "        invoked by Infrastructure Objects\n",
    "        \"\"\"\n",
    "        # get current operation of the job instance\n",
    "        current_op = job.current_op\n",
    "        # before processing\n",
    "        if preprocess:\n",
    "            # operation enters Processing Station\n",
    "            #self.release_operation(op=current_op)\n",
    "            self.enter_operation(op=current_op)\n",
    "            ############# ENTRY OF JOB\n",
    "            #current_op.start_time = self.env.now()\n",
    "            return None\n",
    "        # after processing\n",
    "        else:\n",
    "            # finalise current op\n",
    "            #logger_dispatcher.debug(f\"OP {current_op} is finalised\")\n",
    "            self.finish_operation(op=current_op)\n",
    "            #current_op.finalise()\n",
    "            job.num_finished_ops += 1\n",
    "            \n",
    "            return None\n",
    "    \n",
    "    def update_job_state(\n",
    "        self,\n",
    "        job: Job,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a job in the job database\"\"\"\n",
    "        # update state tracking of the job instance\n",
    "        job.stat_monitor.set_state(state=state)\n",
    "        # update job database\n",
    "        self.update_job_db(job=job, property='state', val=state)\n",
    "        # only update operation state if it is not finished\n",
    "        # operations are finished by post-process call to their 'finalise' method\n",
    "        \n",
    "        # update state of the corresponding operation\n",
    "        if job.current_op is not None:\n",
    "            self.update_operation_state(op=job.current_op, state=state)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    ### OPERATIONS ###\n",
    "    def register_operation(\n",
    "        self,\n",
    "        obj: Operation,\n",
    "        station_group_identifier: CustomID,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) -> tuple[ObjectID, str, ProcessingStation, float]:\n",
    "        \"\"\"\n",
    "        registers an operation object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated operations\n",
    "        \n",
    "        obj: operation to register\n",
    "        machine_identifier: custom ID of the associated machine (user interface)\n",
    "        custom_identifier: custom identifier of the operation \n",
    "            (kept for consistency reasons, perhaps remove later)\n",
    "        name: assigned name the operation\n",
    "        status: for future features if status of operations is tracked\n",
    "        \n",
    "        outputs:\n",
    "        op_id: assigned operation ID\n",
    "        name: assigned name\n",
    "        machine: corresponding machine infrastructure object\n",
    "        \"\"\"\n",
    "        # infrastructure manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        \n",
    "        # obtain id\n",
    "        op_id = self._obtain_load_obj_id(load_type='op')\n",
    "        # time of creation\n",
    "        creation_date = self.env.now()\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'O_gen_{op_id}'\n",
    "        \n",
    "        # corresponding machine object on which operation is performed\n",
    "        #machine = self._env.get_res_obj_by_prop(property='custom_id', val=machine_identifier)\n",
    "        # corresponding machine object on which operation is performed\n",
    "        station_group = infstruct_mgr.lookup_subsystem_info(\n",
    "                                                    subsystem_type='StationGroup',\n",
    "                                                    lookup_property='custom_id',\n",
    "                                                    lookup_val=station_group_identifier)\n",
    "        \n",
    "        # new entry for operation data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'op_id': [op_id],\n",
    "                                'job_id': [obj.job_id],\n",
    "                                'job_name': [obj.job.name()],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'op': [obj],\n",
    "                                'name': [name],\n",
    "                                'station_group': [station_group],\n",
    "                                'station_group_custom_id': [station_group.custom_identifier],\n",
    "                                'station_group_name': [station_group.name],\n",
    "                                'target_station_custom_id': [None],\n",
    "                                'target_station_name': [None],\n",
    "                                'duration': [obj.proc_time],\n",
    "                                'creation_date': [creation_date],\n",
    "                                'release_date': [obj.time_release],\n",
    "                                'entry_date': [obj.time_entry],\n",
    "                                'exit_date': [obj.time_exit],\n",
    "                                'lead_time': [obj.lead_time],\n",
    "                                'state': [state]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._op_prop)\n",
    "        new_entry = new_entry.set_index('op_id')\n",
    "        self._op_db = pd.concat([self._op_db, new_entry])\n",
    "        \n",
    "        logger_dispatcher.info(f\"Successfully registered operation with OpID {op_id} and name {name}\")\n",
    "        \n",
    "        # return machine object\n",
    "        return op_id, name, station_group, creation_date\n",
    "    \n",
    "    def update_operation_db(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        property: str,\n",
    "        val: float | str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        updates the information of a job for a given porperty\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._op_update_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._op_update_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        self._op_db.at[op.op_id, property] = val\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def update_operation_state(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a operation in the operation database\"\"\"\n",
    "        # update state tracking of the operation instance\n",
    "        op.stat_monitor.set_state(state=state)\n",
    "        # update operation database\n",
    "        self.update_operation_db(op=op, property='state', val=state)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def release_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        target_station: ProcessingStation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the release of the given operation\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        current_time = self.env.now()\n",
    "        # release time\n",
    "        op.time_release = current_time\n",
    "        op.is_released = True\n",
    "        # update operation database\n",
    "        # release date\n",
    "        self.update_operation_db(op=op, property='release_date', val=op.time_release)\n",
    "        # target station: custom identifier + name\n",
    "        self.update_operation_db(\n",
    "                    op=op, property='target_station_custom_id', \n",
    "                    val=target_station.custom_identifier)\n",
    "        self.update_operation_db(\n",
    "                    op=op, property='target_station_name', \n",
    "                    val=target_station.name())\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def enter_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the start of the given operation on a Processing Station\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        current_time = self.env.now()\n",
    "        # starting time processing\n",
    "        op.time_entry = current_time\n",
    "        # update operation database\n",
    "        self.update_operation_db(op=op, property='entry_date', val=op.time_entry)\n",
    "        \n",
    "        return None\n",
    "     \n",
    "    def finish_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the finalisation of the given operation\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        current_time = self.env.now()\n",
    "        # [STATE] finished\n",
    "        op.is_finished = True\n",
    "        # [STATS] end + lead time\n",
    "        op.time_exit = current_time\n",
    "        op.lead_time = op.time_exit - op.time_release\n",
    "        \n",
    "        # update databases\n",
    "        logger_dispatcher.debug(f\"Update databases for OP {op} ID {op.op_id} with [{op.time_exit, op.lead_time}]\")\n",
    "        self.update_operation_state(op=op, state='FINISH')\n",
    "        self.update_operation_db(op=op, property='exit_date', val=op.time_exit)\n",
    "        self.update_operation_db(op=op, property='lead_time', val=op.lead_time)\n",
    "        \n",
    "        # [MONITOR] finalise stats\n",
    "        op.stat_monitor.finalise_stats()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    ### PROPERTIES ###\n",
    "    @property\n",
    "    def job_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered jobs in the environment\n",
    "        \"\"\"\n",
    "        return self._job_db\n",
    "    \n",
    "    @property\n",
    "    def op_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered operations in the environment\n",
    "        \"\"\"\n",
    "        return self._op_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_job_obj_by_prop(\n",
    "        self, \n",
    "        val: EnvID | CustomID | str,\n",
    "        property: str = 'job_id',\n",
    "        target_prop: str = 'job',\n",
    "    ) -> Job:\n",
    "        \"\"\"\n",
    "        obtain a job object from the dispatcher by its property and corresponding value\n",
    "        properties: job_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'job_id':\n",
    "            # direct indexing for ID property; job_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: Job = self._job_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no jobs found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._job_db.loc[self._job_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no jobs found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_dispatcher.warning(f\"CAUTION: There are multiple jobs which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "            \n",
    "            return temp1.iat[0]\n",
    "    \n",
    "    ### ROUTING LOGIC ###\n",
    "    def request_job_allocation(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> InfrastructureObject:\n",
    "        \"\"\"\n",
    "        request an allocation decision for the given job \n",
    "        (determine the next processing station on which the job shall be placed)\n",
    "        \n",
    "        1. obtaining the target station group\n",
    "        2. select from target station group (e.g. calling RL agent for that group)\n",
    "        3. return target station (InfrastructureObject)\n",
    "        \n",
    "        requester: output side infrastructure object\n",
    "        request for: infrastructure object instance\n",
    "        \"\"\"\n",
    "        # SIGNALING ALLOCATION DECISION\n",
    "        # (ONLY IF PARALLEL PROCESSING STATIONS EXIST)\n",
    "        ## theoretically: obtaining next operation --> information about machine group -->\n",
    "        ## based on machine group: choice of corresponding allocation agent -->\n",
    "        ## preparing feature vectors as input --> trigger agent decision -->\n",
    "        ## map decision to processing station\n",
    "        \n",
    "        logger_dispatcher.info(f\"[DISPATCHER: {self}] REQUEST TO DISPATCHER FOR ALLOCATION\")\n",
    "        \n",
    "        ## REWORK: NEW TOP-DOWN-APPROACH\n",
    "        # routing of jobs is now organized in a hierarchical fashion and can be described\n",
    "        # for each hierarchy level separately\n",
    "        # routing in Production Areas --> Station Groups --> Processing Stations\n",
    "        # so each job must contain information about the production areas and the corresponding station groups\n",
    "        \n",
    "        ## choice from station group stays as method\n",
    "        # routing essentially depending on production areas --> JOB FROM AREA TO AREA\n",
    "        # NOW DIFFERENTIATE:\n",
    "        ### (1) choice between station groups of the current area\n",
    "        #           placement on machines outside the station group not possible\n",
    "        ### (2) choice between processing stations of the current area\n",
    "        #           placement on machines outside the station group possible, \n",
    "        #           but the stations could be filtered by their station group IDs\n",
    "        \n",
    "        \n",
    "        # get the next operation of the job\n",
    "        next_op = job.get_next_operation()\n",
    "        if next_op is not None:\n",
    "            # select target station from the operation's station group\n",
    "            target_station = self._choose_target_station_from_group(\n",
    "                                            station_group=next_op.target_station_group)\n",
    "            # with allocation request operation is released\n",
    "            self.release_operation(op=next_op, target_station=target_station)\n",
    "        # all operations done, look for sinks\n",
    "        else:\n",
    "            infstruct_mgr = self.env.infstruct_mgr\n",
    "            sinks = list(infstruct_mgr.sinks)\n",
    "            # [PERHAPS CHANGE IN FUTURE]\n",
    "            # use first sink of the registered ones\n",
    "            target_station = sinks[0]\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] Next operation is {next_op} with machine group (machine) {target_station}\")\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def _choose_target_station_from_group(\n",
    "        self,\n",
    "        station_group: StationGroup,\n",
    "    ) -> ProcessingStation:\n",
    "        \"\"\"Choosing a target station from a given Station Group\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        station_group : StationGroup\n",
    "            station group from which the target station should be obtained\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        target_station: ProcessingStation\n",
    "            station object on which the job should be placed\n",
    "        \"\"\"\n",
    "        # infrastructure manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        \n",
    "        # [KPIs] calculate necessary information for decision making\n",
    "        # put all associated processing stations of that group in 'TEMP' state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=station_group, reset_temp=False)\n",
    "        \n",
    "        # stations in list\n",
    "        stations = station_group.as_list()\n",
    "        \n",
    "        # choose only from available processing stations\n",
    "        candidates = [ps for ps in stations if ps.stat_monitor.is_available]\n",
    "        # check if there are available processing stations\n",
    "        # if not: use all stations\n",
    "        if candidates:\n",
    "            avail_stations = candidates\n",
    "        else:\n",
    "            avail_stations = stations\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] Available stations at {self.env.now()} are {avail_stations}\")\n",
    "        \n",
    "        # apply different strategies to select a station out of the station group\n",
    "        match self._curr_alloc_rule:\n",
    "            case 'RANDOM':\n",
    "                # [RANDOM CHOICE]\n",
    "                target_station: ProcessingStation = random.choice(avail_stations)\n",
    "            case 'UTILISATION':\n",
    "                # [UTILISATION]\n",
    "                # choose the station with the lowest utilisation to time\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.utilisation'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] Utilisation of {target_station=} is {target_station.stat_monitor.utilisation:.4f}\")\n",
    "            case 'WIP_LOAD_TIME':\n",
    "                # WIP as load/processing time, choose station with lowest WIP\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.WIP_load_time'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD TIME of {target_station=} is {target_station.stat_monitor.WIP_load_time:.2f}\")\n",
    "            case 'WIP_LOAD_JOBS':\n",
    "                # WIP as number of associated jobs, choose station with lowest WIP\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.WIP_load_num_jobs'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD NUM JOBS of {target_station=} is {target_station.stat_monitor.WIP_load_time:.2f}\")\n",
    "        \n",
    "        # [KPIs] reset all associated processing stations of that group to their original state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=station_group, reset_temp=True)\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def request_job_sequencing(\n",
    "        self,\n",
    "        req_obj: ProcessingStation\n",
    "    ) -> tuple[Job, float]:\n",
    "        \"\"\"\n",
    "        request a sequencing decision for a given queue of the requesting resource\n",
    "        requester: input side processing stations\n",
    "        request for: job instance\n",
    "        \n",
    "        req_obj: requesting object (ProcessingStation)\n",
    "        \"\"\"\n",
    "        # SIGNALING SEQUENCING DECISION\n",
    "        # (ONLY IF MULTIPLE JOBS IN THE QUEUE EXIST)\n",
    "        ## theoretically: get logic queue of requesting object --> information about feasible jobs -->\n",
    "        ## [*] choice of sequencing agent (based on which properties?) --> preparing feature vector as input -->\n",
    "        ## trigger agent decision --> map decision to feasible jobs\n",
    "        ## [*] use implemented priority rules as intermediate step\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] REQUEST TO DISPATCHER FOR SEQUENCING\")\n",
    "        \n",
    "        # get logic queue of requesting object\n",
    "        # contains all feasible jobs for this resource\n",
    "        logic_queue = req_obj.logic_queue\n",
    "        # get job from logic queue with currently defined priority rule\n",
    "        job = self.seq_priority_rule(queue=logic_queue)\n",
    "        \n",
    "        return job, job.current_proc_time\n",
    "    \n",
    "    def seq_priority_rule(\n",
    "        self,\n",
    "        queue: Queue,\n",
    "    ) -> Job:\n",
    "        \"\"\"apply priority rules to a pool of jobs\"\"\"\n",
    "        match self._curr_prio_rule:\n",
    "            case 'FIFO':\n",
    "                # salabim queue pops first entry if no index is specified, \n",
    "                # not last like in Python\n",
    "                job = queue.pop()\n",
    "            case 'LIFO':\n",
    "                # salabim queue pops first entry if no index is specified, \n",
    "                # not last like in Python\n",
    "                job = queue.pop(-1)\n",
    "            case 'SPT':\n",
    "                # sort descending and pop last item\n",
    "                temp = queue.as_list()\n",
    "                temp = sorted(temp, key=attrgetter('current_proc_time'), reverse=True)\n",
    "                job: Job = temp.pop()\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "            case 'LPT':\n",
    "                # sort ascending and pop last item\n",
    "                temp = queue.as_list()\n",
    "                temp = sorted(temp, key=attrgetter('current_proc_time'), reverse=False)\n",
    "                job: Job = temp.pop()\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "                \n",
    "        return job\n",
    "    \n",
    "    ### ANALYSE ###\n",
    "    def draw_gantt_chart(\n",
    "        self,\n",
    "        use_custom_proc_station_id: bool = True,\n",
    "        sort_by_proc_station: bool = False,\n",
    "        sort_ascending: bool = True,\n",
    "        group_by_station_group: bool = False,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'gantt_chart',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        draw a Gantt chart based on the dispatcher's operation database\n",
    "        use_custom_machine_id: whether to use the custom IDs of the processing station (True) or its name (False)\n",
    "        sort_by_proc_station: whether to sort by processing station property (True) or by job name (False) \\\n",
    "            default: False\n",
    "        sort_ascending: whether to sort in ascending (True) or descending order (False) \\\n",
    "            default: True\n",
    "        use_duration: plot each operation with its scheduled duration instead of the delta time \\\n",
    "            between start and end; if there were no interruptions both methods return the same results \\\n",
    "            default: False\n",
    "        \"\"\"\n",
    "        # filter operation DB for relevant information\n",
    "        filter_items: list[str] = [\n",
    "            'job_name',\n",
    "            'target_station_custom_id',\n",
    "            'target_station_name',\n",
    "            'station_group',\n",
    "            'station_group_custom_id',\n",
    "            'entry_date',\n",
    "            'exit_date',\n",
    "        ]\n",
    "        \n",
    "        df = self._op_db.filter(items=filter_items)\n",
    "        # calculate delta time between start and end\n",
    "        df['delta'] = df['exit_date'] - df['entry_date']\n",
    "        \n",
    "        # sorting\n",
    "        sort_key: str = ''\n",
    "        # chose relevant processing station property\n",
    "        proc_station_prop: str = ''\n",
    "        if use_custom_proc_station_id:\n",
    "            proc_station_prop = 'target_station_custom_id'\n",
    "        else:\n",
    "            proc_station_prop = 'target_station_name'\n",
    "        \n",
    "        # check if sorting by processing station is wanted and custom ID should be used or not\n",
    "        if sort_by_proc_station:\n",
    "            sort_key = proc_station_prop\n",
    "        else:\n",
    "            sort_key = 'job_name' \n",
    "        \n",
    "        df = df.sort_values(by=sort_key, ascending=sort_ascending, kind='stable')\n",
    "        \n",
    "        # group by value\n",
    "        if group_by_station_group:\n",
    "            group_by_key = 'station_group_custom_id'\n",
    "        else:\n",
    "            group_by_key = 'job_name'\n",
    "        \n",
    "        # build Gantt chart with Plotly Timeline\n",
    "        fig: PlotlyFigure = px.timeline(df, x_start='entry_date', x_end='exit_date', \n",
    "                          y=proc_station_prop, color=group_by_key)\n",
    "        fig.update_yaxes(type='category', autorange='reversed')\n",
    "        fig.update_xaxes(type='linear')\n",
    "\n",
    "        # reset axis scale for every figure element\n",
    "        # https://stackoverflow.com/questions/66078893/plotly-express-timeline-for-gantt-chart-with-integer-xaxis\n",
    "        for d in fig.data:\n",
    "            try:\n",
    "                # convert to integer if property is of that type in the database\n",
    "                filt_val = int(d.name)\n",
    "            except ValueError:\n",
    "                filt_val = d.name\n",
    "            filt = df[group_by_key] == filt_val\n",
    "            d.x = df.loc[filt, 'delta']\n",
    "\n",
    "        fig.show()\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    ### DISPOSABLE JOBS\n",
    "    ### STILL NECESSARY???\n",
    "    def add_disposable_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        add job to the disposable ones\n",
    "        \"\"\"\n",
    "        self._disposable_jobs[job.job_id] = job\n",
    "    \n",
    "    @property\n",
    "    def disposable_jobs(self) -> dict[int, Job]:\n",
    "        return self._disposable_jobs\n",
    "    \n",
    "    ################# REWORK ##################\n",
    "    ### maybe add a corresponding property in the job DB\n",
    "    def get_disposable_jobs(\n",
    "        self,\n",
    "        job_set: OrderedDict,\n",
    "    ) -> tuple[list[ObjectID], list[Job]]:\n",
    "        \"\"\"\n",
    "        function needs to be reworked, jobs should report back information to a dispatcher instance\n",
    "        (bottom-up instead of top-down)\n",
    "        \"\"\"\n",
    "        #########################################\n",
    "        self._disposable_jobs_ID: list[int] = list()\n",
    "        self._disposable_jobs: list[Job] = list()\n",
    "        \n",
    "        for job_id, job in job_set.items():\n",
    "            if job.is_disposable:\n",
    "                self._disposable_jobs_ID.append(job_id)\n",
    "                self._disposable_jobs.append(job)\n",
    "                \n",
    "        return self._disposable_jobs_ID, self._disposable_jobs\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        self._calc_cycle_time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change ``machine_identifier`` to ``station_group_identifier``\n",
    "- ``target_machine`` to ``target_station_group``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='operation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        job: Job,\n",
    "        proc_time: float,\n",
    "        station_group_identifier: CustomID,\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'WAITING', \n",
    "            'PROCESSING', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        identifier: operation's ID\n",
    "        proc_times: operation's processing times\n",
    "        machine_identifier: ID of machine on which operation is processed\n",
    "        \"\"\"\n",
    "        # !!!!!!!!! perhaps processing times in future multiple entries depending on associated machine\n",
    "        # change of input format necessary, currently only one machine for each operation\n",
    "        # no groups, no differing processing times for different machines \n",
    "        # initialise parent class if available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # assert operation information\n",
    "        self._dispatcher = dispatcher\n",
    "        self._job = job\n",
    "        self._job_id = job.job_id\n",
    "        self._station_group_identifier = station_group_identifier\n",
    "        \n",
    "        # [STATS] Monitoring\n",
    "        self._stat_monitor = Monitor(env=self._dispatcher.env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # process information\n",
    "        # [STATS]\n",
    "        # time characteristics\n",
    "        self.proc_time: float = proc_time\n",
    "        self.lead_time: float = 0.\n",
    "        # inter-process time characteristics\n",
    "        # time of release\n",
    "        self.time_release: float = 0.\n",
    "        # time of first operation starting point\n",
    "        self.time_entry: float = 0.\n",
    "        # time of last operation ending point\n",
    "        self.time_exit: float = 0.\n",
    "        # lead time\n",
    "        self.lead_time: float = 0.\n",
    "        # starting and end points\n",
    "        # in future setting starting points in advance possible\n",
    "        self.is_finished: bool = False\n",
    "        self.is_released: bool = False\n",
    "        \n",
    "        ########### adding machine instances\n",
    "        ### perhaps adding machine sets if multiple machines possible (machine groups)\n",
    "        # assignment of machine instance by dispatcher\n",
    "        # from dispatcher: op_id, name, target_machine\n",
    "        # register operation instance\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        (self._op_id, self.name,\n",
    "         self.target_station_group,\n",
    "         self.time_creation) = self.dispatcher.register_operation(\n",
    "                                                        obj=self, \n",
    "                                                        station_group_identifier=self._station_group_identifier,\n",
    "                                                        custom_identifier=custom_identifier, name=name, \n",
    "                                                        state=current_state)\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Operation(ProcTime: {self.proc_time}, StationGroupID: {self._station_group_identifier})\"    \n",
    "    \n",
    "    @property   \n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    @property\n",
    "    def op_id(self) -> ObjectID:\n",
    "        return self._op_id\n",
    "    \n",
    "    @property\n",
    "    def job(self) -> Job:\n",
    "        return self._job\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> ObjectID:\n",
    "        return self._job_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(sim.Component):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        proc_times: list[float],\n",
    "        station_group_ex_order: list[CustomID],\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'WAITING', \n",
    "            'PROCESSING', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ############## ADD DESCRIPTION\n",
    "        \"\"\"\n",
    "        ### BASIC INFORMATION ###\n",
    "        # assert job information\n",
    "        self.custom_identifier = custom_identifier\n",
    "        self.job_type: str = 'Job'\n",
    "        self._dispatcher = dispatcher\n",
    "        # sum of the proc times of each operation\n",
    "        self.total_proc_time: float = sum(proc_times)\n",
    "        \n",
    "        # inter-process job state parameters\n",
    "        # first operation scheduled --> released job\n",
    "        self.is_released: bool = False\n",
    "        # job's next operation is disposable\n",
    "        # true for each new job, maybe reworked in future for jobs with\n",
    "        # a start date later than creation date\n",
    "        self.is_disposable: bool = True\n",
    "        # add job to disposable ones\n",
    "        #ret = self.dispatcher.add_disposable_job(self)\n",
    "        # last operation ended --> finished job\n",
    "        self.is_finished: bool = False\n",
    "        \n",
    "        # inter-process time characteristics\n",
    "        # time of release\n",
    "        self.time_release: float = 0.\n",
    "        # time of first operation starting point\n",
    "        self.time_entry: float = 0.\n",
    "        # time of last operation ending point\n",
    "        self.time_exit: float = 0.\n",
    "        # lead time\n",
    "        self.lead_time: float = 0.\n",
    "        \n",
    "        # current resource location\n",
    "        self._current_resource: InfrastructureObject | None = None\n",
    "        \n",
    "        # [STATS] Monitoring\n",
    "        self._stat_monitor = Monitor(env=self._dispatcher.env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # register job instance\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        env, self._job_id, name, self.time_creation = self._dispatcher.register_job(\n",
    "                                                        obj=self, custom_identifier=self.custom_identifier,\n",
    "                                                        name=name, state=current_state)\n",
    "        \n",
    "        # intialize base class\n",
    "        super().__init__(env=env, name=name, process='', **kwargs)\n",
    "        \n",
    "        ### OPERATIONS ##\n",
    "        self.operations: deque[Operation] = deque()\n",
    "        \n",
    "        for idx, op_proc_time in enumerate(proc_times):\n",
    "            op = Operation(\n",
    "                dispatcher=self._dispatcher,\n",
    "                job=self,\n",
    "                proc_time=op_proc_time,\n",
    "                station_group_identifier=station_group_ex_order[idx],\n",
    "            )\n",
    "            self.operations.append(op)\n",
    "            \n",
    "        self.open_operations = self.operations.copy()\n",
    "        self.total_num_ops: int = len(self.operations)\n",
    "        self.num_finished_ops: int = 0\n",
    "        # current and last OP: properties set by function \"get_next_operation\"\n",
    "        self._last_op: Operation | None = None\n",
    "        self._last_proc_time: float | None = None\n",
    "        self._current_op: Operation | None = None\n",
    "        self._current_proc_time: float | None = None\n",
    "        # rank-like property, set if job enters the infrastructure object\n",
    "        # acts like a counter to allow easy sorting even if queue order is not maintained\n",
    "        self._obj_entry_idx: int | None = None\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> ObjectID:\n",
    "        return self._job_id\n",
    "    \n",
    "    @property\n",
    "    def last_op(self) -> Operation | None:\n",
    "        return self._last_op\n",
    "\n",
    "    @property\n",
    "    def last_proc_time(self) -> float | None:\n",
    "        return self._last_proc_time\n",
    "    \n",
    "    @property\n",
    "    def current_op(self) -> Operation | None:\n",
    "        \"\"\"\n",
    "        returns the current operation of the job\n",
    "        If a job is currently being processed its current operation is \n",
    "        not changed until this operation is finished.\n",
    "        \"\"\"\n",
    "        return self._current_op\n",
    "    \n",
    "    @property\n",
    "    def current_proc_time(self) -> float | None:\n",
    "        \"\"\"\n",
    "        returns the processing time of the current operation\n",
    "        If a job is currently being processed its current processing time is \n",
    "        not changed until this operation is finished.\n",
    "        \"\"\"\n",
    "        return self._current_proc_time\n",
    "    \n",
    "    @property\n",
    "    def obj_entry_idx(self) -> int | None:\n",
    "        \"\"\"\n",
    "        returns the entry index which is set by each infrastructure object\n",
    "        \"\"\"\n",
    "        return self._obj_entry_idx\n",
    "    \n",
    "    @property\n",
    "    def current_resource(self) -> InfrastructureObject | None:\n",
    "        \"\"\"\n",
    "        returns the current resource on which the job lies\n",
    "        \"\"\"\n",
    "        return self._current_resource\n",
    "\n",
    "    @current_resource.setter\n",
    "    def current_resource(\n",
    "        self,\n",
    "        obj: InfrastructureObject\n",
    "    ) -> None:\n",
    "        \"\"\"setting the current resource object which must be of type InfrastructureObject\"\"\"\n",
    "        if not isinstance(obj, InfrastructureObject):\n",
    "            raise TypeError(f\"From {self}: Object >>{obj}<< muste be of type 'InfrastructureObject'\")\n",
    "        else:\n",
    "            self._current_resource = obj\n",
    "    \n",
    "    def get_next_operation(self) -> Operation | None:\n",
    "        \"\"\"\n",
    "        get next operation\n",
    "        \"\"\"\n",
    "        # last operation information\n",
    "        self._last_op = self._current_op\n",
    "        self._last_proc_time = self._current_proc_time\n",
    "        # current operation information\n",
    "        if self.open_operations:\n",
    "            op = self.open_operations.popleft()\n",
    "            self._current_proc_time = op.proc_time\n",
    "        else:\n",
    "            op = None\n",
    "            self._current_proc_time = None\n",
    "        \n",
    "        self._current_op = op\n",
    "        \n",
    "        return op\n",
    "    \n",
    "    def has_job_id(\n",
    "        self,\n",
    "        job_id: ObjectID,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        checks whether the current job has the given id\n",
    "        \"\"\"\n",
    "        if self._job_id == job_id:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link Collection**\n",
    "\n",
    "- [Environment](#environment)\n",
    "- [Machine](#machine)\n",
    "- [Dispatcher](#dispatcher)\n",
    "- [Operation](#operation)\n",
    "- [Job](#job)\n",
    "- [Logic Test](#logic_test)\n",
    "\n",
    "\n",
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"MachineBreakdownTest\"></a>\n",
    "\n",
    "# Check interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = sim.Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMachine(sim.Component):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.proc_time = 8.\n",
    "        \n",
    "    def process(self):\n",
    "        yield self.passivate()\n",
    "        \n",
    "        print(f\"Processing time machine = {self.proc_time}; start processing at {self.env.now()}\")\n",
    "        \n",
    "        yield self.hold(self.proc_time)\n",
    "        \n",
    "        print(f\"Processing finished at {self.env.now()}\")\n",
    "        \n",
    "        \n",
    "class Interruptor(sim.Component):\n",
    "    \n",
    "    def __init__(self, machine, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.machine = machine\n",
    "        self.time_till_failure = 2.\n",
    "        self.breakdown_time = 3.\n",
    "        \n",
    "    def process(self):\n",
    "        machine = self.machine\n",
    "        machine.activate()\n",
    "        \n",
    "        yield self.hold(self.time_till_failure)\n",
    "        \n",
    "        print(f\"Interrupt machine at {self.env.now()} for time units {self.breakdown_time}\")\n",
    "        machine.interrupt()\n",
    "        \n",
    "        yield self.hold(self.breakdown_time)\n",
    "        \n",
    "        print(f\"Resume machine at {self.env.now()}\")\n",
    "        machine.resume()\n",
    "        \n",
    "        yield self.passivate()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = TestMachine(env=env)\n",
    "failure = Interruptor(machine=machine, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time machine = 8.0; start processing at 0.0\n",
      "Interrupt machine at 2.0 for time units 3.0\n",
      "Resume machine at 5.0\n",
      "Processing finished at 11.0\n"
     ]
    }
   ],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine.status.value_duration('interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine.status.value_duration('scheduled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
