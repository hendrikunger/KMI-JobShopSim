{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Table of contents\n",
    "- [Random Generator](#randomgenerator)\n",
    "- [Environment](#environment)\n",
    "- [Infrastructure Object](#infrastructureobject)\n",
    "- [Processing Station](#processingstation)\n",
    "- [Machine](#machine)\n",
    "- [Buffer](#buffer)\n",
    "- [Source](#source)\n",
    "- [Dispatcher](#dispatcher)\n",
    "- [Operation](#operation)\n",
    "- [Job](#job)\n",
    "- [Logic Test](#logic_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do:\n",
    "\n",
    "08.09.2023:\n",
    "- [x] ~~write operation properties directly during dispatcher registration~~\n",
    "- [x] ~~write job properties directly during dispatcher registration~~\n",
    "- [x] ~~add job/operation information about target station groups:~~\n",
    "    - [x] ~~station groups~~\n",
    "    - [x] ~~add validity check of target station groups:~~\n",
    "        - currently possible to assign station groups which do not correspond to the execution system\n",
    "        - objective: only stations of the current execution system allowed\n",
    "    - [x] ~~generate method to randomly assign target station group IDs to jobs depending on the execution system~~\n",
    "- [x] ~~*user-defined additional information as dictionary*~~ --> currently only as simple parameter, not conceptualised yet\n",
    "\n",
    "11.09.2023:\n",
    "- [ ] add feasibility check\n",
    "    - [x] ~~since agents can choose actions which are not feasible a feasiblity check is necessary~~\n",
    "    - [ ] describe learning flow if a non-feasible action was chosen\n",
    "- [ ] consolidate Markdown notes and explanations\n",
    "- [ ] common code cleansing\n",
    "\n",
    "---\n",
    "\n",
    "- [x] add job/operation priority\n",
    "- [ ] add KSG-specific priority level mapping\n",
    "- [x] add dates:\n",
    "    - [x] planned starting\n",
    "    - [x] planned ending\n",
    "    - [x] date deviation measures\n",
    "- [ ] add prod area information to operation database\n",
    "- [x] ~~add simulation time on date base (time unit conversion)~~\n",
    "- [ ] add allocation rule setting on execution system level, not only whole environment\n",
    "\n",
    "- [ ] logic/ interface for generation of multiple jobs\n",
    "    - using dispatcher or source?\n",
    "    - interface: design + properties\n",
    "- [ ] feature vector description\n",
    "- [ ] add layout configuration\n",
    "- [ ] add calendar functionality with breaks\n",
    "\n",
    "\n",
    "- [ ] capacity deadlocks between buffers and machines\n",
    "    - [ ] resolve necessary! otherwise no information about blockages\n",
    "    - [x] ~~remove deadlocks by counting the associated machines and comparing the counter to the buffer's capacity~~ (**no capacities > 1 for processing stations**)\n",
    "    - **problem persists: if predecessor systems produce faster than the target processing stations, they fill the buffer until it is filled --> result == deadlock again if buffer is shared between processing station**\n",
    "    - shared buffers: if only used for machine groups --> no problem because there are no circles between these machines\n",
    "    - [ ] look into problems where processing stations have a capacity greater than 1\n",
    "- [ ] add logistic objective values:\n",
    "    - [x] ~~WIP~~\n",
    "    - [x] ~~lead time~~\n",
    "    - [x] ~~utilisation~~\n",
    "    - [ ] rank\n",
    "- [ ] add Gantt chart visualisation for debugging\n",
    "    - [x] ~~after simulation run~~\n",
    "    - [ ] during simulation run\n",
    "- [ ] tracking disjunctive graph model\n",
    "    - *still possible with parallel stations?*\n",
    "    - **[QUESTION] Working with parallel machines?**\n",
    "- [ ] initialisation of the model with pre-defined state information\n",
    "    - [x] ~~build base by implementing a pre-process method (initialisation) before the simulation starts~~\n",
    "    - [x] ~~initialise/create objects with pre-defined states~~\n",
    "    - [ ] design interface to load system state\n",
    "- [ ] add machine breakdowns\n",
    "    - vide **[Check Interruption](#MachineBreakdownTest)**\n",
    "\n",
    "#### Continuous Tasks\n",
    "\n",
    "- [ ] machine groups: add different allocation rules\n",
    "    - currently: ``Random, Lowest Utilisation, Lowest WIP Time, Lowest WIP number jobs``\n",
    "- [ ] add priority rules for sequencing\n",
    "    - currently: ``FIFO, LIFO, SPT, LPT, Shortest Setup Time (SST), Longest Setup Time (LST)``\n",
    "    - additional (casually updated, depending on implemented features): priority\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DONE**:\n",
    "\n",
    "- [x] ~~add setup times~~\n",
    "- [x] ~~add environment indicators for decision-making:~~\n",
    "    - [x] ~~sequencing~~\n",
    "    - [x] ~~allocation~~\n",
    "    - flags to signal agent decisions: **necessary for implementation as Gyamnasium environment**\n",
    "- [x] ~~add machine groups (parallel machines)~~\n",
    "    - logic behind communicating machine groups\n",
    "    - registration of machines in groups\n",
    "- [x] ~~additional 'Production Areas' necessary because each of these areas can contain multiple station groups~~\n",
    "    - Routing: production area --> station group --> processing station\n",
    "    - Example KSG: drilling range --> 4 station groups --> different number of processing stations\n",
    "- [X] ~~rework WIP tracking: no plausible results~~\n",
    "    - *fixed bug*\n",
    "- [x] ~~description of process logic for generation and entry of jobs~~\n",
    "- [x] ~~add setting of job/machine states in machine logic~~\n",
    "    - using state update function which combine all necessary state update calls\n",
    "- [x] ~~add status info to job DB? (waiting, processing, ...) (disposable = waiting?)~~\n",
    "    - advantage:\n",
    "        - one central DB with all information, no cluttered information\n",
    "        - simple filtering for jobs by current status incl. disposable jobs\n",
    "- [x] ~~add sources and sinks~~\n",
    "    - [x] source: generates new job with given intervals\n",
    "    - [x] sink: destroys jobs and finalises data collection\n",
    "- [x] ~~add physical buffers~~\n",
    "\n",
    "- [x] ~~add bar charts for time components~~\n",
    "- [x] ~~add monitor class to unitise data collection~~\n",
    "- [x] ~~I/O functions for elements~~\n",
    "\n",
    "- [x] ~~register job object in dispatcher~~\n",
    "- [x] ~~register operations in dispatcher~~\n",
    "- [x] ~~add uniqueness check for custom IDs in resource objects (only interface to user)~~\n",
    "- [x] ~~operations list of jobs as deque~~\n",
    "- [x] ~~add generic infrastructure class from which infrastructure objects are derived~~\n",
    "- [x] ~~implement routing logic in objects~~\n",
    "- [x] ~~add operation starting and end points~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic behind simulation model approach\n",
    "*Model of Resource and Load*:\n",
    "- system consists of physical objects, also called infrastructure\n",
    "    - each element can be considered as encapsulated resource\n",
    "- stress can be put on each system by occupying resources, also called load\n",
    "    - definition of load depends on system type and modelling, e.g. production jobs for production systems or customers for cashiers in a shop\n",
    "- load objects are called ***load unit***\n",
    "\n",
    "*Guiding Priciples*:\n",
    "- **load objects** can only be spatially and temporally modified by **resources**\n",
    "    - only resource objects can put load objects on other resources and change their state\n",
    "    - load objects **contain the necessary information** which is essential for their further processing\n",
    "\n",
    "################\n",
    "\n",
    "Logic of ``Lang et al.: Modeling Production Scheduling Problems as Reinforcement Learning Environments based on Discrete-Event Simulation and OpenAI Gym``\n",
    "- whole routing logic is implemented in a collaborative manner between resources and load objects\n",
    "    - each load object puts itself in a associated queue\n",
    "    - therefore load objects can change their *states* and *location* by theirown\n",
    "- **violates resource-load model: no load object can change its state without a associated resource**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideas for handling time units**\n",
    "\n",
    "- use Python-integrated standard types like datetime and timedelta\n",
    "    - datetime: point in time like planned dates\n",
    "    - timedelta: durations like processing times\n",
    "\n",
    "Advantages:\n",
    "- using standard types which are integrated by default and designed to handle time units well\n",
    "- common standard to interact with the simulation environment\n",
    "    - no time conversion with continuous time unit checks\n",
    "    - handling different time units in one object\n",
    "    - no time conversions within the model or library\n",
    "    - outsourcing of date parsing to interact properly with the environment --> adapt messy data to a standard format (exchange format known) --> easy building of custom parsing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salabim time functions**\n",
    "\n",
    "**Converting SimTime to Datetime and vice versa**\n",
    "- t_to_datetime\n",
    "- timedelta_to_duration\n",
    "\n",
    "**Converting SimTime to time units**\n",
    "- to_hours\n",
    "- to_minutes\n",
    "- to_seconds\n",
    "- ...\n",
    "- *general*: to_time_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- associated station group IDs\n",
    "- check possible if a chosen proc station matches the job's target station group --> feasible\n",
    "- feasibility check function\n",
    "    - implemented in environment, splitted:\n",
    "        - sequencing\n",
    "        - allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**procedure**:\n",
    "- [x] request to dispatcher for allocation\n",
    "- [x] get target *ProductionArea*\n",
    "- [x] obtain *tuple of **processing stations*** for target prod_area\n",
    "    - tuple must always have the **same length and order**\n",
    "- [x] if agent as allocation method: \n",
    "    - CHECK: available agent for that prod_area --> implemented in system class\n",
    "- [ ] (SIMULATE AT FIRST) build *feature vector* for given proc_stations and job instance\n",
    "    - not implemented, only placeholder\n",
    "- [x] (IMPLEMENT OPTION TO CHOOSE AGENT) choose *allocation agent* for target prod_area\n",
    "    - call agent decision by providing feature vector\n",
    "    - result: *index value* for chosen proc_station\n",
    "- [ ] agent decision:\n",
    "    - **1. FOR TESTING PURPOSES**:\n",
    "        - [x] implement index choice by user input\n",
    "    - **2. TRUE AGENT DECISION**:\n",
    "        - [ ] call agent decision by providing feature vector\n",
    "    - result: *index value* for chosen proc_station, get station by index value\n",
    "- [x] check if processing station is feasible:\n",
    "    - obtain *station group identifiers* (SGI) of the proc_station\n",
    "    - obtain *station group identifier* for the operation\n",
    "    - check if operation SGI is in the proc_station SGIs\n",
    "        - if yes: feasible\n",
    "        - if no: non-feasible\n",
    "\n",
    "\n",
    "**requirements**:\n",
    "- SGI of jobs/operations **must be identical to the infrastructure**, otherwise no comparison possible\n",
    "    - function/method to check if the custom identifier of an operation occurs in the environment --> **InfrastructureManager**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from numpy.random._generator import Generator as NPRandomGenerator\n",
    "import random\n",
    "import simpy\n",
    "import salabim as sim\n",
    "from salabim import Queue, State\n",
    "from typing import TypeAlias, Self, Any\n",
    "from collections import OrderedDict, deque\n",
    "from collections.abc import Iterable, Sequence, Generator\n",
    "from operator import attrgetter\n",
    "from functools import lru_cache\n",
    "from pprint import pprint\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "from datetime import datetime as Datetime\n",
    "from datetime import timedelta as Timedelta\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import plotly.express as px\n",
    "from plotly.graph_objs._figure import Figure\n",
    "\n",
    "sim.yieldless(False)\n",
    "\n",
    "# type aliases\n",
    "#NPRandomGenerator: TypeAlias = Generator\n",
    "SimPyEnv: TypeAlias = simpy.core.Environment\n",
    "SalabimEnv: TypeAlias = sim.Environment\n",
    "EnvID: TypeAlias = int\n",
    "# change in supersystem types\n",
    "SuperSystem: TypeAlias = 'ProductionArea | StationGroup'\n",
    "#JobID: TypeAlias = int\n",
    "#OpID: TypeAlias = int\n",
    "ObjectID: TypeAlias = int\n",
    "### [CHANGE] Replace MachineID as CustomID\n",
    "MachineID: TypeAlias = int | str\n",
    "CustomID: TypeAlias = int | str\n",
    "#InfstructObj: TypeAlias = object # better naming in future\n",
    "PlotlyFigure: TypeAlias = Figure\n",
    "\n",
    "# forward reference, referenced before assignment\n",
    "#Job: TypeAlias = 'Job'\n",
    "#Dispatcher: TypeAlias = 'Dispatcher'\n",
    "\n",
    "# logging\n",
    "# IPython compatibility\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "LOGGING_LEVEL = 'ERROR'\n",
    "LOGGING_LEVEL_ENV = 'INFO'\n",
    "LOGGING_LEVEL_DISPATCHER = 'DEBUG'\n",
    "LOGGING_LEVEL_INFSTRCT = 'INFO'\n",
    "LOGGING_LEVEL_SOURCES = 'ERROR'\n",
    "LOGGING_LEVEL_SINKS = 'ERROR'\n",
    "LOGGING_LEVEL_PRODSTATIONS = 'ERROR'\n",
    "LOGGING_LEVEL_JOBS = 'ERROR'\n",
    "LOGGING_LEVEL_OPERATIONS = 'ERROR'\n",
    "LOGGING_LEVEL_BUFFERS = 'ERROR'\n",
    "LOGGING_LEVEL_MONITORS = 'ERROR'\n",
    "LOGGING_LEVEL_AGENTS = 'DEBUG'\n",
    "\n",
    "\n",
    "logger = logging.getLogger('base')\n",
    "logger.setLevel(LOGGING_LEVEL)\n",
    "logger_env = logging.getLogger('env')\n",
    "logger_env.setLevel(LOGGING_LEVEL_ENV)\n",
    "logger_dispatcher = logging.getLogger('dispatcher')\n",
    "logger_dispatcher.setLevel(LOGGING_LEVEL_DISPATCHER)\n",
    "logger_infstrct = logging.getLogger('infstrct')\n",
    "logger_infstrct.setLevel(LOGGING_LEVEL_INFSTRCT)\n",
    "logger_sources = logging.getLogger('sources')\n",
    "logger_sources.setLevel(LOGGING_LEVEL_SOURCES)\n",
    "logger_sinks = logging.getLogger('sinks')\n",
    "logger_sinks.setLevel(LOGGING_LEVEL_SINKS)\n",
    "logger_prodStations = logging.getLogger('prodStations')\n",
    "logger_prodStations.setLevel(LOGGING_LEVEL_PRODSTATIONS)\n",
    "logger_buffers = logging.getLogger('buffers')\n",
    "logger_buffers.setLevel(LOGGING_LEVEL_BUFFERS)\n",
    "logger_monitors = logging.getLogger('monitors')\n",
    "logger_monitors.setLevel(LOGGING_LEVEL_MONITORS)\n",
    "logger_agents = logging.getLogger('agents')\n",
    "logger_agents.setLevel(LOGGING_LEVEL_AGENTS)\n",
    "\n",
    "logger_jobs = logging.getLogger('jobs')\n",
    "logger_jobs.setLevel(LOGGING_LEVEL_JOBS)\n",
    "logger_operations = logging.getLogger('operations')\n",
    "logger_operations.setLevel(LOGGING_LEVEL_OPERATIONS)\n",
    "\n",
    "\n",
    "# infinity\n",
    "INF: float = float('inf')\n",
    "# definition of routing system level\n",
    "EXEC_SYSTEM_TYPE: str = 'ProductionArea'\n",
    "# time after a store request is failed\n",
    "FAIL_DELAY: float = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined errors\n",
    "class AssociationError(Exception):\n",
    "    \"\"\"error that describes cases in which systems are \n",
    "    created but not added to supersystems\"\"\"\n",
    "    pass\n",
    "\n",
    "class NoAllocationAgentAssignedError(Exception):\n",
    "    \"\"\"error that describes that a system has no assigned allocation agent\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def flatten(\n",
    "    lst_tpl: list[Any] | tuple[Any, ...]\n",
    ") -> Generator[Any, None, None]:\n",
    "    \"\"\"flattens an arbitrarily nested list or tuple\n",
    "    https://stackoverflow.com/questions/2158395/flatten-an-irregular-arbitrarily-nested-list-of-lists \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lst_tpl : list[Any] | tuple[Any, ...]\n",
    "        arbitrarily nested list or tuple\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    Generator[Any, None, None]\n",
    "        non-nested list or tuple\n",
    "    \"\"\"\n",
    "    #\n",
    "    for x in lst_tpl:\n",
    "        # only flatten lists and tuples\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "\n",
    "def filter_processing_stations(\n",
    "    infstruct_obj_collection: Iterable[InfrastructureObject]\n",
    ") -> list[ProcessingStation]:\n",
    "    \"\"\"Filters an iterable with InfrastructureObjects for ProcessingStations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infstruct_obj_collection : Iterable[InfrastructureObject]\n",
    "        collection of InfrastrcutureObjects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[ProcessingStation]\n",
    "        list of ProcessingStations for the given collection\n",
    "    \"\"\"\n",
    "    \n",
    "    return [x for x in infstruct_obj_collection if isinstance(x, ProcessingStation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTParser:\n",
    "    \n",
    "    def __init__(\n",
    "        self\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        date and time parser with convenient methods \n",
    "        to parse time units as timedelta and datetime objects\n",
    "        \"\"\"\n",
    "        \n",
    "        self._time_units_datetime: set[str] = set([\n",
    "            'year',\n",
    "            'month',\n",
    "            'day',\n",
    "            'hour',\n",
    "            'minute',\n",
    "            'second',\n",
    "            'microsecond',\n",
    "        ])\n",
    "        \n",
    "        self._time_units_timedelta: set[str] = set([\n",
    "            'weeks',\n",
    "            'days',\n",
    "            'hours',\n",
    "            'minutes',\n",
    "            'seconds',\n",
    "            'milliseconds',\n",
    "            'microseconds',\n",
    "        ])\n",
    "        \n",
    "    def timedelta_from_val(\n",
    "        self,\n",
    "        val: float,\n",
    "        time_unit: str,\n",
    "    ) -> datetime.timedelta:\n",
    "        \n",
    "        if time_unit not in self._time_units_timedelta:\n",
    "            raise ValueError(f\"Time unit >>{time_unit}<< not supported. Choose from {self._time_units_timedelta}\")\n",
    "        \n",
    "        match time_unit:\n",
    "            case 'weeks':\n",
    "                ret = datetime.timedelta(weeks=val)\n",
    "            case 'days':\n",
    "                ret = datetime.timedelta(days=val)\n",
    "            case 'hours':\n",
    "                ret = datetime.timedelta(hours=val)\n",
    "            case 'minutes':\n",
    "                ret = datetime.timedelta(minutes=val)\n",
    "            case 'seconds':\n",
    "                ret = datetime.timedelta(seconds=val)\n",
    "            case 'milliseconds':\n",
    "                ret = datetime.timedelta(milliseconds=val)\n",
    "            case 'microseconds':\n",
    "                ret = datetime.timedelta(microseconds=val)\n",
    "                \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parser = DTParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = dt_parser.timedelta_from_val(\n",
    "    val=2.0,\n",
    "    time_unit='hours',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=7200)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='randomgenerator'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomJobGenerator:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        seed: int = 42,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        seed: seed value for random number generator\n",
    "        \"\"\"\n",
    "        self._np_rnd_gen: NPRandomGenerator = np.random.default_rng(seed=seed)\n",
    "        self._dt_parser: DTParser = DTParser()\n",
    "        random.seed(seed)\n",
    "        \n",
    "    def gen_rnd_JSSP_inst(\n",
    "        self,\n",
    "        n_jobs: int,\n",
    "        n_machines: int,\n",
    "    ) -> tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "        \"\"\"\n",
    "        Generates random job shop instance with given number of and machines\n",
    "        - each job on all machines\n",
    "        - max processing time = 9\n",
    "        \n",
    "        Output:\n",
    "        n_jobs: number of jobs\n",
    "        n_machines: number of machines\n",
    "        n_tasks: number of tasks\n",
    "        mat_ProcTimes: matrix of processing times | shape=(n_jobs,n_machines)\n",
    "        mat_JobMachID: matrix of machine IDs per job starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        mat_OpID: matrix of operation IDs starting by index 1 | shape=(n_jobs,n_machines)\n",
    "        \"\"\"\n",
    "        # generate random process time matrix shape=(n_jobs, n_machines)\n",
    "        mat_ProcTimes = self._np_rnd_gen.integers(1, 10, size=(n_jobs,n_machines), dtype=np.uint16)\n",
    "        \n",
    "        # generate randomly shuffled job machine combinations\n",
    "        # machine IDs from 1 to n_machines\n",
    "        temp = np.arange(0, n_machines, step=1, dtype=np.uint16)\n",
    "        temp = np.expand_dims(temp, axis=0)\n",
    "        # repeat dummy line until number n_jobs is reached\n",
    "        temp = np.repeat(temp, n_jobs, axis=0)\n",
    "        # randomly permute the machine indices job-wise\n",
    "        mat_JobMachID = self._np_rnd_gen.permuted(temp, axis=1)\n",
    "        \n",
    "        # generate operation ID matrix\n",
    "        # not mandatory because operations are registered in the environment's dispatcher\n",
    "        n_ops = n_jobs * n_machines\n",
    "        temp2 = np.arange(0, (n_ops), step=1, dtype=np.uint16)\n",
    "        mat_OpID = temp2.reshape(n_jobs, -1)\n",
    "        \n",
    "        return mat_ProcTimes, mat_JobMachID\n",
    "    \n",
    "    def gen_rnd_job(\n",
    "        self,\n",
    "        n_machines: int,\n",
    "    ) -> tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]:\n",
    "        \"\"\"generates random job with machine IDs\n",
    "        [OUTDATED] Should be replaced by the more generic 'gen_rnd_job_by_ids' method\n",
    "        which uses any IDs provided as NumPy array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_machines : int\n",
    "            _description_\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[npt.NDArray[np.uint16], npt.NDArray[np.uint16]]\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        # generate random process time matrix shape=(n_machines)\n",
    "        mat_ProcTimes = self._np_rnd_gen.integers(1, 10, size=n_machines, dtype=np.uint16)\n",
    "        \n",
    "        # generate randomly shuffled job machine combinations\n",
    "        # machine IDs from 1 to n_machines\n",
    "        temp = np.arange(0, n_machines, step=1, dtype=np.uint16)\n",
    "        # randomly permute the machine indices job-wise\n",
    "        mat_JobMachID = self._np_rnd_gen.permuted(temp)\n",
    "        \n",
    "        return mat_ProcTimes, mat_JobMachID\n",
    "    \n",
    "    def gen_rnd_job_by_ids(\n",
    "        self,\n",
    "        exec_system_ids: Sequence[CustomID],\n",
    "        target_station_group_ids: dict[CustomID, Sequence[CustomID]] | None = None,\n",
    "        min_proc_time: int = 1,\n",
    "        max_proc_time: int = 10,\n",
    "        gen_setup_times: bool = False,\n",
    "        min_setup_time: int = 1,\n",
    "        max_setup_time: int = 10,\n",
    "        time_unit: str = 'hours',\n",
    "    ) -> tuple[list[CustomID], list[CustomID] | None, list[Timedelta], list[Timedelta] | None]:\n",
    "        \"\"\"Generic function to generate processing times and execution flow of a job object\n",
    "        \"\"\"\n",
    "        n_objects = len(exec_system_ids)\n",
    "        \n",
    "        # processing times\n",
    "        proc_times: list[Timedelta] = list()\n",
    "        proc_times_time_unit: list[int] = self._np_rnd_gen.integers(\n",
    "                                            min_proc_time, \n",
    "                                            max_proc_time, \n",
    "                                            size=n_objects, \n",
    "                                            dtype=np.uint16).tolist()\n",
    "        for time in proc_times_time_unit:\n",
    "            # build timedelta object\n",
    "            td = self._dt_parser.timedelta_from_val(val=time,\n",
    "                                                    time_unit=time_unit)\n",
    "            proc_times.append(td)\n",
    "        \n",
    "        \n",
    "        # setup times\n",
    "        setup_times: list[Timedelta] = list()\n",
    "        setup_times_time_unit: list[int] | None = None\n",
    "        if gen_setup_times:\n",
    "            setup_times_time_unit = self._np_rnd_gen.integers(\n",
    "                                                min_setup_time, \n",
    "                                                max_setup_time, \n",
    "                                                size=n_objects, \n",
    "                                                dtype=np.uint16).tolist()\n",
    "            for time in setup_times_time_unit:\n",
    "                # build timedelta object\n",
    "                td = self._dt_parser.timedelta_from_val(val=time,\n",
    "                                                        time_unit=time_unit)\n",
    "                # append object\n",
    "                setup_times.append(td)\n",
    "        \n",
    "        # randomly permute the execution systems indices\n",
    "        job_ex_order = self._np_rnd_gen.permuted(exec_system_ids).tolist()\n",
    "        \n",
    "        job_target_station_groups: list[CustomID] | None = None\n",
    "        if target_station_group_ids is not None:\n",
    "            job_target_station_groups = list()\n",
    "            \n",
    "            for exec_system_id in job_ex_order:\n",
    "                # multiple candidates: random choice\n",
    "                candidates = target_station_group_ids[exec_system_id]\n",
    "                \n",
    "                if len(candidates) > 1:\n",
    "                    #candidate = self._np_rnd_gen.choice(candidates)\n",
    "                    candidate = random.choice(candidates)\n",
    "                # only one entry\n",
    "                else:\n",
    "                    candidate = candidates[0]\n",
    "                \n",
    "                job_target_station_groups.append(candidate)\n",
    "        \n",
    "        return job_ex_order, job_target_station_groups, proc_times, setup_times\n",
    "    \n",
    "    def gen_prio(\n",
    "        self,\n",
    "        lowest: int = 1,\n",
    "        highest: int = 9,\n",
    "    ) -> int:\n",
    "        \"\"\"Generates a single priority score\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lowest_prio : int\n",
    "            lowest available priority\n",
    "        highest_prio : int\n",
    "            highest available priority\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            randomly chosen priority between lowest and highest value\n",
    "        \"\"\"\n",
    "        return int(self._np_rnd_gen.integers(low=lowest, high=highest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_generator = RandomJobGenerator(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cust02', 'cust03', 'cust01'],\n",
       " None,\n",
       " [datetime.timedelta(seconds=7200),\n",
       "  datetime.timedelta(seconds=3600),\n",
       "  datetime.timedelta(seconds=32400)],\n",
       " [datetime.timedelta(seconds=32400),\n",
       "  datetime.timedelta(seconds=21600),\n",
       "  datetime.timedelta(seconds=14400)])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_generator.gen_rnd_job_by_ids(exec_system_ids=['cust01', 'cust02', 'cust03'], gen_setup_times=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brainstorming of ways to import machine names and IDs\n",
    "*Case 1: only names are given*\n",
    "- read machine names and assert IDs to them\n",
    "- build data structure with name and ID bundled (maybe as property of a machine class)\n",
    "\n",
    "*Case 2: IDs are given*\n",
    "- only building data structure with name and ID bundled\n",
    "\n",
    "*Data Structure:*\n",
    "- if only mapping of two pairs in each direction (lookup ID or lookup machine name)\n",
    "    - bi-directional dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for resource objects:**\n",
    "- CustomID may not be of type 'None' because the custom identifiers are the only interface to the end user (EnvID are solely handled inernally)\n",
    "- add checking for uniqueness of custom identifiers necessary, else the mapping of different objects could be ambiguous\n",
    "- jobs and operations can use ambiguous custom IDs --> custom IDs can still be None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dedicated environment class with information on associated resources and jobs\n",
    "- maybe add possibility of using subsystems (bundle of resources with unique identifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='environment'></a>\n",
    "**Salabim Env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationEnvironment(sim.Environment):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        time_unit: str = 'seconds',\n",
    "        starting_datetime: Datetime | None = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        # time units\n",
    "        self.time_unit = time_unit\n",
    "        # if starting datetime not provided use current time\n",
    "        if starting_datetime is None:\n",
    "            starting_datetime = datetime.datetime.now()\n",
    "        # remove microseconds, such accuracy not needed\n",
    "        starting_datetime = starting_datetime.replace(microsecond=0)\n",
    "        self.starting_datetime = starting_datetime\n",
    "        \n",
    "        super().__init__(time_unit=self.time_unit, datetime0=self.starting_datetime, **kwargs)\n",
    "        \n",
    "        # [RESOURCE] infrastructure manager\n",
    "        self._infstruct_mgr_registered: bool = False\n",
    "        self._infstruct_mgr: InfrastructureManager | None = None\n",
    "        \n",
    "        # [LOAD] job dispatcher\n",
    "        self._dispatcher_registered: bool = False\n",
    "        self._dispatcher: Dispatcher | None = None\n",
    "        \n",
    "        # [DECISION FLAGS]\n",
    "        self._signal_allocation: bool = False\n",
    "        self._signal_sequencing: bool = False\n",
    "    \n",
    "    def t_as_dt(self) -> Datetime:\n",
    "        \"\"\"return current simulation time as Datetime object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Datetime\n",
    "            simulation time in current time unit as Datetime object\n",
    "        \"\"\"\n",
    "        return self.t_to_datetime(t=self.t())\n",
    "    \n",
    "    @property\n",
    "    def infstruct_mgr(self) -> InfrastructureManager:\n",
    "        \"\"\"obtain the current registered Infrastructure Manager instance of the environment\"\"\"\n",
    "        if self._infstruct_mgr is None:\n",
    "            raise ValueError(\"No Infrastructure Manager instance registered.\")\n",
    "        else:\n",
    "            return self._infstruct_mgr\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        \"\"\"obtain the current registered Dispatcher instance of the environment\"\"\"\n",
    "        if self._dispatcher is None:\n",
    "            raise ValueError(\"No Dipsatcher instance registered.\")\n",
    "        else:\n",
    "            return self._dispatcher\n",
    "        \n",
    "    def register_infrastructure_manager(\n",
    "        self,\n",
    "        infstruct_mgr: InfrastructureManager,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        if not self._infstruct_mgr_registered and isinstance(infstruct_mgr, InfrastructureManager):\n",
    "            self._infstruct_mgr = infstruct_mgr\n",
    "            self._infstruct_mgr_registered = True\n",
    "            logger_env.info(f\"Successfully registered Infrastructure Manager in Env >>{self.name()}<<\")\n",
    "        elif not isinstance(infstruct_mgr, InfrastructureManager):\n",
    "            raise TypeError(f\"The object must be of type >>InfrastructureManager<< but is type >>{type(infstruct_mgr)}<<\")\n",
    "        else:\n",
    "            raise AttributeError(\"There is already a registered Infrastructure Manager instance \\\n",
    "                                 Only one instance per environement is allowed.\")\n",
    "    \n",
    "    def register_dispatcher(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a dispatcher instance for the environment. Only one instance per environment is allowed.\n",
    "        returns: EnvID for the dispatcher instance\n",
    "        \"\"\"\n",
    "        if not self._dispatcher_registered and isinstance(dispatcher, Dispatcher):\n",
    "            self._dispatcher = dispatcher\n",
    "            self._dispatcher_registered = True\n",
    "            logger_env.info(f\"Successfully registered Dispatcher in Env >>{self.name()}<<\")\n",
    "        elif not isinstance(dispatcher, Dispatcher):\n",
    "            raise TypeError(f\"The object must be of type >>Dispatcher<< but is type >>{type(dispatcher)}<<\")\n",
    "        else:\n",
    "            raise AttributeError(\"There is already a registered Dispatcher instance \\\n",
    "                                 Only one instance per environment is allowed.\")\n",
    "    \n",
    "    # [DISPATCHING SIGNALS]\n",
    "    @property\n",
    "    def signal_allocation(self) -> bool:\n",
    "        return self._signal_allocation\n",
    "    \n",
    "    @property\n",
    "    def signal_sequencing(self) -> bool:\n",
    "        return self._signal_sequencing\n",
    "    \n",
    "    def set_dispatching_signal(\n",
    "        self,\n",
    "        sequencing: bool,\n",
    "        reset: bool = False,\n",
    "    ) -> None:\n",
    "        # obtain current value\n",
    "        if sequencing:\n",
    "            signal = self._signal_sequencing\n",
    "            signal_type = 'SEQ'\n",
    "        else:\n",
    "            signal = self._signal_allocation\n",
    "            signal_type = 'ALLOC'\n",
    "        \n",
    "        # check flag and determine value\n",
    "        if not reset:\n",
    "            # check if already set\n",
    "            if signal:\n",
    "                raise RuntimeError(f\"Dispatching type >>{signal_type}<<: Flag for Env {self.name()} was already set.\")\n",
    "            else:\n",
    "                signal = True\n",
    "        # reset\n",
    "        else:\n",
    "            # check if already not set\n",
    "            if not signal:\n",
    "                raise RuntimeError(f\"Dispatching type >>{signal_type}<<: Flag for Env {self.name()} was already reset.\")\n",
    "            else:\n",
    "                signal = False\n",
    "        \n",
    "        # set flag\n",
    "        if sequencing:\n",
    "            self._signal_sequencing = signal\n",
    "        else:\n",
    "            self._signal_allocation = signal\n",
    "        \n",
    "        logger_env.debug(f\"Dispatching type >>{signal_type}<<: Flag for Env {self.name()} was set to >>{signal}<<.\")\n",
    "    \n",
    "    def build_alloc_feat_vec(\n",
    "        self,\n",
    "        exec_system: System | None = None,\n",
    "    ) -> 'FeatureVector':\n",
    "        \"\"\"\n",
    "        REWORK\n",
    "        method to generate allocation feature vectors for a given execution system\n",
    "        currently neither conceptualised nor implemented\n",
    "        functionality needed:\n",
    "            - obtain all relevant subsystems of the execution system\n",
    "            - define relevant Infrastructure Object properties which are considered features\n",
    "            - build feature vector\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def build_seq_feat_vec(\n",
    "        self,\n",
    "        res_obj: InfrastructureObject,\n",
    "    ) -> 'FeatureVector':\n",
    "        raise NotImplementedError(\"Building sequencing feature vectors is not supported yet.\")\n",
    "    \n",
    "    def check_feasible_agent_alloc(\n",
    "        self,\n",
    "        target_station: ProcessingStation,\n",
    "        op: Operation,\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        method which checks for feasibility of agent allocation decisions\n",
    "        returning True if feasible, False otherwise\n",
    "        \"\"\"\n",
    "        # check if operation has station group identifier (SGI) (CustomID)\n",
    "        op_SGI = op.target_station_group_identifier\n",
    "        \n",
    "        # no station group assigned, choosen station is automatically feasible\n",
    "        if op_SGI is None:\n",
    "            return True\n",
    "        else:\n",
    "            # lookup SGIs of the target station's station groups\n",
    "            target_SGIs = target_station.supersystems_custom_ids\n",
    "            \n",
    "        if op_SGI in target_SGIs:\n",
    "            # operation SGI in associated station group IDs found, \n",
    "            # target station is feasible for given operation\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def check_integrity(self) -> None:\n",
    "        \"\"\"\n",
    "        method to evaluate if certain criteria for the simulation run are satisfied\n",
    "        checks for:\n",
    "        - registered dispatcher (min: 1, max: 1)\n",
    "        - registered sink (min: 1, max: INF)\n",
    "        \"\"\"\n",
    "        # registration of an Infrastructure Manager\n",
    "        if not self._infstruct_mgr_registered:\n",
    "            raise ValueError(\"No Infrastructure Manager instance registered.\")\n",
    "        # registration of a Dispatcher\n",
    "        elif not self._dispatcher_registered:\n",
    "            raise ValueError(\"No Dispatcher instance registered.\")\n",
    "        # registration of sinks\n",
    "        elif not self._infstruct_mgr.sink_registered:\n",
    "            raise ValueError(\"No Sink instance registered.\")\n",
    "        # check if all subsystems are associated to supersystems\n",
    "        elif not self._infstruct_mgr.verify_system_association():\n",
    "            raise AssociationError(\"Non-associated subsystems detected!\")\n",
    "        \n",
    "        logger_env.info(f\"Integrity check for Environment {self.name()} successful.\")\n",
    "    \n",
    "    def finalise_sim(self) -> None:\n",
    "        \"\"\"\n",
    "        Function which should be executed at the end of the simulation.\n",
    "        Can be used for finalising data collection, other related tasks or further processing pipelines\n",
    "        \"\"\"\n",
    "        # infrastructure manager instance\n",
    "        self._infstruct_mgr.finalise()\n",
    "        \n",
    "        # dispatcher instance\n",
    "        self._dispatcher.finalise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Infrastructure Manager**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfrastructureManager:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        # init base class, even if not available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # [COMMON]\n",
    "        self._env = env\n",
    "        self._env.register_infrastructure_manager(infstruct_mgr=self)\n",
    "        # subsystem types\n",
    "        self._subsystem_types: set[str] = set([\n",
    "            'ProductionArea',\n",
    "            'StationGroup',\n",
    "            'Resource',\n",
    "        ])\n",
    "        \n",
    "        # [PRODUCTION AREAS] database as simple Pandas DataFrame\n",
    "        self._prod_area_prop: dict[str, type] = {\n",
    "            'prod_area_id': int,\n",
    "            'custom_id': object,\n",
    "            'name': str,\n",
    "            'prod_area': object,\n",
    "            'containing_proc_stations': bool,\n",
    "        }\n",
    "        self._prod_area_db: DataFrame = pd.DataFrame(columns=list(self._prod_area_prop.keys()))\n",
    "        self._prod_area_db = self._prod_area_db.astype(self._prod_area_prop)\n",
    "        self._prod_area_db = self._prod_area_db.set_index('prod_area_id')\n",
    "        self._prod_area_lookup_props: set[str] = set(['prod_area_id', 'custom_id', 'name'])\n",
    "        # [PRODUCTION AREAS] identifiers\n",
    "        self._prod_area_counter: ObjectID = 0\n",
    "        self._prod_area_custom_identifiers: set[CustomID] = set()\n",
    "        \n",
    "        # [STATION GROUPS] database as simple Pandas DataFrame\n",
    "        self._station_group_prop: dict[str, type] = {\n",
    "            'station_group_id': int,\n",
    "            'custom_id': object,\n",
    "            'name': str,\n",
    "            'station_group': object,\n",
    "            'prod_area_id': pd.Int64Dtype(),\n",
    "            'containing_proc_stations': bool,\n",
    "        }\n",
    "        self._station_group_db: DataFrame = pd.DataFrame(columns=list(self._station_group_prop.keys()))\n",
    "        self._station_group_db = self._station_group_db.astype(self._station_group_prop)\n",
    "        self._station_group_db = self._station_group_db.set_index('station_group_id')\n",
    "        self._station_group_lookup_props: set[str] = set(['station_group_id', 'custom_id', 'name'])\n",
    "        # [STATION GROUPS] identifiers\n",
    "        self._station_group_counter: ObjectID = 0\n",
    "        self._station_groups_custom_identifiers: set[CustomID] = set()\n",
    "        \n",
    "        # [RESOURCES] database as simple Pandas DataFrame\n",
    "        self._infstruct_prop: dict[str, type] = {\n",
    "            'res_id': int,\n",
    "            'custom_id': object,\n",
    "            'resource': object,\n",
    "            'name': str,\n",
    "            'res_type': str,\n",
    "            'state': str,\n",
    "            'station_group_id': pd.Int64Dtype(),\n",
    "        }\n",
    "        self._res_db: DataFrame = pd.DataFrame(columns=list(self._infstruct_prop.keys()))\n",
    "        self._res_db = self._res_db.astype(self._infstruct_prop)\n",
    "        self._res_db = self._res_db.set_index('res_id')\n",
    "        self._res_lookup_props: set[str] = set(['res_id', 'custom_id', 'name'])\n",
    "        # [RESOURCES] custom identifiers\n",
    "        self._res_counter: ObjectID = 0\n",
    "        self._res_custom_identifiers: set[CustomID] = set()\n",
    "        # [RESOURCES] sink: pool of sinks possible to allow multiple sinks in one environment\n",
    "        # [PERHAPS CHANGED LATER] \n",
    "        # currently only one sink out of the pool is chosen because jobs do not contain \n",
    "        # information about a target sink\n",
    "        self._sink_registered: bool = False\n",
    "        self._sinks: list[Sink] = list()\n",
    "        \n",
    "        # counter for processing stations (machines, assembly, etc.)\n",
    "        self.num_proc_stations: int = 0\n",
    "        \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    # [PRODUCTION AREAS]\n",
    "    @property\n",
    "    def prod_area_db(self) -> DataFrame:\n",
    "        return self._prod_area_db\n",
    "    \n",
    "    # [STATION GROUPS]\n",
    "    @property\n",
    "    def station_group_db(self) -> DataFrame:\n",
    "        return self._station_group_db\n",
    "    \n",
    "    def verify_system_association(self) -> bool:\n",
    "        \"\"\"checks if there are any registered, but non-associated subsystems for each subsystem type\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            indicator if all systems are associated (True) or not (False)\n",
    "        \"\"\"\n",
    "        # check all subsystem types with reference to supersystems if there are\n",
    "        # any open references (NA values as secondary key)\n",
    "        relevant_subsystems = ('StationGroup', 'Resource')\n",
    "        \n",
    "        for subsystem_type in relevant_subsystems:\n",
    "            match subsystem_type:\n",
    "                case 'StationGroup':\n",
    "                    target_db = self._station_group_db\n",
    "                    secondary_key: str = 'prod_area_id'\n",
    "                case 'Resource':\n",
    "                    target_db = self._res_db\n",
    "                    secondary_key: str = 'station_group_id'\n",
    "            # check if there are any NA values as secondary key\n",
    "            check_val: bool = target_db[secondary_key].isna().any()\n",
    "            if check_val:\n",
    "                # there are NA values\n",
    "                logger_infstrct.error(f\"There are non-associated systems for system type >>{subsystem_type}<<. \\\n",
    "                    Please check these systems and add them to a corresponding supersystem.\")\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    ####################################################################################\n",
    "    ## REWORK TO WORK WITH DIFFERENT SUBSYSTEMS\n",
    "    # only one register method by analogy with 'lookup_subsystem_info'\n",
    "    # currently checking for existence and registration implemented, split into different methods\n",
    "    # one to check whether such a subsystem already exists\n",
    "    # another one registers a new subsystem\n",
    "    # if check positive: return subsystem by 'lookup_subsystem_info'\n",
    "    ### REWORK TO MULTIPLE SUBSYSTEMS\n",
    "    def _obtain_system_id(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "    ) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing system IDs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ObjectID\n",
    "            unique system ID\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                system_id = self._prod_area_counter\n",
    "                self._prod_area_counter += 1\n",
    "            case 'StationGroup':\n",
    "                system_id = self._station_group_counter\n",
    "                self._station_group_counter += 1\n",
    "            case 'Resource':\n",
    "                system_id = self._res_counter\n",
    "                self._res_counter += 1\n",
    "        \n",
    "        return system_id\n",
    "    \n",
    "    def register_subsystem(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        obj: System,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None,\n",
    "        state: str | None = None,\n",
    "    ) ->  tuple[ObjectID, str]:\n",
    "        \"\"\"\n",
    "        registers an infrastructure object in the environment by assigning an unique id and \n",
    "        adding the object to the associated resources of the environment\n",
    "        \n",
    "        obj: env resource = instance of a subclass of InfrastructureObject\n",
    "        custom_identifier: user defined identifier\n",
    "        name: custom name of the object, \\\n",
    "            default: None\n",
    "        returns:\n",
    "            ObjectID: assigned resource ID\n",
    "            str: assigned resource's name\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                custom_identifiers = self._prod_area_custom_identifiers\n",
    "            case 'StationGroup':\n",
    "                custom_identifiers = self._station_groups_custom_identifiers\n",
    "            case 'Resource':\n",
    "                custom_identifiers = self._res_custom_identifiers\n",
    "        \n",
    "        # check for uniqueness of custom_identifier\n",
    "        # type security\n",
    "        if not isinstance(custom_identifier, (str, int)):\n",
    "            raise TypeError(\"Custom identifier must be of type STR or INT\")\n",
    "        # create check value\n",
    "        if isinstance(custom_identifier, str):\n",
    "            # remove capital letters for checking\n",
    "            check_val = custom_identifier.lower()\n",
    "        else:\n",
    "            check_val = custom_identifier\n",
    "        \n",
    "        # check if value already exists\n",
    "        if check_val in custom_identifiers:\n",
    "            raise ValueError(f\"The custom identifier {custom_identifier} provided for subsystem type {subsystem_type} \\\n",
    "                already exists, but has to be unique.\")\n",
    "        else:\n",
    "            custom_identifiers.add(check_val)\n",
    "        \n",
    "        # obtain system ID\n",
    "        system_id = self._obtain_system_id(subsystem_type=subsystem_type)\n",
    "        \n",
    "        # [RESOURCES] resource related data\n",
    "        # register sinks\n",
    "        if isinstance(obj, Sink):\n",
    "            if not self._sink_registered:\n",
    "                self._sink_registered = True\n",
    "            self._sinks.append(obj)\n",
    "        # count number of machines\n",
    "        if isinstance(obj, ProcessingStation):\n",
    "            self.num_proc_stations += 1\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'{type(obj).__name__}_env_{system_id}'\n",
    "        \n",
    "        # new entry for corresponding database\n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'prod_area_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'name': [name],\n",
    "                                        'prod_area': [obj],\n",
    "                                        'containing_proc_stations': [obj.containing_proc_stations]})\n",
    "                new_entry = new_entry.astype(self._prod_area_prop)\n",
    "                new_entry = new_entry.set_index('prod_area_id')\n",
    "                self._prod_area_db = pd.concat([self._prod_area_db, new_entry])\n",
    "            case 'StationGroup':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'station_group_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'name': [name],\n",
    "                                        'station_group': [obj],\n",
    "                                        'prod_area_id': [None],\n",
    "                                        'containing_proc_stations': [obj.containing_proc_stations]})\n",
    "                new_entry = new_entry.astype(self._station_group_prop)\n",
    "                new_entry = new_entry.set_index('station_group_id')\n",
    "                self._station_group_db = pd.concat([self._station_group_db, new_entry])\n",
    "            case 'Resource':\n",
    "                new_entry: DataFrame = pd.DataFrame({\n",
    "                                        'res_id': [system_id],\n",
    "                                        'custom_id': [custom_identifier],\n",
    "                                        'resource': [obj],\n",
    "                                        'name': [name],\n",
    "                                        'res_type': [obj.res_type],\n",
    "                                        'state': [state],\n",
    "                                        'station_group_id': [None]})\n",
    "                new_entry = new_entry.astype(self._infstruct_prop)\n",
    "                new_entry = new_entry.set_index('res_id')\n",
    "                self._res_db = pd.concat([self._res_db, new_entry])\n",
    "        \n",
    "        logger_infstrct.info(f\"Successfully registered object with SystemID {system_id} and name {name}\")\n",
    "        \n",
    "        return system_id, name\n",
    "    \n",
    "    def register_system_association(\n",
    "        self,\n",
    "        supersystem: System,\n",
    "        subsystem: System,\n",
    "    ) -> None:\n",
    "        \"\"\"associate two system types with each other in the corresponding databases\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        supersystem : System\n",
    "            system to which the subsystem is added\n",
    "        subsystem : System\n",
    "            system which is added to the supersystem and to whose database the entry is made\n",
    "        \"\"\"\n",
    "        # target subsystem type -> identify appropriate database\n",
    "        subsystem_type = subsystem.subsystem_type\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'StationGroup':\n",
    "                target_db = self._station_group_db\n",
    "                target_property: str = 'prod_area_id'\n",
    "            case 'Resource':\n",
    "                target_db = self._res_db\n",
    "                target_property: str = 'station_group_id'\n",
    "        # system IDs\n",
    "        supersystem_id = supersystem.system_id\n",
    "        subsystem_id = subsystem.system_id\n",
    "        # write supersystem ID to subsystem database entry\n",
    "        target_db.at[subsystem_id, target_property] = supersystem_id\n",
    "    \n",
    "    def set_contain_proc_station(\n",
    "        self,\n",
    "        system: System,\n",
    "    ) -> None:\n",
    "        \n",
    "        match system.subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                lookup_db = self._prod_area_db\n",
    "            case 'StationGroup':\n",
    "                lookup_db = self._station_group_db\n",
    "\n",
    "        lookup_db.at[system.system_id, 'containing_proc_stations'] = True\n",
    "        system.containing_proc_stations = True\n",
    "        \n",
    "        # iterate over supersystems\n",
    "        for supersystem in system.supersystems.values():\n",
    "            if not supersystem.containing_proc_stations:\n",
    "                self.set_contain_proc_station(system=supersystem)\n",
    "    \n",
    "    def lookup_subsystem_info(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        lookup_val: CustomID,\n",
    "        lookup_property: str | None = None,\n",
    "        target_property: str | None = None,\n",
    "    ) -> tuple[Any, Series | None]:\n",
    "        \"\"\"\n",
    "        obtain a subsystem by its property and corresponding value\n",
    "        properties: Subsystem ID, Custom ID, Name\n",
    "        \"\"\"\n",
    "        if subsystem_type not in self._subsystem_types:\n",
    "            raise ValueError(f\"The subsystem type >>{subsystem_type}<< is not allowed. Choose from {self._subsystem_types}\")\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                allowed_lookup_props = self._prod_area_lookup_props\n",
    "                lookup_db = self._prod_area_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'prod_area'\n",
    "                id_prop: str = 'prod_area_id'\n",
    "            case 'StationGroup':\n",
    "                allowed_lookup_props = self._station_group_lookup_props\n",
    "                lookup_db = self._station_group_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'station_group'\n",
    "                id_prop: str = 'station_group_id'\n",
    "            case 'Resource':\n",
    "                allowed_lookup_props = self._res_lookup_props\n",
    "                lookup_db = self._res_db\n",
    "                if target_property is None:\n",
    "                    target_property = 'resource'\n",
    "                id_prop: str = 'res_id'\n",
    "        \n",
    "        # if no lookup property provided use ID\n",
    "        if lookup_property is None:\n",
    "            lookup_property = id_prop\n",
    "        \n",
    "        # allowed target properties\n",
    "        allowed_target_props: set[str] = set(lookup_db.columns.to_list())\n",
    "        # lookup property can not be part of the target properties\n",
    "        if lookup_property in allowed_target_props:\n",
    "            allowed_target_props.remove(lookup_property)\n",
    "        \n",
    "        # check if property is a filter criterion\n",
    "        if lookup_property not in allowed_lookup_props:\n",
    "            raise IndexError(f\"Lookup Property '{lookup_property}' is not allowed for subsystem type {subsystem_type}. Choose from {allowed_lookup_props}\")\n",
    "        # check if target property is allowed\n",
    "        if target_property not in allowed_target_props:\n",
    "            raise IndexError(f\"Target Property >>{target_property}<< is not allowed for subsystem type {subsystem_type}. Choose from {allowed_target_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if lookup_val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type >>None<<.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if lookup_property == id_prop:\n",
    "            # direct indexing for ID property: always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: Any = lookup_db.at[lookup_val, target_property]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                with the value >>{lookup_val}<<\")\n",
    "        else:\n",
    "            try:\n",
    "                temp1: Series = lookup_db.loc[lookup_db[lookup_property] == lookup_val, target_property]\n",
    "                # check for empty search result, at least one result necessary\n",
    "                if len(temp1) == 0:\n",
    "                    raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                    with the value >>{lookup_val}<<\")\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no subsystems found for the lookup property >>{lookup_property}<< \\\n",
    "                                with the value >>{lookup_val}<<\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            if len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_infstrct.warning(f\"CAUTION: There are multiple subsystems which share the \\\n",
    "                            same value >>{lookup_val}<< for the lookup property >>{lookup_property}<<. \\\n",
    "                            Only the first entry is returned.\")\n",
    "        \n",
    "            return temp1.iat[0]\n",
    "    \n",
    "    def lookup_custom_ID(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        system_ID: ObjectID,\n",
    "    ) -> CustomID:\n",
    "        \n",
    "        match subsystem_type:\n",
    "            case 'ProductionArea':\n",
    "                id_prop: str = 'prod_area_id'\n",
    "            case 'StationGroup':\n",
    "                id_prop: str = 'station_group_id'\n",
    "            case 'Resource':\n",
    "                id_prop: str = 'res_id'\n",
    "        \n",
    "        custom_id = self.lookup_subsystem_info(\n",
    "            subsystem_type=subsystem_type,\n",
    "            lookup_val=system_ID,\n",
    "            lookup_property=id_prop,\n",
    "            target_property='custom_id',\n",
    "        )\n",
    "        \n",
    "        return custom_id\n",
    "    \n",
    "    def lookup_system_ID(\n",
    "        self,\n",
    "        subsystem_type: str,\n",
    "        custom_ID: CustomID,\n",
    "    ) -> ObjectID:\n",
    "        \n",
    "        system = self.lookup_subsystem_info(\n",
    "            subsystem_type=subsystem_type,\n",
    "            lookup_val=custom_ID,\n",
    "            lookup_property='custom_id',\n",
    "        )\n",
    "        \n",
    "        return system.system_id\n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    # [RESOURCES]\n",
    "    @property\n",
    "    def res_db(self) -> DataFrame:\n",
    "        \"\"\"obtain a current overview of registered objects in the environment\"\"\"\n",
    "        return self._res_db\n",
    "    \n",
    "    @property\n",
    "    def sinks(self) -> set[Sink]:\n",
    "        \"\"\"registered sinks\"\"\"\n",
    "        return self._sinks\n",
    "    \n",
    "    @property\n",
    "    def sink_registered(self) -> bool:\n",
    "        return self._sink_registered\n",
    "    \n",
    "    def update_res_state(\n",
    "        self,\n",
    "        obj: InfrastructureObject,\n",
    "        state: str,\n",
    "        reset_temp: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a resource object in the resource database\"\"\"\n",
    "        logger_infstrct.debug(f\"Set state of {obj} to {state}\")\n",
    "        \n",
    "        # check if 'TEMP' state should be reset\n",
    "        if reset_temp:\n",
    "            # special reset method, calls state setting to previous state\n",
    "            obj.stat_monitor.reset_temp_state()\n",
    "            state = obj.stat_monitor.state_current\n",
    "        else:\n",
    "            obj.stat_monitor.set_state(state=state)\n",
    "        \n",
    "        self._res_db.at[obj.system_id, 'state'] = state\n",
    "        logger_infstrct.debug(f\"Executed state setting of {obj} to {state}\")\n",
    "    \n",
    "    def res_objs_temp_state(\n",
    "        self,\n",
    "        res_objs: Iterable[InfrastructureObject],\n",
    "        reset_temp: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"Sets/resets given resource objects from the 'TEMP' state\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        res_objs : Iterable[InfrastructureObject]\n",
    "            objects for which the TEMP state should be changed\n",
    "        set_temp : bool\n",
    "            indicates if the temp state should be set or reset\n",
    "        \"\"\"\n",
    "        for obj in res_objs:\n",
    "            self.update_res_state(obj=obj, state='TEMP', reset_temp=reset_temp)\n",
    "            # calculate KPIs if 'TEMP' state is set\n",
    "            if not reset_temp:\n",
    "                obj.stat_monitor.calc_KPI()\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \n",
    "        # set end state for each resource object to calculate the right time amounts\n",
    "        for res_obj in self._res_db['resource']:\n",
    "            res_obj.finalise()\n",
    "        logger_infstrct.info(\"Successful finalisation of the state information for all resource objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Monitors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='infrastructureobject'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monitor:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        obj: InfrastructureObject | Job | Operation,\n",
    "        init_state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'WAITING', \n",
    "            'PROCESSING',\n",
    "            'SETUP', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Class to monitor associated objects (load and resource)\n",
    "        \"\"\"\n",
    "        # initialise parent class if available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # [REGISTRATION]\n",
    "        self._env = env\n",
    "        self._target_object = obj\n",
    "        \n",
    "        # [STATE] state parameters\n",
    "        # all possible/allowed states\n",
    "        self.states_possible: set[str] = set(possible_states)\n",
    "        # always add states 'INIT', 'FINISH', 'TEMP' for control flow\n",
    "        if not 'INIT' in self.states_possible:\n",
    "            self.states_possible.add('INIT')\n",
    "        if not 'FINISH' in self.states_possible:\n",
    "            self.states_possible.add('FINISH')\n",
    "        if not 'TEMP' in self.states_possible:\n",
    "            self.states_possible.add('TEMP')\n",
    "            \n",
    "        # check integrity of the given state\n",
    "        if init_state in self.states_possible:\n",
    "            self.state_current: str = init_state\n",
    "        else:\n",
    "            raise ValueError(f\"The state {state} is not allowed. Must be one of {self.states_possible}\")\n",
    "        \n",
    "        # boolean indicator if a state is set\n",
    "        self.state_status: dict[str, bool] = dict()\n",
    "        # time counter for each state\n",
    "        #self.state_times: dict[str, float] = dict()\n",
    "        self.state_times: dict[str, Timedelta] = dict()\n",
    "        # starting time variable indicating when the last state assignment took place\n",
    "        #self.state_starting_time: float = self._env.t()\n",
    "        self.state_starting_time: Datetime = self._env.t_as_dt()\n",
    "        \n",
    "        for state in self.states_possible:\n",
    "            # init state time dictionary\n",
    "            #self.state_times[state] = 0.\n",
    "            self.state_times[state] = Timedelta()\n",
    "            # init state is set to True\n",
    "            if state == self.state_current:\n",
    "                self.state_status[state] = True\n",
    "            else:\n",
    "                self.state_status[state] = False\n",
    "                \n",
    "        # DataFrame to further analyse state durations\n",
    "        self.state_durations: DataFrame | None = None\n",
    "\n",
    "        # availability indicator\n",
    "        self._availability_states: set[str] = set([\n",
    "            'WAITING',\n",
    "        ])\n",
    "        if self.state_current in self._availability_states:\n",
    "            self.is_available: bool = True\n",
    "        else:\n",
    "            self.is_available: bool = False\n",
    "        \n",
    "        # additional 'TEMP' state information\n",
    "        # indicator if state was 'TEMP'\n",
    "        self._is_temp: bool = False\n",
    "        # state before 'TEMP' was set\n",
    "        self._state_before_temp: str = self.state_current\n",
    "        # time components\n",
    "        self.time_active: float = 0.\n",
    "        #self.time_active: Timedelta = Timedelta()\n",
    "        \n",
    "        # time handling\n",
    "        self._dt_parser: DTParser = DTParser()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Monitor instance of {self._target_object}\"\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "        \n",
    "    def get_current_state(self) -> str:\n",
    "        \"\"\"get the current state of the associated resource\"\"\"\n",
    "        return self.state_current\n",
    "        \n",
    "    def set_state(\n",
    "        self,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        function to set the object in the given state\n",
    "        state: name of the state in which the object should be placed, must be part \\\n",
    "            of the object's possible states\n",
    "        \"\"\"\n",
    "        # eliminate lower-case letters\n",
    "        target_state = state.upper()\n",
    "        \n",
    "        # check if state is allowed\n",
    "        if target_state not in self.states_possible:\n",
    "            raise ValueError(f\"The state {target_state} is not allowed. Must be one of {self.states_possible}\")\n",
    "        \n",
    "        # check if state is already set\n",
    "        if self.state_status[target_state] == True and target_state != 'TEMP':\n",
    "            logger_monitors.info(f\"Tried to set state of {self._target_object} to >>{target_state}<<, but this state was already set.\\\n",
    "                The object's state was not changed.\")\n",
    "        # check if the 'TEMP' state was already set, this should never happen\n",
    "        # if it happens raise an error to catch wrong behaviour\n",
    "        elif self.state_status[target_state] == True and target_state == 'TEMP':\n",
    "            raise RuntimeError(f\"Tried to set state of {self._target_object} to >>TEMP<<, but this state was already set.\")\n",
    "        \n",
    "        # calculate time for which the object was in the current state before changing it\n",
    "        current_state_start = self.state_starting_time\n",
    "        #current_time = self._env.now()\n",
    "        current_time = self._env.t_as_dt()\n",
    "        current_state_duration: Timedelta = current_time - current_state_start\n",
    "        # add time to the time counter for the current state\n",
    "        current_state = self.state_current\n",
    "        self.state_times[current_state] += current_state_duration\n",
    "        \n",
    "        # check if 'TEMP' state shall be set\n",
    "        if target_state == 'TEMP':\n",
    "            # set 'TEMP' state indicator to true\n",
    "            self._is_temp = True\n",
    "            # save current state for the state reset\n",
    "            self._state_before_temp = current_state\n",
    "        \n",
    "        # set old state to False and new state to True\n",
    "        self.state_status[current_state] = False\n",
    "        self.state_status[target_state] = True\n",
    "        # assign new state as current one\n",
    "        self.state_current = target_state\n",
    "        # set state starting time to current time\n",
    "        self.state_starting_time = current_time\n",
    "        # availability\n",
    "        if self.state_current in self._availability_states:\n",
    "            self.is_available: bool = True\n",
    "        elif self.state_current == 'TEMP':\n",
    "            # 'TEMP' state shall not change the availability indicator\n",
    "            pass\n",
    "        else:\n",
    "            self.is_available: bool = False\n",
    "        \n",
    "        logger_monitors.debug(f\"Duration for state {current_state} on {self._target_object} was {current_state_duration}\")\n",
    "    \n",
    "    def reset_temp_state(self) -> None:\n",
    "        \"\"\"Reset from 'TEMP' state\n",
    "        \"\"\"\n",
    "        # check if object was in TEMP state, raise error if not\n",
    "        if not self._is_temp:\n",
    "            raise RuntimeError(f\"Tried to reset {self._target_object} from 'TEMP' state but \\\n",
    "                the current state is >>{self.state_current}<<\")\n",
    "        else:\n",
    "            self._is_temp = False\n",
    "            self.set_state(state=self._state_before_temp)\n",
    "    \n",
    "    def calc_KPI(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"calculates different KPIs at any point in time\n",
    "        \"\"\"\n",
    "        \n",
    "        # state durations for analysis\n",
    "        if not is_finalise:\n",
    "            self.state_durations = self.state_durations_as_df()\n",
    "        \n",
    "        # [TOTAL ACTIVE TIME]\n",
    "        self.time_active = self.state_durations.loc[:, 'abs [seconds]'].sum()\n",
    "    \n",
    "    def state_durations_as_df(self) -> DataFrame:\n",
    "        \"\"\"Calculates absolute and relative state durations at the current time\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            State duration table with absolute and relative values\n",
    "        \"\"\"\n",
    "        # build state duration table\n",
    "        temp1: Series = pd.Series(data=self.state_times)\n",
    "        temp2: DataFrame = temp1.to_frame()\n",
    "        temp2.columns = ['abs [Timedelta]']\n",
    "        temp2['abs [seconds]'] = temp2['abs [Timedelta]'].apply(func= lambda x: x.total_seconds())\n",
    "        temp2['rel [%]'] = temp2['abs [seconds]'] / temp2.sum(axis=0)['abs [seconds]'] * 100\n",
    "        temp2 = temp2.drop(labels=['INIT', 'FINISH', 'TEMP'], axis=0)\n",
    "        temp2 = temp2.sort_index(axis=0, ascending=True, kind='stable')\n",
    "        state_durations_df = temp2.copy()\n",
    "        \n",
    "        return state_durations_df\n",
    "    \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        \n",
    "        # assign state duration table\n",
    "        self.state_durations = self.state_durations_as_df()\n",
    "        \n",
    "        # calculate KPIs\n",
    "        self.calc_KPI(is_finalise=True)\n",
    "    \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_state_bar_chart(        \n",
    "        self,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'state_distribution_bar',\n",
    "        time_unit: str = 'hours',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"draws the collected state times of the object as bar chart\"\"\"\n",
    "        data = pd.DataFrame.from_dict(data=self.state_times, orient='index', columns=['total time'])\n",
    "        data.index = data.index.rename('state')\n",
    "        # change time from Timedelta to any time unit possible --> float\n",
    "        # Plotly can not handle Timedelta objects properly, only Datetimes\n",
    "        calc_td = self._dt_parser.timedelta_from_val(val=1., time_unit=time_unit)\n",
    "        calc_col: str = f'total time [{time_unit}]'\n",
    "        data[calc_col] = data['total time'] / calc_td\n",
    "        data = data.sort_index(axis=0, kind='stable')\n",
    "        \n",
    "        fig: PlotlyFigure = px.bar(data, y=calc_col, text_auto='.2f')\n",
    "        fig.update_layout(title=f'State Time Distribution of {self._target_object}', showlegend=False)\n",
    "        fig.update_yaxes(title=dict({'text': calc_col}))\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def draw_state_pie_chart(        \n",
    "        self,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'state_distribution_pie',\n",
    "        time_unit: str = 'hours',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"draws the collected state times of the object as bar chart\"\"\"\n",
    "        data = pd.DataFrame.from_dict(data=self.state_times, orient='index', columns=['total time'])\n",
    "        data.index = data.index.rename('state')\n",
    "        # change time from Timedelta to any time unit possible --> float\n",
    "        # Plotly can not handle Timedelta objects properly, only Datetimes\n",
    "        calc_td = self._dt_parser.timedelta_from_val(val=1., time_unit=time_unit)\n",
    "        calc_col: str = f'total time [{time_unit}]'\n",
    "        data[calc_col] = data['total time'] / calc_td\n",
    "        data = data.sort_index(axis=0, kind='stable')\n",
    "        data = data.loc[data[calc_col] > 0., :]\n",
    "        \n",
    "        fig: PlotlyFigure = px.pie(data, values=calc_col, names=data.index)\n",
    "        fig.update_layout(title=f'State Time Distribution of {self._target_object}')\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferMonitor(Monitor):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obj: Buffer,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # initialise parent class\n",
    "        super().__init__(obj=obj, **kwargs)\n",
    "        \n",
    "        # fill level tracking\n",
    "        \"\"\"\n",
    "        self._level_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': int,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self._level_db_types = {\n",
    "            'sim_time': object,\n",
    "            'duration': object,\n",
    "            'level': int,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self._level_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., obj.start_fill_level]])\n",
    "        \"\"\"\n",
    "        self._level_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[self.env.t_as_dt(), Timedelta(), obj.start_fill_level]])\n",
    "        self._level_db = self._level_db.astype(self._level_db_types)\n",
    "        \n",
    "        self._current_fill_level = obj.start_fill_level\n",
    "        #self._fill_level_starting_time: float = self.env.now()\n",
    "        self._fill_level_starting_time: Datetime = self.env.t_as_dt()\n",
    "        self._wei_avg_fill_level: float | None = None\n",
    "        \n",
    "    @property\n",
    "    def wei_avg_fill_level(self) -> float:\n",
    "        return self._wei_avg_fill_level\n",
    "    \n",
    "    @property\n",
    "    def level_db(self) -> DataFrame:\n",
    "        return self._level_db\n",
    "    \n",
    "    def set_state(\n",
    "        self,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"additional level tracking functionality\"\"\"\n",
    "        super().set_state(state=state)\n",
    "        \n",
    "        is_finalise: bool = False\n",
    "        if self.state_current == 'FINISH':\n",
    "            is_finalise: bool = True\n",
    "        self.track_fill_level(is_finalise=is_finalise)\n",
    "        \n",
    "    # Buffer fill level tracking\n",
    "    def track_fill_level(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"adds an entry to the fill level database\"\"\"\n",
    "        # only calculate duration if buffer level changes\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        duration: Timedelta = current_time - self._fill_level_starting_time\n",
    "        logger_buffers.debug(f\"[BUFFER: {self._target_object}] Current time is {current_time} with level {len(self._target_object)} and old level {self._current_fill_level}\")\n",
    "        #if ((self._current_fill_level != len(self)) and (duration > 0.0)) or is_finalise:\n",
    "        if (self._current_fill_level != len(self._target_object)) or is_finalise:\n",
    "            temp1: Series = pd.Series(\n",
    "                                    index=['sim_time', 'duration', 'level'],\n",
    "                                    data=[current_time, duration, self._current_fill_level])\n",
    "            temp2: DataFrame = temp1.to_frame().T.astype(self._level_db_types)\n",
    "            self._level_db = pd.concat([self._level_db, temp2], ignore_index=True)\n",
    "            self._current_fill_level = len(self._target_object)\n",
    "            self._fill_level_starting_time = current_time\n",
    "        \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        # execute parent class function\n",
    "        super().finalise_stats()\n",
    "        \n",
    "        # finalise fill level tracking\n",
    "        self.track_fill_level(is_finalise=True)\n",
    "        \n",
    "        # weighted average fill level\n",
    "        self._level_db = self._level_db.loc[self._level_db['duration'] > Timedelta(), :].copy()\n",
    "        self._level_db = self._level_db.reset_index(drop=True)\n",
    "        temp1: DataFrame = self._level_db.copy()\n",
    "        temp1['duration_seconds'] = temp1['duration'].apply(func= lambda x: x.total_seconds())\n",
    "        temp1['mul'] = temp1['duration_seconds'] * temp1['level']\n",
    "        sums: Series = temp1.filter(items=['duration_seconds', 'mul']).sum(axis=0)\n",
    "        #sums: Series = temp1.sum(axis=0)\n",
    "        self._wei_avg_fill_level: float = sums['mul'] / sums['duration_seconds']\n",
    "        \n",
    "        \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_fill_level(\n",
    "        self,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'fill_level',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        method to draw and display the fill level expansion of the corresponding buffer\n",
    "        \"\"\"\n",
    "        # add starting point to start chart at t = init time\n",
    "        data = self._level_db.copy()\n",
    "        val1: float = data.at[0, 'sim_time'] - data.at[0, 'duration']\n",
    "        val2: float = 0.\n",
    "        val3: int = data.at[0, 'level']\n",
    "        temp1: DataFrame = pd.DataFrame(columns=data.columns, data=[[val1, val2, val3]])\n",
    "        temp1 = pd.concat([temp1, data], ignore_index=True)\n",
    "        \n",
    "        fig: PlotlyFigure = px.line(x=temp1['sim_time'], y=temp1['level'], line_shape=\"vh\")\n",
    "        fig.update_traces(line=dict(width=3))\n",
    "        fig.update_layout(title=f'Fill Level of {self._target_object}')\n",
    "        fig.update_yaxes(title=dict({'text': 'fill level [-]'}))\n",
    "        fig.update_xaxes(title=dict({'text': 'time'}))\n",
    "        # weighted average fill level\n",
    "        fig.add_hline(\n",
    "                    y=self.wei_avg_fill_level, line_width=3, \n",
    "                    line_dash='dot', line_color='orange')\n",
    "        # capacity\n",
    "        cap = self._target_object.capacity()\n",
    "        if cap < INF:\n",
    "            fig.add_hline(\n",
    "                        y=cap, line_width=3, \n",
    "                        line_dash='dash', line_color='red')\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfStructMonitor(Monitor):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        obj: ProcessingStation,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # initialise parent class\n",
    "        super().__init__(obj=obj, **kwargs)\n",
    "        \n",
    "        # WIP tracking time load\n",
    "        \"\"\"\n",
    "        self._WIP_time_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': float,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self._WIP_time_db_types = {\n",
    "            'sim_time': object,\n",
    "            'duration': object,\n",
    "            'level': object,\n",
    "        }\n",
    "        ###################### PERHAPS ADD STARTING LEVEL LATER\n",
    "        \"\"\"\n",
    "        self._WIP_time_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., 0.]])\n",
    "        \"\"\"\n",
    "        self._WIP_time_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[self.env.t_as_dt(), Timedelta(), Timedelta()]])\n",
    "        self._WIP_time_db = self._WIP_time_db.astype(self._WIP_time_db_types)\n",
    "        \n",
    "        # WIP tracking number of jobs\n",
    "        \"\"\"\n",
    "        self._WIP_num_db_types = {\n",
    "            'sim_time': float,\n",
    "            'duration': float,\n",
    "            'level': int,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self._WIP_num_db_types = {\n",
    "            'sim_time': object,\n",
    "            'duration': object,\n",
    "            'level': int,\n",
    "        }\n",
    "        ###################### PERHAPS ADD STARTING LEVEL LATER\n",
    "        \"\"\"\n",
    "        self._WIP_num_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[0., 0., 0]])\n",
    "        \"\"\"\n",
    "        self._WIP_num_db: DataFrame = pd.DataFrame(\n",
    "                                        columns=['sim_time', 'duration', 'level'], \n",
    "                                        data=[[self.env.t_as_dt(), Timedelta(), 0]])\n",
    "        self._WIP_num_db = self._WIP_num_db.astype(self._WIP_num_db_types)\n",
    "        \n",
    "        #self._current_WIP_time: float = 0.\n",
    "        #self._last_WIP_time: float = 0.\n",
    "        #self._current_WIP_num: int = 0\n",
    "        #self._last_WIP_num: int = 0\n",
    "        \n",
    "        #self._WIP_time_starting_time: float = self.env.now()\n",
    "        self._WIP_time_starting_time: Datetime = self.env.t_as_dt()\n",
    "        #self._WIP_num_starting_time: float = self.env.now()\n",
    "        self._WIP_num_starting_time: Datetime = self.env.t_as_dt()\n",
    "        self._wei_avg_WIP_level_time: Timedelta | None = None\n",
    "        self._wei_avg_WIP_level_num: float | None = None\n",
    "        \n",
    "        # time components\n",
    "        self.time_occupied: float = 0.\n",
    "        \n",
    "        # resource KPIs\n",
    "        self.utilisation: float = 0.\n",
    "        \n",
    "        # logistic objective values\n",
    "        #self.WIP_load_time: float = 0.\n",
    "        #self._WIP_load_time_last: float = 0.\n",
    "        self.WIP_load_time: Timedelta = Timedelta()\n",
    "        self._WIP_load_time_last: Timedelta = Timedelta()\n",
    "        self.WIP_load_num_jobs: int = 0\n",
    "        self._WIP_load_num_jobs_last: int = 0\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_WIP_level_time(self) -> float:\n",
    "        return self._wei_avg_WIP_level_time\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_WIP_level_num(self) -> float:\n",
    "        return self._wei_avg_WIP_level_num\n",
    "    \n",
    "    @property\n",
    "    def WIP_time_db(self) -> DataFrame:\n",
    "        return self._WIP_time_db\n",
    "    \n",
    "    @property\n",
    "    def WIP_num_db(self) -> DataFrame:\n",
    "        return self._WIP_num_db\n",
    "    \n",
    "    def _track_WIP_level(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"adds an entry to the fill level database\"\"\"\n",
    "        # only calculate duration if level changes\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        \n",
    "        if (self._WIP_load_time_last != self.WIP_load_time) or is_finalise:\n",
    "            \n",
    "            # if updates occur at an already set time, just update the level\n",
    "            if self._WIP_time_starting_time == current_time:\n",
    "                self._WIP_time_db.iat[-1,2] = self.WIP_load_time\n",
    "                self._WIP_load_time_last = self.WIP_load_time\n",
    "            # else new entry\n",
    "            else:\n",
    "                duration = current_time - self._WIP_time_starting_time\n",
    "                temp1: Series = pd.Series(\n",
    "                                        index=['sim_time', 'duration', 'level'],\n",
    "                                        data=[current_time, duration, self.WIP_load_time])\n",
    "                temp2: DataFrame = temp1.to_frame().T.astype(self._WIP_time_db_types)\n",
    "                self._WIP_time_db = pd.concat([self._WIP_time_db, temp2], ignore_index=True)\n",
    "                self._WIP_load_time_last = self.WIP_load_time\n",
    "                self._WIP_time_starting_time = current_time\n",
    "            \n",
    "        if (self._WIP_load_num_jobs_last != self.WIP_load_num_jobs) or is_finalise:\n",
    "            \n",
    "            # if updates occur at an already set time, just update the level\n",
    "            if self._WIP_num_starting_time == current_time:\n",
    "                self._WIP_num_db.iat[-1,2] = self.WIP_load_num_jobs\n",
    "                self._WIP_load_num_jobs_last = self.WIP_load_num_jobs\n",
    "            # else new entry\n",
    "            else:\n",
    "                duration = current_time - self._WIP_num_starting_time\n",
    "                temp1: Series = pd.Series(\n",
    "                                        index=['sim_time', 'duration', 'level'],\n",
    "                                        data=[current_time, duration, self.WIP_load_num_jobs])\n",
    "                temp2: DataFrame = temp1.to_frame().T.astype(self._WIP_num_db_types)\n",
    "                self._WIP_num_db = pd.concat([self._WIP_num_db, temp2], ignore_index=True)\n",
    "                self._WIP_load_num_jobs_last = self.WIP_load_num_jobs\n",
    "                self._WIP_num_starting_time = current_time\n",
    "    \n",
    "    def calc_KPI(\n",
    "        self,\n",
    "        is_finalise: bool = False,\n",
    "    ) -> None:\n",
    "        \n",
    "        super().calc_KPI()\n",
    "        \n",
    "        # [OCCUPATION]\n",
    "        # properties which count as occupied\n",
    "        # paused counts in because pausing the processing station is an external factor\n",
    "        util_props = ['PROCESSING', 'PAUSED']\n",
    "        self.time_occupied = self.state_durations.loc[util_props, 'abs [seconds]'].sum()\n",
    "        \n",
    "        # [UTILISATION]\n",
    "        # avoid division by 0\n",
    "        if self.time_active > 0.:\n",
    "            self.utilisation: float = self.time_occupied / self.time_active\n",
    "    \n",
    "    def change_WIP(\n",
    "        self,\n",
    "        job: Job,\n",
    "        remove: bool,\n",
    "    ) -> None:\n",
    "        # removing WIP\n",
    "        if remove:\n",
    "            # next operation of the job already assigned\n",
    "            #self.WIP_load_time -= job.last_proc_time\n",
    "            self.WIP_load_time -= job.last_order_time\n",
    "            self.WIP_load_num_jobs -= 1\n",
    "        else:\n",
    "            #self.WIP_load_time += job.current_proc_time\n",
    "            self.WIP_load_time += job.current_order_time\n",
    "            self.WIP_load_num_jobs += 1\n",
    "        \n",
    "        self._track_WIP_level()\n",
    "    \n",
    "    def finalise_stats(self) -> None:\n",
    "        \"\"\"finalisation of stats gathering\"\"\"\n",
    "        # execute parent class function\n",
    "        super().finalise_stats()\n",
    "        \n",
    "        # finalise WIP level tracking\n",
    "        self._track_WIP_level(is_finalise=True)\n",
    "        \n",
    "        # post-process WIP time level databases\n",
    "        #print(f'I AM {self}')\n",
    "        self._WIP_time_db['level'] = self._WIP_time_db['level'].shift(periods=1, fill_value=Timedelta())\n",
    "        self._WIP_time_db = self._WIP_time_db.loc[self._WIP_time_db['duration'] > Timedelta(), :].copy()\n",
    "        self._WIP_time_db = self._WIP_time_db.reset_index(drop=True)\n",
    "        \n",
    "        # weighted average WIP time level\n",
    "        temp1: DataFrame = self._WIP_time_db.copy()\n",
    "        temp1['level_seconds'] = temp1['level'].apply(func= lambda x: x.total_seconds())\n",
    "        temp1['duration_seconds'] = temp1['duration'].apply(func= lambda x: x.total_seconds())\n",
    "        temp1['mul'] = temp1['duration_seconds'] * temp1['level_seconds']\n",
    "        sums: Series = temp1.filter(items=['duration_seconds', 'mul']).sum(axis=0)\n",
    "        wei_avg_time_sec: float = sums['mul'] / sums['duration_seconds']\n",
    "        self._wei_avg_WIP_level_time: Timedelta = Timedelta(seconds=wei_avg_time_sec)\n",
    "        \n",
    "        # post-process WIP num level databases\n",
    "        self._WIP_num_db['level'] = self._WIP_num_db['level'].shift(periods=1, fill_value=Timedelta())\n",
    "        self._WIP_num_db = self._WIP_num_db.loc[self._WIP_num_db['duration'] > Timedelta(), :].copy()\n",
    "        self._WIP_num_db = self._WIP_num_db.reset_index(drop=True)\n",
    "        # weighted average WIP num level\n",
    "        temp1: DataFrame = self._WIP_num_db.copy()\n",
    "        temp1['duration_seconds'] = temp1['duration'].apply(func= lambda x: x.total_seconds())\n",
    "        temp1['mul'] = temp1['duration_seconds'] * temp1['level']\n",
    "        sums: Series = temp1.filter(items=['duration_seconds', 'mul']).sum(axis=0)\n",
    "        self._wei_avg_WIP_level_num: float = sums['mul'] / sums['duration_seconds']\n",
    "    \n",
    "    ### ANALYSE AND CHARTS ###\n",
    "    def draw_WIP_level(\n",
    "        self,\n",
    "        use_num_jobs_metric: bool = False,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'fill_level',\n",
    "        time_unit_load_time: str = 'hours',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        method to draw and display the fill level expansion of the corresponding buffer\n",
    "        \"\"\"\n",
    "        # add starting point to start chart at t = init time\n",
    "        if use_num_jobs_metric:\n",
    "            data = self._WIP_num_db.copy()\n",
    "            title = f'WIP Level Num Jobs of {self._target_object}'\n",
    "            yaxis = 'WIP Level Number of Jobs [-]'\n",
    "            avg_WIP_level = self._wei_avg_WIP_level_num\n",
    "            #last_WIP_level = self.WIP_load_time\n",
    "            last_WIP_level = self.WIP_load_num_jobs\n",
    "        else:\n",
    "            data = self._WIP_time_db.copy()\n",
    "            # change WIP load time from Timedelta to any time unit possible --> float\n",
    "            # Plotly can not handle Timedelta objects properly, only Datetimes\n",
    "            calc_td = self._dt_parser.timedelta_from_val(val=1., time_unit=time_unit_load_time)\n",
    "            data['level'] = data['level'] / calc_td\n",
    "            title = f'WIP Level Time of {self._target_object}'\n",
    "            yaxis = 'WIP Level Time [time units]'\n",
    "            avg_WIP_level: float = self._wei_avg_WIP_level_time / calc_td\n",
    "            last_WIP_level: float = self.WIP_load_time / calc_td\n",
    "        f_val1: Datetime = data.at[0, 'sim_time'] - data.at[0, 'duration']\n",
    "        f_val2: Timedelta = Timedelta()\n",
    "        f_val3: float = data.at[0, 'level']\n",
    "        first_entry: DataFrame = pd.DataFrame(columns=data.columns, data=[[f_val1, f_val2, f_val3]])\n",
    "        l_val1: Datetime = data.iat[-1, 0]\n",
    "        l_val2: Timedelta = Timedelta()\n",
    "        l_val3: float = last_WIP_level # REWORK type hint\n",
    "        last_entry: DataFrame = pd.DataFrame(columns=data.columns, data=[[l_val1, l_val2, l_val3]])\n",
    "        temp1: DataFrame = pd.concat([first_entry, data, last_entry], ignore_index=True)\n",
    "        \n",
    "        fig: PlotlyFigure = px.line(x=temp1['sim_time'], y=temp1['level'], line_shape=\"vh\")\n",
    "        fig.update_traces(line=dict(width=3))\n",
    "        fig.update_layout(title=title)\n",
    "        fig.update_yaxes(title=dict({'text': yaxis}))\n",
    "        fig.update_xaxes(title=dict({'text': 'time'}))\n",
    "        # weighted average WIP level\n",
    "        fig.add_hline(\n",
    "                    y=avg_WIP_level, line_width=3, \n",
    "                    line_dash='dot', line_color='orange')\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        file_name = file_name + f'_{self}'\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "td1 = Timedelta(hours=1)\n",
    "td2 = Timedelta(hours=2)\n",
    "td3 = Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1 > td2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement an ABC to provide an interface for the simulation logic methods:**\n",
    "- *name: ResourceModule*\n",
    "- pre, main, post\n",
    "- finalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-Down Registration of Components or Subsystems\n",
    "- object-oriented way to add subsystems to supersystems\n",
    "- supersystems are a form of set (not necessarily implemented as set):\n",
    "    - each supersystem can contain each subsystem only once\n",
    "    - but each subsystem can be part of multiple supersystems\n",
    "- supersystems contain a special method to add subsystems\n",
    "    - parameter to check or create subsystem\n",
    "    - call to InfrastructureManager:\n",
    "        - check if subsystem already created\n",
    "        - if check fails create subsystem with given parameters\n",
    "        - return subsystem\n",
    "    - add subsystem\n",
    "\n",
    "- **important addition:**\n",
    "    - each subsystem database must contain a supersystem ID as secondary key\n",
    "    - initialise systems with invalid secondary keys (NaN, None, etc.)\n",
    "    - integrity check: secondary keys must not contain any invalid values\n",
    "\n",
    "- **procedure:**\n",
    "    - supersystem creation:\n",
    "        - register in Infrastructure Manager --> assignment of unique system ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(OrderedDict):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        subsystem_type: str,\n",
    "        custom_identifier: CustomID,\n",
    "        abstraction_level: int,\n",
    "        name: str | None = None,\n",
    "        state: str | None = None,\n",
    "    ) -> None:\n",
    "        # [BASIC INFO]\n",
    "        # environment\n",
    "        self.env = env\n",
    "        # subsystem information\n",
    "        self._subsystem_type: str = subsystem_type\n",
    "        # supersystem information\n",
    "        self._supersystems: OrderedDict[ObjectID, System] = dict()\n",
    "        self._supersystems_ids: set[ObjectID] = set()\n",
    "        self._supersystems_custom_ids: set[CustomID] = set()\n",
    "        # number of lower levels\n",
    "        # how many levels of subsystems are possible\n",
    "        self._abstraction_level = abstraction_level\n",
    "        # indicator if the system contains processing stations\n",
    "        self._containing_proc_stations: bool = False\n",
    "        \n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        self._system_id, self._name = infstruct_mgr.register_subsystem(\n",
    "                                        subsystem_type=self._subsystem_type,\n",
    "                                        obj=self, custom_identifier=custom_identifier,\n",
    "                                        name=name, state=state)\n",
    "        self._custom_identifier = custom_identifier\n",
    "        \n",
    "        # [AGENT] decision agent\n",
    "        self._agent_types: set[str] = set(['SEQ', 'ALLOC'])\n",
    "        self._alloc_agent_registered: bool = False\n",
    "        # assignment\n",
    "        self._alloc_agent: AllocationAgent | None = None\n",
    "        \n",
    "    ### REWORK\n",
    "    def register_agent(\n",
    "        self,\n",
    "        agent: Agent,\n",
    "        agent_type: str,\n",
    "    ) -> tuple[Self, SimulationEnvironment]:\n",
    "        \n",
    "        if agent_type not in self._agent_types:\n",
    "            raise ValueError(f\"The agent type >>{agent_type}<< is not allowed. Choose from {self._agent_types}\")\n",
    "        \n",
    "        match agent_type:\n",
    "            case 'ALLOC':\n",
    "                # allocation agents on lowest hierarchy level not allowed\n",
    "                if self._abstraction_level == 0:\n",
    "                    raise RuntimeError(f\"Can not register allocation agents for lowest hierarchy level objects.\")\n",
    "                # registration, type and existence check\n",
    "                if not self._alloc_agent_registered and isinstance(agent, AllocationAgent):\n",
    "                    self._alloc_agent = agent\n",
    "                    self._alloc_agent_registered = True\n",
    "                    logger_env.info(f\"Successfully registered Allocation Agent in {self}\")\n",
    "                elif not isinstance(agent, AllocationAgent):\n",
    "                    raise TypeError(f\"The object must be of type >>AllocationAgent<< but is type >>{type(alloc_agent)}<<\")\n",
    "                else:\n",
    "                    raise AttributeError(\"There is already a registered AllocationAgent instance \\\n",
    "                                        Only one instance per system is allowed.\")\n",
    "            case 'SEQ':\n",
    "                raise NotImplementedError(f\"Registration of sequencing agents not supported yet!\")\n",
    "            \n",
    "        return self, self.env\n",
    "    \n",
    "    @property\n",
    "    def alloc_agent(self) -> AllocationAgent:\n",
    "        if self._alloc_agent is None:\n",
    "            raise ValueError(\"No AllocationAgent instance registered.\")\n",
    "        else:\n",
    "            return self._alloc_agent\n",
    "    \n",
    "    def register_alloc_agent(\n",
    "        self,\n",
    "        alloc_agent: 'AllocationAgent',\n",
    "    ) -> None:\n",
    "        \n",
    "        if self._abstraction_level == 0:\n",
    "            raise RuntimeError(f\"Can not register allocation agents for lowest hierarchy level objects.\")\n",
    "        \n",
    "        if not self._alloc_agent_registered and isinstance(alloc_agent, AllocationAgent):\n",
    "            self._alloc_agent = alloc_agent\n",
    "            self._alloc_agent_registered = True\n",
    "            logger_env.info(f\"Successfully registered Allocation Agent in Env = {self.name()}\")\n",
    "        elif not isinstance(alloc_agent, AllocationAgent):\n",
    "            raise TypeError(f\"The object must be of type >>AllocationAgent<< but is type >>{type(alloc_agent)}<<\")\n",
    "        else:\n",
    "            raise AttributeError(\"There is already a registered AllocationAgent instance \\\n",
    "                                 Only one instance per system is allowed.\")\n",
    "    \n",
    "    def check_alloc_agent(self) -> None:\n",
    "        \"\"\"checks if an allocation agent is registered for the system\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NoAllocationAgentAssignedError\n",
    "            if no allocation agent was found\n",
    "        \"\"\"\n",
    "        if not self._alloc_agent_registered:\n",
    "            raise NoAllocationAgentAssignedError(f\"The system {self} has no allocation agent assigned.\")\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f'System (type: {self._subsystem_type}, custom_id: {self._custom_identifier}, name: {self._name})'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'System (type: {self._subsystem_type}, custom_id: {self._custom_identifier}, name: {self._name})'\n",
    "    \n",
    "    def __key(self) -> tuple[ObjectID, str]:\n",
    "        return (self._system_id, self._subsystem_type)\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.__key())\n",
    "    \n",
    "    @property\n",
    "    def subsystem_type(self) -> str:\n",
    "        return self._subsystem_type\n",
    "    \n",
    "    @property\n",
    "    def system_id(self) -> ObjectID:\n",
    "        return self._system_id\n",
    "    \n",
    "    @property\n",
    "    def custom_identifier(self) -> CustomID:\n",
    "        return self._custom_identifier\n",
    "    \n",
    "    # compatibility to salabim component --> declaration as property not allowed\n",
    "    def name(self) -> str | None:\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def abstraction_level(self) -> int:\n",
    "        return self._abstraction_level\n",
    "    \n",
    "    @property\n",
    "    def containing_proc_stations(self) -> bool:\n",
    "        return self._containing_proc_stations\n",
    "    \n",
    "    @containing_proc_stations.setter\n",
    "    def containing_proc_stations(\n",
    "        self,\n",
    "        val: bool,\n",
    "    ) -> None:\n",
    "        if not isinstance(val, bool):\n",
    "            raise TypeError(f\"Type of {val} must be boolean, but is {type(val)}\")\n",
    "        \n",
    "        self._containing_proc_stations = val\n",
    "    \n",
    "    @property\n",
    "    def supersystems(self) -> OrderedDict[ObjectID, System]:\n",
    "        return self._supersystems\n",
    "    \n",
    "    @property\n",
    "    def supersystems_ids(self) -> set[ObjectID]:\n",
    "        return self._supersystems_ids\n",
    "    \n",
    "    @property\n",
    "    def supersystems_custom_ids(self) -> set[CustomID]:\n",
    "        return self._supersystems_custom_ids\n",
    "    \n",
    "    def as_list(self) -> list[System]:\n",
    "        \"\"\"output the associated subsystems as list\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[System]\n",
    "            list of associated subsystems\n",
    "        \"\"\"\n",
    "        return list(self.values())\n",
    "    \n",
    "    def as_tuple(self) -> tuple[System, ...]:\n",
    "        \"\"\"output the associated subsystems as tuple\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[System, ...]\n",
    "            tuple of associated subsystems\n",
    "        \"\"\"\n",
    "        return tuple(self.values())\n",
    "    \n",
    "    def add_supersystem(\n",
    "        self,\n",
    "        supersystem: System,\n",
    "    ) -> None:\n",
    "        if supersystem.system_id not in self._supersystems:\n",
    "            self._supersystems[supersystem.system_id] = supersystem\n",
    "            self._supersystems_ids.add(supersystem.system_id)\n",
    "            self._supersystems_custom_ids.add(supersystem.custom_identifier)\n",
    "    \n",
    "    def add_subsystem(\n",
    "        self,\n",
    "        subsystem: System,\n",
    "    ) -> None:\n",
    "        \"\"\"adding a subsystem to the given supersystem\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subsystem : System\n",
    "            subsystem object which shall be added to the supersystem\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        UserWarning\n",
    "            if a subsystem is already associated with the given supersystem\n",
    "        \"\"\"\n",
    "        # do not allow adding of subsystems for lowest level systems\n",
    "        if self._abstraction_level == 0:\n",
    "            raise RuntimeError(f\"Tried to add subsystem to {self}, but it is \\\n",
    "                on the lowest hierarchy level. Systems on the lowest level can not contain other systems.\")\n",
    "        \n",
    "        if subsystem.system_id not in self:\n",
    "            self[subsystem.system_id] = subsystem\n",
    "        else:\n",
    "            raise UserWarning(f\"Subsystem {subsystem} was already \\\n",
    "                in supersystem {self}!\")\n",
    "        \n",
    "        subsystem.add_supersystem(supersystem=self)\n",
    "        \n",
    "        # register association in corresponding database\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.register_system_association(supersystem=self, subsystem=subsystem)\n",
    "        \n",
    "        # check if a processing station was added\n",
    "        if isinstance(subsystem, ProcessingStation):\n",
    "            # set flag\n",
    "            self._containing_proc_stations = True\n",
    "            # update property in database\n",
    "            infstruct_mgr.set_contain_proc_station(system=self)\n",
    "        \n",
    "        logger_infstrct.info(f\"Successfully added {subsystem} to {self}.\")\n",
    "    \n",
    "    #@lru_cache(maxsize=3)\n",
    "    def lowest_level_subsystems(\n",
    "        self,\n",
    "        only_processing_stations: bool = False,\n",
    "    ) -> tuple[InfrastructureObject, ...]:\n",
    "        \"\"\"obtain all associated InfrastructureObjects on the lowest hierarchy level\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        only_processing_stations : bool, optional\n",
    "            return all associated InfrastructureObjects (False)\n",
    "            or only ProcessingStations (True), by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[InfrastructureObject, ...]\n",
    "            tuple with all associated InfrastructureObjects\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            if system itself is on the lowest hierarchy level\n",
    "        \"\"\"\n",
    "        \n",
    "        if self._abstraction_level == 0:\n",
    "            raise RuntimeError(f\"Can not obtain lowest level subsystems from lowest hierarchy level objects.\")\n",
    "        \n",
    "        remaining_abstraction_level = self._abstraction_level - 1\n",
    "        subsystems = self.as_list()\n",
    "        \n",
    "        while remaining_abstraction_level > 0:\n",
    "            temp: list[System] = list()\n",
    "            \n",
    "            for subsystem in subsystems:\n",
    "                children = subsystem.as_list()\n",
    "                temp.append(children)\n",
    "                \n",
    "            subsystems = temp.copy()\n",
    "            remaining_abstraction_level -= 1\n",
    "        \n",
    "        # flatten list and remove duplicates by making a set\n",
    "        low_lev_subsystems_set: set[InfrastructureObject] = set(flatten(subsystems))\n",
    "        # filter only processing stations if option chosen\n",
    "        if only_processing_stations:\n",
    "            low_lev_subsystems_lst = filter_processing_stations(\n",
    "                                        infstruct_obj_collection=low_lev_subsystems_set)\n",
    "        else:\n",
    "            # obtain list and \n",
    "            low_lev_subsystems_lst: list[InfrastructureObject] = list(low_lev_subsystems_set)\n",
    "        \n",
    "        # sort list by system ID (ascending), so that the order is always the same\n",
    "        low_lev_subsystems_lst = sorted(low_lev_subsystems_lst, \n",
    "                                        key=attrgetter('system_id'), reverse=False)\n",
    "        \n",
    "        return tuple(low_lev_subsystems_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionArea(System):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Group of processing stations which are considered parallel machines\n",
    "        \"\"\"\n",
    "        \n",
    "        # initiliase base class\n",
    "        super().__init__(subsystem_type='ProductionArea', abstraction_level=2, **kwargs)\n",
    "    \n",
    "    def add_subsystem(\n",
    "        self,\n",
    "        subsystem: System,\n",
    "    ) -> None:\n",
    "        \"\"\"adding a subsystem to the given supersystem\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subsystem : System\n",
    "            subsystem object which shall be added to the supersystem\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            if a subsystem is not the type this system contains\n",
    "        \"\"\"\n",
    "        # type check: only certain subsystems are allowed for each supersystem\n",
    "        if not isinstance(subsystem, StationGroup):\n",
    "            raise TypeError(f\"The provided subsystem muste be of type >>StationGroup<<, \\\n",
    "                but it is {type(subsystem)}.\")\n",
    "            \n",
    "        super().add_subsystem(subsystem=subsystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StationGroup(System):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Group of processing stations which are considered parallel machines\n",
    "        \"\"\"\n",
    "        \n",
    "        # initiliase base class\n",
    "        super().__init__(subsystem_type='StationGroup', abstraction_level=1, **kwargs)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def add_subsystem(\n",
    "        self,\n",
    "        subsystem: System,\n",
    "    ) -> None:\n",
    "        \"\"\"adding a subsystem to the given supersystem\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subsystem : System\n",
    "            subsystem object which shall be added to the supersystem\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            if a subsystem is not the type this system contains\n",
    "        \"\"\"\n",
    "        # type check: only certain subsystems are allowed for each supersystem\n",
    "        if not isinstance(subsystem, InfrastructureObject):\n",
    "            raise TypeError(f\"The provided subsystem muste be of type >>InfrastructureObject<<, \\\n",
    "                but it is {type(subsystem)}.\")\n",
    "            \n",
    "        super().add_subsystem(subsystem=subsystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Infrastructure Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfrastructureObject(System, sim.Component):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        custom_identifier: CustomID,\n",
    "        name: str | None = None,\n",
    "        setup_time: Timedelta | None = None,\n",
    "        capacity: float = INF,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'WAITING', \n",
    "            'PROCESSING',\n",
    "            'SETUP', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env: simulation environment in which the infrastructure object is embedded\n",
    "        custom_identifier: unique user-defined custom ID of the given object \\\n",
    "            necessary for user interfaces\n",
    "        capacity: capacity of the infrastructure object, if multiple processing \\\n",
    "            slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        # [STATS] Monitoring\n",
    "        # special monitors for some classes\n",
    "        if isinstance(self, Buffer):\n",
    "            self._stat_monitor = BufferMonitor(\n",
    "                                env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        elif isinstance(self, InfrastructureObject) and not isinstance(self, Buffer):\n",
    "            self._stat_monitor = InfStructMonitor(\n",
    "                                env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        else:\n",
    "            self._stat_monitor = Monitor(env=env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # assert machine information and register object in the environment\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        \n",
    "        # [HIERARCHICAL SYSTEM INFORMATION]\n",
    "        # contrary to other system types no bucket because a processing station \n",
    "        # is the smallest unit in the system view/analysis\n",
    "        # initiliase base class >>System<<\n",
    "        # calls to Infrastructure Manager to register object\n",
    "        System.__init__(\n",
    "            self,\n",
    "            env=env,\n",
    "            subsystem_type='Resource',\n",
    "            custom_identifier=custom_identifier,\n",
    "            abstraction_level=0,\n",
    "            name=name,\n",
    "            state=current_state,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        self.cap = capacity\n",
    "        \n",
    "        # [SALABIM COMPONENT] intialise base class\n",
    "        process: str = 'main_logic'\n",
    "        sim.Component.__init__(self, env=env, name=self._name, \n",
    "                               process=process, suppress_trace=True, **kwargs)\n",
    "        \n",
    "        # add logic queues\n",
    "        # each resource uses one associated logic queue, logic queues are not physically available\n",
    "        queue_name: str = f\"queue_{self.name()}\"\n",
    "        self.logic_queue: Queue = sim.Queue(name=queue_name, env=self.env)\n",
    "        \n",
    "        # currently available jobs on that resource\n",
    "        self.contents: OrderedDict[ObjectID, Job] = OrderedDict()\n",
    "        \n",
    "        # [STATS] additional information\n",
    "        # number of inputs/outputs\n",
    "        self.num_inputs: int = 0\n",
    "        self.num_outputs: int = 0\n",
    "        \n",
    "        # time characteristics\n",
    "        #self._proc_time: float = 0.\n",
    "        self._proc_time: Timedelta = Timedelta.min\n",
    "        # setup time: if a setup time is provided use always this time and ignore job-related setup times\n",
    "        #self._setup_time = setup_time\n",
    "        self._setup_time = setup_time\n",
    "        if self._setup_time is not None:\n",
    "            self._use_const_setup_time: bool = True\n",
    "        else:\n",
    "            self._use_const_setup_time: bool = False\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    def td_to_simtime(\n",
    "        self,\n",
    "        timedelta: Timedelta,\n",
    "    ) -> float:\n",
    "        return self.env.timedelta_to_duration(timedelta=timedelta)\n",
    "    \n",
    "    @property\n",
    "    def use_const_setup_time(self) -> bool:\n",
    "        return self._use_const_setup_time\n",
    "    \n",
    "    @property\n",
    "    def proc_time(self) -> Timedelta:\n",
    "        return self._proc_time\n",
    "    \n",
    "    @proc_time.setter\n",
    "    def proc_time(\n",
    "        self,\n",
    "        new_proc_time: Timedelta,\n",
    "    ) -> None:\n",
    "        if isinstance(new_proc_time, Timedelta):\n",
    "            self._proc_time = new_proc_time\n",
    "        else:\n",
    "            raise TypeError(f\"The processing time must be of type >>Timedelta<<, \\\n",
    "                but it is >>{type(new_proc_time)}<<\")\n",
    "    \n",
    "    @property\n",
    "    def setup_time(self) -> float:\n",
    "        return self._setup_time\n",
    "    \n",
    "    @setup_time.setter\n",
    "    def setup_time(\n",
    "        self, \n",
    "        new_setup_time: float,\n",
    "    ) -> None:\n",
    "        if self._use_const_setup_time:\n",
    "            raise RuntimeError(f\"Tried to change setup time of >>{self}<<, but it is \\\n",
    "                configured to use a constant time of >>{self._setup_time}<<\")\n",
    "        \n",
    "        if isinstance(new_setup_time, Timedelta):\n",
    "            self._setup_time = new_setup_time\n",
    "        else:\n",
    "            raise TypeError(f\"The setup time must be of type >>Timedelta<<, \\\n",
    "                but it is >>{type(new_proc_time)}<<\")\n",
    "    \n",
    "    def add_content(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"add contents to the InfrastructureObject\"\"\"\n",
    "        job_id = job.job_id\n",
    "        if job_id not in self.contents:\n",
    "            self.contents[job_id] = job\n",
    "        else:\n",
    "            raise KeyError(f\"Job {job} already in contents of {self}\")\n",
    "    \n",
    "    def remove_content(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"remove contents from the InfrastructureObject\"\"\"\n",
    "        job_id = job.job_id\n",
    "        if job_id in self.contents:\n",
    "            del self.contents[job_id]\n",
    "        else:\n",
    "            raise KeyError(f\"Job {job} not in contents of {self}\")\n",
    "    \n",
    "    def put_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> Generator[InfrastructureObject, None, InfrastructureObject]:\n",
    "        \"\"\"\n",
    "        placing\n",
    "        \"\"\"\n",
    "        # ALLOCATION REQUEST\n",
    "        ## call dispatcher --> request for allocation\n",
    "        ## self._dispatcher.request_allocation ...\n",
    "        ### input job\n",
    "        #### LATER: LOGIC FOR RESOURCE ALLOCATION (AGENT)\n",
    "        ### - Dispatcher calls \"get_next_operation\"\n",
    "        ### - Dispatcher returns target_machine\n",
    "        ## ret: obtaining target machine\n",
    "        # ++++++++++ add later ++++++++++++\n",
    "        ## time component: given start date of operation\n",
    "        ## returning release date, waiting for release date or release early\n",
    "        dispatcher = self.env.dispatcher\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # call dispatcher to check for allocation rule\n",
    "        # if agent is set, do set flags and calculate feature vector\n",
    "        print(f'--------------- DEBUG: call before hold(0) at {self.env.t()}')\n",
    "        yield self.hold(0)\n",
    "        print(f'--------------- DEBUG: call after hold(0) at {self.env.t()}')\n",
    "        target_station = dispatcher.request_job_allocation(job=job)\n",
    "        #target_station = yield from dispatcher.request_job_allocation(job=job)\n",
    "        \n",
    "        ### UPDATE JOB PROCESS INFO IN REQUEST FUNCTION???\n",
    "        \n",
    "        # get logic queue\n",
    "        logic_queue = target_station.logic_queue\n",
    "        # check if the target is a sink\n",
    "        if isinstance(target_station, Sink):\n",
    "            pass\n",
    "        else:\n",
    "            # check if associated buffers exist\n",
    "            logger_prodStations.debug(f\"[{self}] Check for buffers\")\n",
    "            buffers = target_station.buffers\n",
    "            \n",
    "            if buffers:\n",
    "                #logger_prodStations.debug(f\"[{self}] Buffer found\")\n",
    "                # [STATE:InfrStructObj] BLOCKED\n",
    "                infstruct_mgr.update_res_state(obj=self, state='BLOCKED')\n",
    "                # [STATE:Job] BLOCKED\n",
    "                dispatcher.update_job_state(job=job, state='BLOCKED')\n",
    "                yield self.to_store(store=buffers, item=job, fail_delay=FAIL_DELAY, fail_priority=1)\n",
    "                if self.failed():\n",
    "                    raise UserWarning(f\"Store placement failed after {FAIL_DELAY} time steps. \\\n",
    "                        There seems to be deadlock.\")\n",
    "                # [STATE:Buffer] trigger state setting for target buffer\n",
    "                buffer = self.to_store_store()\n",
    "                if not isinstance(buffer, Buffer):\n",
    "                    #logger_prodStations.debug(f\"To store store object: {buffer}\")\n",
    "                    raise TypeError(f\"From {self}: Job {job} Obj {buffer} is no buffer type at {self.env.now()}\")\n",
    "                buffer.activate()\n",
    "                # [CONTENT:Buffer] add content\n",
    "                buffer.add_content(job=job)\n",
    "                # [STATS:Buffer] count number of inputs\n",
    "                buffer.num_inputs += 1\n",
    "                logger_prodStations.debug(f\"obj = {self} \\t type of buffer >>{buffer}<< = {type(buffer)} at {self.env.now()}\")\n",
    "            else:\n",
    "                # adding request to machine\n",
    "                # currently not possible because machines are components,\n",
    "                # but resources which could be requested are not\n",
    "                pass\n",
    "        \n",
    "        # [Job] enter logic queue after physical placement\n",
    "        job.enter(logic_queue)\n",
    "        # [STATS:WIP] REMOVING WIP FROM CURRENT STATION\n",
    "        # remove only if it was added before, only case if the last operation exists\n",
    "        if job.last_op is not None:\n",
    "            self.stat_monitor.change_WIP(job=job, remove=True)\n",
    "        # [STATS:WIP] ADDING WIP TO TARGET STATION\n",
    "        # add only if there is a next operation, only case if the current operation exists\n",
    "        if job.current_op is not None:\n",
    "            target_station.stat_monitor.change_WIP(job=job, remove=False)\n",
    "        \n",
    "        # activate target processing station if passive\n",
    "        if target_station.ispassive():\n",
    "            target_station.activate()\n",
    "        \n",
    "        logger_prodStations.debug(f\"[{self}] Put Job {job} in queue {logic_queue}\")\n",
    "    \n",
    "        # [STATE:InfrStructObj] WAITING\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "        # [STATE:Job] successfully placed --> WAITING\n",
    "        dispatcher.update_job_state(job=job, state='WAITING')\n",
    "        # [STATS:InfrStructObj] count number of outputs\n",
    "        self.num_outputs += 1\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def get_job(self) -> Generator[None | InfrastructureObject, None, Job]:\n",
    "        \"\"\"\n",
    "        getting jobs from associated predecessor resources\n",
    "        \"\"\"\n",
    "        # entering target machine (logic_buffer)\n",
    "        ## logic_buffer: job queue regardless of physical buffers\n",
    "        ### entity physically on machine, but no true holding resource object (violates load-resource model)\n",
    "        ### no capacity restrictions between resources, e.g. source can endlessly produce entities\n",
    "        ## --- logic ---\n",
    "        ## job enters logic queue of machine with unrestricted capacity\n",
    "        ## each machine can have an associated physical buffer\n",
    "        dispatcher = self.env.dispatcher\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # request job and its time characteristics from associated queue\n",
    "        job, job_proc_time, job_setup_time = dispatcher.request_job_sequencing(req_obj=self)\n",
    "        \n",
    "        ### UPDATE JOB PROCESS INFO IN REQUEST FUNCTION???\n",
    "        \n",
    "        # update time characteristics of the infrastructure object\n",
    "        # contains additonal checks if the target values are allowed\n",
    "        self.proc_time = job_proc_time\n",
    "        if job_setup_time is not None:\n",
    "            logger_prodStations.debug(f\"-------->>>>> [SETUP TIME DETECTED] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier} \\\n",
    "                with setup time {self.setup_time}\")\n",
    "            self.setup_time = job_setup_time\n",
    "        \n",
    "        # request and get job from associated buffer if it exists\n",
    "        if self._buffers:\n",
    "            yield self.from_store(store=self._buffers, filter=lambda item: item.job_id == job.job_id)\n",
    "            buffer = self.from_store_store()\n",
    "            # [STATS:Buffer] count number of outputs\n",
    "            buffer.num_outputs += 1\n",
    "            # [CONTENT:Buffer] remove content\n",
    "            buffer.remove_content(job=job)\n",
    "            # [STATE:Buffer] trigger state setting for target buffer\n",
    "            buffer.activate()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # RELEVANT INFORMATION BEFORE PROCESSING\n",
    "        dispatcher.update_job_process_info(job=job, preprocess=True)\n",
    "        # [STATS] count number of inputs\n",
    "        self.num_inputs += 1\n",
    "        # [CONTENT] add content\n",
    "        self.add_content(job=job)\n",
    "        \n",
    "        # SETUP\n",
    "        if self.setup_time is not None:\n",
    "            # special state setting only for setup times\n",
    "            # [STATE:InfrStructObj]\n",
    "            infstruct_mgr.update_res_state(obj=self, state='SETUP')\n",
    "            # [STATE:Job]\n",
    "            dispatcher.update_job_state(job=job, state='SETUP')\n",
    "            logger_prodStations.debug(f\"[START SETUP] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier} \\\n",
    "                with setup time {self.setup_time}\")\n",
    "            sim_time = self.td_to_simtime(timedelta=self.setup_time)\n",
    "            #yield self.hold(self.setup_time)\n",
    "            yield self.hold(sim_time)\n",
    "        \n",
    "        # [STATE:InfrStructObj] set state to processing\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "        # [STATE:Job] successfully taken --> PROCESSING\n",
    "        dispatcher.update_job_state(job=job, state='PROCESSING')\n",
    "        \n",
    "        return job\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    # each method of 'pre_process', 'sim_control', 'post_process' must be implemented in the child classes\n",
    "    def pre_process(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No pre-process method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def sim_control(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No sim-control method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def post_process(self) -> None:\n",
    "        \"\"\"return type: tuple with parameters or None\"\"\"\n",
    "        raise NotImplementedError(f\"No post-process method for {self} of type {self.__class__.__name__} defined.\")\n",
    "    \n",
    "    def main_logic(self) -> Generator[Any, None, None]:\n",
    "        \"\"\"main logic loop for all resources in the simulation environment\"\"\"\n",
    "        logger.debug(f\"----> Process logic of {self}\")\n",
    "        # pre control logic\n",
    "        ret = self.pre_process()\n",
    "        # main control logic\n",
    "        if ret is not None:\n",
    "            ret = yield from self.sim_control(*ret)\n",
    "        else:\n",
    "            ret = yield from self.sim_control()\n",
    "        # post control logic\n",
    "        if ret is not None:\n",
    "            ret = self.post_process(*ret)\n",
    "        else:\n",
    "            ret = self.post_process()\n",
    "            \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # set finish state for each infrastructure object no matter of which child class\n",
    "        infstruct_mgr.update_res_state(obj=self, state='FINISH')\n",
    "        # finalise stat gathering\n",
    "        self._stat_monitor.finalise_stats()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processingstation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingStation(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        buffers: Iterable[Buffer] | None = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        env: simulation environment in which the infrastructure object is embedded\n",
    "        capacity: capacity of the infrastructure object, if multiple processing \\\n",
    "            slots available at the same time > 1, default=1\n",
    "        \"\"\"\n",
    "        # intialize base class\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # add physical buffers, more than one allowed\n",
    "        # contrary to logic queues buffers are infrastructure objects and exist physically\n",
    "        if buffers is None:\n",
    "            self._buffers: set[Buffer] = set()\n",
    "        else:\n",
    "            self._buffers: set[Buffer] = set(buffers).copy()\n",
    "        \n",
    "        # add processing station to the associated ones of each buffer\n",
    "        # necessary because if the number of resources for one buffer exceeds its capacity\n",
    "        # deadlocks are possible\n",
    "        for buffer in self._buffers:\n",
    "            buffer.add_prod_station(prod_station=self)\n",
    "    \n",
    "    @property\n",
    "    def station_group_id(self) -> ObjectID:\n",
    "        return self._station_group_id\n",
    "    \n",
    "    @property\n",
    "    def station_group(self) -> StationGroup:\n",
    "        return self._station_group\n",
    "    \n",
    "    @property\n",
    "    def buffers(self) -> set[Buffer]:\n",
    "        return self._buffers\n",
    "    \n",
    "    def add_buffer(\n",
    "        self,\n",
    "        buffer: Buffer,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        adding buffer to the current associated ones\n",
    "        \"\"\"\n",
    "        # only buffer types allowed\n",
    "        if not isinstance(buffer, Buffer):\n",
    "            raise TypeError(f\"Object is no Buffer type. Only objects of type Buffer can be added as buffers.\")\n",
    "        # check if already present\n",
    "        if buffer not in self._buffers:\n",
    "            self._buffers.add(buffer)\n",
    "            buffer.add_prod_station(prod_station=self)\n",
    "        else:\n",
    "            logger_prodStations.warning(f\"The Buffer >>{buffer}<< is already associated with the resource >>{self}<<. \\\n",
    "                Buffer was not added to the resource.\")\n",
    "\n",
    "    def remove_buffer(\n",
    "        self,\n",
    "        buffer: Buffer,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        removing buffer from the current associated ones\n",
    "        \"\"\"\n",
    "        if buffer in self._buffers:\n",
    "            self._buffers.remove(buffer)\n",
    "            buffer.remove_prod_station(prod_station=self)\n",
    "        else:\n",
    "            raise KeyError(f\"The buffer >>{buffer}<< is not associated with the resource >>{self}<< and \\\n",
    "                therefore could not be removed.\")\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "    \n",
    "    def sim_control(self) -> Generator[None | Job, None, None]:\n",
    "        dispatcher = self.env.dispatcher\n",
    "        while True:\n",
    "            # initialise state by passivating machines\n",
    "            # resources are activated by other resources\n",
    "            if len(self.logic_queue) == 0:\n",
    "                yield self.passivate()\n",
    "            logger_prodStations.debug(f\"[MACHINE: {self}] is getting job from queue\")\n",
    "            \n",
    "            # get job function from PARENT CLASS\n",
    "            # ONLY PROCESSING STATIONS ARE ASKING FOR SEQUENCING\n",
    "            # state setting --> 'PROCESSING'\n",
    "            job = yield from self.get_job()\n",
    "            \n",
    "            logger_prodStations.debug(f\"[START] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier} \\\n",
    "                with proc time {self.proc_time}\")\n",
    "            # PROCESSING\n",
    "            sim_time = self.td_to_simtime(timedelta=self.proc_time)\n",
    "            yield self.hold(sim_time)\n",
    "            # RELEVANT INFORMATION AFTER PROCESSING\n",
    "            dispatcher.update_job_process_info(job=job, preprocess=False)\n",
    "            \n",
    "            logger_prodStations.debug(f\"[END] job ID {job.job_id} at {self.env.now()} on machine ID {self.custom_identifier}\")\n",
    "            # only place job if there are open operations left\n",
    "            # maybe add to 'put_job' method\n",
    "            target_proc_station = yield from self.put_job(job=job)\n",
    "            # [CONTENT:ProdStation] remove content\n",
    "            self.remove_content(job=job)\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        # each resource object class has dedicated finalise methods which \n",
    "        # must be called by children\n",
    "        super().finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(ProcessingStation):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ADD LATER\n",
    "        \"\"\"\n",
    "        # assert object information\n",
    "        self.res_type = 'Machine'\n",
    "        \n",
    "        # intialize base class\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='buffer'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer(sim.Store, InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity: float,\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'TEMP',\n",
    "            'FULL',\n",
    "            'EMPTY',\n",
    "            'INTERMEDIATE',\n",
    "            'FAILED',\n",
    "            'PAUSED',\n",
    "        ),\n",
    "        fill_level: int = 0,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        capacity: capacity of the buffer, can be infinite\n",
    "        \"\"\"\n",
    "        # assert object information\n",
    "        self.res_type = 'Buffer'\n",
    "        self.start_fill_level = fill_level\n",
    "        \n",
    "        # intialize base classes\n",
    "        # using hard-coded classes because salabim does not provide \n",
    "        # interfaces for multiple inheritance\n",
    "        sim.Store.__init__(self, capacity=capacity, env=env)\n",
    "        InfrastructureObject.__init__(\n",
    "                            self, capacity=capacity, \n",
    "                            possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # material flow relationships\n",
    "        self._associated_prod_stations: set[ProcessingStation] = set()\n",
    "        self._count_associated_prod_stations: int = 0\n",
    "    \n",
    "    @property\n",
    "    def level_db(self) -> DataFrame:\n",
    "        return self._stat_monitor.level_db\n",
    "    \n",
    "    @property\n",
    "    def wei_avg_fill_level(self) -> float:\n",
    "        return self._stat_monitor.wei_avg_fill_level\n",
    "    \n",
    "    \n",
    "    ### MATERIAL FLOW RELATIONSHIP\n",
    "    def add_prod_station(\n",
    "        self,\n",
    "        prod_station: ProcessingStation\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        function to add processing stations which are associated with \n",
    "        \"\"\"\n",
    "        if not isinstance(prod_station, ProcessingStation):\n",
    "            raise TypeError(f\"Object is no ProcessingStation type. Only objects of type ProcessingStation can be added to a buffer.\")\n",
    "        \n",
    "        # check if adding a new resource exceeds the given capacity\n",
    "        # each associated processing station needs one storage place in the buffer\n",
    "        # else deadlocks are possible\n",
    "        if (self._count_associated_prod_stations + 1) > self.cap:\n",
    "            raise UserWarning(f\"Tried to add a new resource to buffer {self}, but the number of associated \\\n",
    "                resources exceeds its capacity which could result in deadlocks.\")\n",
    "        \n",
    "        # check if processing station can be added\n",
    "        if prod_station not in self._associated_prod_stations:\n",
    "            self._associated_prod_stations.add(prod_station)\n",
    "            self._count_associated_prod_stations += 1\n",
    "        else:\n",
    "            logger_buffers.warning(f\"The Processing Station >>{prod_station}<< is already associated with the resource >>{self}<<. \\\n",
    "                Processing Station was not added to the resource.\")\n",
    "        \n",
    "    def remove_prod_station(\n",
    "        self,\n",
    "        prod_station: ProcessingStation\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        removing a processing station from the current associated ones\n",
    "        \"\"\"\n",
    "        if prod_station in self._associated_prod_stations:\n",
    "            self._associated_prod_stations.remove(prod_station)\n",
    "            self._count_associated_prod_stations -= 1\n",
    "        else:\n",
    "            raise KeyError(f\"The processing station >>{prod_station}<< is not associated with the resource >>{self}<< and \\\n",
    "                therefore could not be removed.\")\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='EMPTY')\n",
    "    \n",
    "    def sim_control(self) -> Generator[None, None, None]:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        while True:\n",
    "            logger_prodStations.debug(f\"[BUFFER: {self}] Invoking at {self.env.now()}\")\n",
    "            # full\n",
    "            if self.available_quantity() == 0:\n",
    "                # [STATE] FULL\n",
    "                infstruct_mgr.update_res_state(obj=self, state='FULL')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Set to 'FULL' at {self.env.now()}\")\n",
    "            # empty\n",
    "            elif self.available_quantity() == self.capacity():\n",
    "                # [STATE] EMPTY\n",
    "                infstruct_mgr.update_res_state(obj=self, state='EMPTY')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Set to 'EMPTY' at {self.env.now()}\")\n",
    "            else:\n",
    "                # [STATE] INTERMEDIATE\n",
    "                infstruct_mgr.update_res_state(obj=self, state='INTERMEDIATE')\n",
    "                logger_prodStations.debug(f\"[BUFFER: {self}] Neither 'EMPTY' nor 'FULL' at {self.env.now()}\")\n",
    "            \n",
    "            yield self.passivate()\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        # each resource object class has dedicated finalise methods which \n",
    "        # must be called by children\n",
    "        super().finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- entity generation:\n",
    "    - constant\n",
    "    - random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='source'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Source(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        proc_time: Timedelta = Timedelta(hours=2),\n",
    "        random_generation: bool = False,\n",
    "        job_generator: RandomJobGenerator | None = None,\n",
    "        num_gen_jobs: int = 5,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        num_gen_jobs: total number of jobs to be generated\n",
    "        \"\"\"\n",
    "        # assert object information and register object in the environment\n",
    "        self.res_type = 'Source'\n",
    "        \n",
    "        # random generation\n",
    "        if random_generation and job_generator is None:\n",
    "            raise ValueError(\"Random job generator instance needed for random job generation\")\n",
    "        \n",
    "        self.random_generation = random_generation\n",
    "        self.job_generator = job_generator\n",
    "        \n",
    "        ################## REWORK\n",
    "        # initialize component with necessary process function\n",
    "        random.seed(42)\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # parameters\n",
    "        self.proc_time = proc_time\n",
    "        self.num_gen_jobs = num_gen_jobs\n",
    "    \n",
    "    def _obtain_proc_time(self) -> float:\n",
    "        \"\"\"\n",
    "        function to generate a constant or random processing time\n",
    "        \"\"\"\n",
    "        proc_time = self.td_to_simtime(timedelta=self.proc_time)\n",
    "        if self.random_generation:\n",
    "            # random generation, add later\n",
    "            return proc_time\n",
    "        else:\n",
    "            return proc_time\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "    \n",
    "    def sim_control(self) -> Generator[None, None, None]:\n",
    "        # id counter for debugging, else endless generation\n",
    "        count = 0\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        dispatcher = self.env.dispatcher\n",
    "        \n",
    "        # use machine custom identifiers for generation\n",
    "        machines = infstruct_mgr.res_db.loc[infstruct_mgr.res_db['res_type']=='Machine']\n",
    "        machines_custom_ids = machines['custom_id'].to_list()\n",
    "        \n",
    "        # use station group custom identifiers for generation\n",
    "        station_groups_custom_ids = infstruct_mgr.station_group_db['custom_id'].to_list()\n",
    "        \n",
    "        # use production area custom identifiers for generation\n",
    "        prod_areas = infstruct_mgr.prod_area_db.copy()\n",
    "        # prod_area_custom_ids = prod_areas.loc[prod_areas['containing_proc_stations'] == True,'custom_id'].to_list()\n",
    "        prod_area_custom_ids = prod_areas.loc[prod_areas['containing_proc_stations'] == True,'custom_id']\n",
    "        #prod_area_system_ids = prod_areas.loc[prod_areas['containing_proc_stations'] == True,:].index.to_list()\n",
    "        # get station group custom identifiers which are associated with \n",
    "        # the relevant production areas\n",
    "        stat_groups = infstruct_mgr.station_group_db.copy()\n",
    "        stat_group_ids: dict[CustomID, list[CustomID]] = dict()\n",
    "        for PA_sys_id, PA_custom_id in prod_area_custom_ids.items():\n",
    "            # get associated station group custom IDs by their corresponding production area system ID\n",
    "            candidates = stat_groups.loc[(stat_groups['prod_area_id'] == PA_sys_id), 'custom_id'].to_list()\n",
    "            # map production area custom ID to the associated station group custom IDs\n",
    "            stat_group_ids[PA_custom_id] = candidates\n",
    "        \n",
    "        while count < self.num_gen_jobs:\n",
    "            # start at t=0 with generation\n",
    "            # generate object\n",
    "            ## random job properties\n",
    "            ## currently: each job passes each machine, only one machine of each operation type\n",
    "            #mat_ProcTimes, mat_JobMachID = self.job_generator.gen_rnd_job(n_machines=self.env.num_proc_stations)\n",
    "            #job = Job(dispatcher=dispatcher, proc_times=mat_ProcTimes.tolist(), \n",
    "            #          machine_order=mat_JobMachID.tolist())\n",
    "            #mat_ProcTimes, mat_JobMachID = self.job_generator.gen_rnd_job_by_ids(ids=machines_custom_ids)\n",
    "            #mat_ProcTimes, mat_JobExOrder = self.job_generator.gen_rnd_job_by_ids(ids=station_groups_custom_ids, min_proc_time=5)\n",
    "            (job_ex_order, job_target_station_groups, \n",
    "             proc_times, setup_times) = self.job_generator.gen_rnd_job_by_ids(\n",
    "                exec_system_ids=prod_area_custom_ids,\n",
    "                target_station_group_ids=stat_group_ids,\n",
    "                #target_station_group_ids=None,\n",
    "                min_proc_time=5,\n",
    "                gen_setup_times=True,\n",
    "            )\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] ProcTimes {proc_times} at {self.env.now()}\")\n",
    "            \n",
    "            # assign random priority\n",
    "            prio = self.job_generator.gen_prio() + count\n",
    "            #prio = [2,8]\n",
    "            # assign starting and ending dates\n",
    "            start_date_init = Datetime(2023, 11, 20, hour=6)\n",
    "            end_date_init = Datetime(2023, 12, 1, hour=10)\n",
    "            #start_date_init = [Datetime(2023, 11, 20, hour=6), Datetime(2023, 11, 21, hour=2)]\n",
    "            #end_date_init = [Datetime(2023, 12, 1, hour=10), Datetime(2023, 12, 2, hour=2)]\n",
    "            \n",
    "            logger_sources.debug(f\"{job_ex_order=}\")\n",
    "            logger_sources.debug(f\"{job_target_station_groups=}\")\n",
    "            job = Job(dispatcher=dispatcher,\n",
    "                      exec_systems_order=job_ex_order,\n",
    "                      target_stations_order=job_target_station_groups,\n",
    "                      proc_times=proc_times,\n",
    "                      setup_times=setup_times,\n",
    "                      prio=prio,\n",
    "                      planned_starting_date=start_date_init,\n",
    "                      planned_ending_date=end_date_init)\n",
    "            # [Call:DISPATCHER]\n",
    "            dispatcher.release_job(job=job)\n",
    "            # [STATS:Source] count number of inputs (source: generation of jobs or entry in pipeline)\n",
    "            # implemented in 'get_job' method which is not executed by source objects\n",
    "            self.num_inputs += 1\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Generated {job} at {self.env.now()}\")\n",
    "            \n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Request allocation...\")\n",
    "            # put job via 'put_job' function, implemented in parent class 'InfrastructureObject'\n",
    "            target_proc_station = yield from self.put_job(job=job)\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] PUT JOB with ret = {target_proc_station}\")\n",
    "            # [STATE:Source] put in 'WAITING' by 'put_job' method but still processing\n",
    "            # only 'WAITING' if all jobs are generated\n",
    "            infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "            \n",
    "            # hold for defined generation time (constant or statistically distributed)\n",
    "            # if hold time elapsed start new generation\n",
    "            proc_time = self._obtain_proc_time()\n",
    "            logger_sources.debug(f\"[SOURCE: {self}] Hold for >>{proc_time}<< at {self.env.now()}\")\n",
    "            yield self.hold(proc_time)\n",
    "            # set counter up\n",
    "            count += 1\n",
    "        \n",
    "        # [STATE:Source] WAITING\n",
    "        infstruct_mgr.update_res_state(obj=self, state='WAITING')\n",
    "        \n",
    "    def post_process(self) -> None:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sink(InfrastructureObject):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        num_gen_jobs: total number of jobs to be generated\n",
    "        \"\"\"\n",
    "        # assert object information and register object in the environment\n",
    "        self.res_type = 'Sink'\n",
    "        \n",
    "        # initialize parent class\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    ### PROCESS LOGIC\n",
    "    def pre_process(self) -> None:\n",
    "        # currently sinks are 'PROCESSING' the whole time\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        infstruct_mgr.update_res_state(obj=self, state='PROCESSING')\n",
    "    \n",
    "    def sim_control(self) -> Generator[None, None, None]:\n",
    "        dispatcher = self.env.dispatcher\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        while True:\n",
    "            # in analogy to ProcessingStations\n",
    "            if len(self.logic_queue) == 0:\n",
    "                yield self.passivate()\n",
    "            logger_sinks.debug(f\"[SINK: {self}] is getting job from queue\")\n",
    "            # get job, simple FIFO\n",
    "            job: Job = self.logic_queue.pop()\n",
    "            # [Call:DISPATCHER] data collection: finalise job\n",
    "            dispatcher.finish_job(job=job)\n",
    "            #job.finalise()\n",
    "            # destroy job object ???\n",
    "            # if job object destroyed, unsaved information is lost\n",
    "            # if not destroyed memory usage could increase\n",
    "            \n",
    "    def post_process(self) -> None:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker: Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 11, 21, 0, 0)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = Datetime(2023, 11, 21)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:env:Successfully registered Infrastructure Manager in Env >>base<<\n",
      "INFO:env:Successfully registered Dispatcher in Env >>base<<\n"
     ]
    }
   ],
   "source": [
    "#env = SimulationEnvironment(name='base', time_unit='seconds')\n",
    "env = SimulationEnvironment(name='base', time_unit='seconds', starting_datetime=dt)\n",
    "job_generator = RandomJobGenerator(seed=2)\n",
    "infstruct_mgr = InfrastructureManager(env=env)\n",
    "dispatcher = Dispatcher(env=env, priority_rule='FIFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:infstrct:Successfully registered object with SystemID 0 and name ProductionArea_env_0\n",
      "INFO:infstrct:Successfully registered object with SystemID 0 and name StationGroup_env_0\n",
      "INFO:infstrct:Successfully added System (type: StationGroup, custom_id: 1000, name: StationGroup_env_0) to System (type: ProductionArea, custom_id: 1000, name: ProductionArea_env_0).\n",
      "INFO:infstrct:Successfully registered object with SystemID 0 and name Source_env_0\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: source, name: Source_env_0) to System (type: StationGroup, custom_id: 1000, name: StationGroup_env_0).\n",
      "INFO:infstrct:Successfully registered object with SystemID 1 and name ProductionArea_env_1\n",
      "INFO:infstrct:Successfully registered object with SystemID 1 and name StationGroup_env_1\n",
      "INFO:infstrct:Successfully added System (type: StationGroup, custom_id: 2000, name: StationGroup_env_1) to System (type: ProductionArea, custom_id: 2000, name: ProductionArea_env_1).\n",
      "INFO:infstrct:Successfully registered object with SystemID 1 and name Sink_env_1\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: sink, name: Sink_env_1) to System (type: StationGroup, custom_id: 2000, name: StationGroup_env_1).\n",
      "INFO:infstrct:Successfully registered object with SystemID 2 and name ProductionArea_env_2\n",
      "INFO:infstrct:Successfully registered object with SystemID 2 and name StationGroup_env_2\n",
      "INFO:infstrct:Successfully added System (type: StationGroup, custom_id: 1, name: StationGroup_env_2) to System (type: ProductionArea, custom_id: 1, name: ProductionArea_env_2).\n",
      "INFO:infstrct:Successfully registered object with SystemID 3 and name StationGroup_env_3\n",
      "INFO:infstrct:Successfully added System (type: StationGroup, custom_id: 2, name: StationGroup_env_3) to System (type: ProductionArea, custom_id: 1, name: ProductionArea_env_2).\n",
      "INFO:infstrct:Successfully registered object with SystemID 2 and name Buffer_env_2\n",
      "INFO:infstrct:Successfully registered object with SystemID 3 and name Machine_env_3\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 10, name: Buffer_env_2) to System (type: StationGroup, custom_id: 1, name: StationGroup_env_2).\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 0, name: Machine_env_3) to System (type: StationGroup, custom_id: 1, name: StationGroup_env_2).\n",
      "INFO:infstrct:Successfully registered object with SystemID 4 and name Buffer_env_4\n",
      "INFO:infstrct:Successfully registered object with SystemID 5 and name Machine_env_5\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 11, name: Buffer_env_4) to System (type: StationGroup, custom_id: 1, name: StationGroup_env_2).\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 1, name: Machine_env_5) to System (type: StationGroup, custom_id: 1, name: StationGroup_env_2).\n",
      "INFO:infstrct:Successfully registered object with SystemID 6 and name Buffer_env_6\n",
      "INFO:infstrct:Successfully registered object with SystemID 7 and name Machine_env_7\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 12, name: Buffer_env_6) to System (type: StationGroup, custom_id: 2, name: StationGroup_env_3).\n",
      "INFO:infstrct:Successfully added System (type: Resource, custom_id: 2, name: Machine_env_7) to System (type: StationGroup, custom_id: 2, name: StationGroup_env_3).\n"
     ]
    }
   ],
   "source": [
    "# source\n",
    "area_source = ProductionArea(env=env, custom_identifier=1000)\n",
    "group_source = StationGroup(env=env, custom_identifier=1000)\n",
    "area_source.add_subsystem(group_source)\n",
    "source = Source(env=env, custom_identifier='source', proc_time=Timedelta(hours=2), \n",
    "                random_generation=True, job_generator=job_generator, num_gen_jobs=5)\n",
    "group_source.add_subsystem(source)\n",
    "\n",
    "# sink\n",
    "area_sink = ProductionArea(env=env, custom_identifier=2000)\n",
    "group_sink = StationGroup(env=env, custom_identifier=2000)\n",
    "area_sink.add_subsystem(group_sink)\n",
    "sink = Sink(env=env, custom_identifier='sink')\n",
    "group_sink.add_subsystem(sink)\n",
    "\n",
    "# processing stations\n",
    "# prod area 1\n",
    "area_prod = ProductionArea(env=env, custom_identifier=1)\n",
    "group_prod = StationGroup(env=env, custom_identifier=1)\n",
    "area_prod.add_subsystem(group_prod)\n",
    "group_prod2 = StationGroup(env=env, custom_identifier=2)\n",
    "area_prod.add_subsystem(group_prod2)\n",
    "# prod area 2\n",
    "#area_prod2 = ProductionArea(env=env, custom_identifier=2)\n",
    "#group_prod3 = StationGroup(env=env, custom_identifier=3)\n",
    "#area_prod2.add_subsystem(group_prod3)\n",
    "#area_prod.add_subsystem(group_prod3)\n",
    "## machines\n",
    "for machine in range(3):\n",
    "    buffer = Buffer(capacity=20, env=env, custom_identifier=(10+machine))\n",
    "    if machine == 5:\n",
    "        MachInst = Machine(env=env, custom_identifier=machine, buffers=[buffer], setup_time=5.)\n",
    "    else:\n",
    "        MachInst = Machine(env=env, custom_identifier=machine, buffers=[buffer])\n",
    "        \n",
    "    if machine == 0:\n",
    "        testMachInst = MachInst\n",
    "    \n",
    "    if machine < 2:\n",
    "        group_prod.add_subsystem(buffer)\n",
    "        group_prod.add_subsystem(MachInst)\n",
    "    elif machine >= 2:\n",
    "        group_prod2.add_subsystem(buffer)\n",
    "        group_prod2.add_subsystem(MachInst)\n",
    "    else:\n",
    "        pass\n",
    "        #group_prod3.add_subsystem(buffer)\n",
    "        #group_prod3.add_subsystem(MachInst)\n",
    "    \n",
    "\n",
    "add_machine_to_bottleneck: bool = False\n",
    "if add_machine_to_bottleneck:\n",
    "    buffer = Buffer(capacity=20, env=env, custom_identifier=(10+machine+1))\n",
    "    MachInst = Machine(env=env, custom_identifier=machine+1, buffers=[buffer])\n",
    "    group_prod3.add_subsystem(buffer)\n",
    "    group_prod3.add_subsystem(MachInst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_prod.containing_proc_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:env:Successfully registered Allocation Agent in System (type: ProductionArea, custom_id: 1, name: ProductionArea_env_2)\n"
     ]
    }
   ],
   "source": [
    "alloc_agent = AllocationAgent(assoc_system=area_prod)\n",
    "#alloc_agent2 = AllocationAgent(assoc_system=area_prod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(System (type: Resource, custom_id: 0, name: Machine_env_3),\n",
       " System (type: Resource, custom_id: 1, name: Machine_env_5),\n",
       " System (type: Resource, custom_id: 2, name: Machine_env_7))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alloc_agent._assoc_infstrct_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alloc_agent.build_feat_vec(job=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_prod.supersystems_custom_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# station group IDs (system, custom) for processing stations\n",
    "MachInst.supersystems_custom_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>prod_area</th>\n",
       "      <th>containing_proc_stations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prod_area_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>ProductionArea_env_0</td>\n",
       "      <td>{0: {0: {}}}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ProductionArea_env_1</td>\n",
       "      <td>{1: {1: {}}}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ProductionArea_env_2</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             custom_id                  name   \n",
       "prod_area_id                                   \n",
       "0                 1000  ProductionArea_env_0  \\\n",
       "1                 2000  ProductionArea_env_1   \n",
       "2                    1  ProductionArea_env_2   \n",
       "\n",
       "                                                      prod_area   \n",
       "prod_area_id                                                      \n",
       "0                                                  {0: {0: {}}}  \\\n",
       "1                                                  {1: {1: {}}}   \n",
       "2             {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "\n",
       "              containing_proc_stations  \n",
       "prod_area_id                            \n",
       "0                                False  \n",
       "1                                False  \n",
       "2                                 True  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.prod_area_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station_group</th>\n",
       "      <th>prod_area_id</th>\n",
       "      <th>containing_proc_stations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>StationGroup_env_0</td>\n",
       "      <td>{0: {}}</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>StationGroup_env_1</td>\n",
       "      <td>{1: {}}</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>StationGroup_env_2</td>\n",
       "      <td>{2: {}, 3: {}, 4: {}, 5: {}}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>StationGroup_env_3</td>\n",
       "      <td>{6: {}, 7: {}}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 custom_id                name                 station_group   \n",
       "station_group_id                                                               \n",
       "0                     1000  StationGroup_env_0                       {0: {}}  \\\n",
       "1                     2000  StationGroup_env_1                       {1: {}}   \n",
       "2                        1  StationGroup_env_2  {2: {}, 3: {}, 4: {}, 5: {}}   \n",
       "3                        2  StationGroup_env_3                {6: {}, 7: {}}   \n",
       "\n",
       "                  prod_area_id  containing_proc_stations  \n",
       "station_group_id                                          \n",
       "0                            0                     False  \n",
       "1                            1                     False  \n",
       "2                            2                      True  \n",
       "3                            2                      True  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.station_group_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "      <th>station_group_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source</td>\n",
       "      <td>{}</td>\n",
       "      <td>Source_env_0</td>\n",
       "      <td>Source</td>\n",
       "      <td>INIT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sink</td>\n",
       "      <td>{}</td>\n",
       "      <td>Sink_env_1</td>\n",
       "      <td>Sink</td>\n",
       "      <td>INIT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_2</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>INIT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_3</td>\n",
       "      <td>Machine</td>\n",
       "      <td>INIT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_4</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>INIT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_5</td>\n",
       "      <td>Machine</td>\n",
       "      <td>INIT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_6</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>INIT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_7</td>\n",
       "      <td>Machine</td>\n",
       "      <td>INIT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id resource           name res_type state  station_group_id\n",
       "res_id                                                                   \n",
       "0         source       {}   Source_env_0   Source  INIT                 0\n",
       "1           sink       {}     Sink_env_1     Sink  INIT                 1\n",
       "2             10       {}   Buffer_env_2   Buffer  INIT                 2\n",
       "3              0       {}  Machine_env_3  Machine  INIT                 2\n",
       "4             11       {}   Buffer_env_4   Buffer  INIT                 2\n",
       "5              1       {}  Machine_env_5  Machine  INIT                 2\n",
       "6             12       {}   Buffer_env_6   Buffer  INIT                 3\n",
       "7              2       {}  Machine_env_7  Machine  INIT                 3"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:env:Integrity check for Environment base successful.\n"
     ]
    }
   ],
   "source": [
    "env.check_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FIFO', 'LIFO', 'LPT', 'LST', 'PRIO', 'SPT', 'SST'}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.possible_prio_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dispatcher:Changed priority rule to PRIO\n"
     ]
    }
   ],
   "source": [
    "dispatcher.curr_prio_rule = 'PRIO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGENT', 'RANDOM', 'UTILISATION', 'WIP_LOAD_JOBS', 'WIP_LOAD_TIME'}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.possible_alloc_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dispatcher:Changed allocation rule to WIP_LOAD_TIME\n"
     ]
    }
   ],
   "source": [
    "#dispatcher.curr_prio_rule = 'SPT'\n",
    "dispatcher.curr_alloc_rule = 'WIP_LOAD_TIME'\n",
    "#dispatcher.curr_alloc_rule = 'UTILISATION'\n",
    "#dispatcher.curr_alloc_rule = 'AGENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env.step()\n",
    "env.signal_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dispatcher:Successfully registered job with JobID 0 and name J_gen_0\n",
      "INFO:dispatcher:Successfully registered operation with OpID 0 and name O_gen_0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 0.0 are (System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5))\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 1 and name J_gen_1\n",
      "INFO:dispatcher:Successfully registered operation with OpID 1 and name O_gen_1\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 7200.0 are [System (type: Resource, custom_id: 1, name: Machine_env_5)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 1, name: Machine_env_5) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 1, name: Machine_env_5)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 2 and name J_gen_2\n",
      "INFO:dispatcher:Successfully registered operation with OpID 2 and name O_gen_2\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 14400.0 are [System (type: Resource, custom_id: 2, name: Machine_env_7)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 2, name: Machine_env_7) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2) with machine group (machine) System (type: Resource, custom_id: 2, name: Machine_env_7)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 3 and name J_gen_3\n",
      "INFO:dispatcher:Successfully registered operation with OpID 3 and name O_gen_3\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 21600.0 are (System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5))\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 7:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1) ID 0 with [(datetime.datetime(2023, 11, 21, 7, 0), datetime.timedelta(seconds=25200))]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 4 and name J_gen_4\n",
      "INFO:dispatcher:Successfully registered operation with OpID 4 and name O_gen_4\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 28800.0 are (System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5))\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 7:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1) ID 3 with [(datetime.datetime(2023, 11, 21, 14, 0), datetime.timedelta(seconds=28800))]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) ID 1 with [(datetime.datetime(2023, 11, 21, 18, 0), datetime.timedelta(seconds=57600))]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2) ID 2 with [(datetime.datetime(2023, 11, 21, 19, 0), datetime.timedelta(seconds=54000))]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) ID 4 with [(datetime.datetime(2023, 11, 22, 2, 0), datetime.timedelta(seconds=64800))]\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# check stepping\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m alloc_agent\u001b[38;5;241m.\u001b[39mRL_decision_request:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\site-packages\\salabim\\salabim.py:10648\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_on_empty_eventlist:\n\u001b[0;32m  10647\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39m_now\n\u001b[1;32m> 10648\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun ended\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno events left\u001b[39m\u001b[38;5;124m\"\u001b[39m, s0\u001b[38;5;241m=\u001b[39m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m  10649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10650\u001b[0m     t \u001b[38;5;241m=\u001b[39m inf\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\site-packages\\salabim\\salabim.py:9822\u001b[0m, in \u001b[0;36mComponent.lineno_txt\u001b[1;34m(self, add_at)\u001b[0m\n\u001b[0;32m   9820\u001b[0m             s0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   9821\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39madd_at\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 9822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39madd_at\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frame_to_lineno\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mplus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\site-packages\\salabim\\salabim.py:13998\u001b[0m, in \u001b[0;36mEnvironment._frame_to_lineno\u001b[1;34m(self, frame, add_filename)\u001b[0m\n\u001b[0;32m  13997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frame_to_lineno\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame, add_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m> 13998\u001b[0m     frameinfo \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m add_filename:\n\u001b[0;32m  14000\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(frameinfo\u001b[38;5;241m.\u001b[39mlineno) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(frameinfo\u001b[38;5;241m.\u001b[39mfilename)\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\inspect.py:1688\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isframe(frame):\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a frame or traceback object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame))\n\u001b[1;32m-> 1688\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m getfile(frame)\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1690\u001b[0m     start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\inspect.py:952\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__loader__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[1;32mc:\\Users\\flfo\\AppData\\Local\\mambaforge\\envs\\geom\\Lib\\inspect.py:973\u001b[0m, in \u001b[0;36mgetmodule\u001b[1;34m(object, _filename)\u001b[0m\n\u001b[0;32m    970\u001b[0m modulesbyfile \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    971\u001b[0m _filesbymodname \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetmodule\u001b[39m(\u001b[38;5;28mobject\u001b[39m, _filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the module an object was defined in, or None if not found.\"\"\"\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ismodule(\u001b[38;5;28mobject\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check stepping\n",
    "while not alloc_agent.RL_decision_request:\n",
    "    env.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:agents:[DECISION SET Agent]: Set self._action=0, self._RL_decision_done=True, self._RL_decision_request=False\n"
     ]
    }
   ],
   "source": [
    "alloc_agent.set_decision(action=0)\n",
    "env.main().activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:dispatcher:Successfully registered job with JobID 0 and name J_gen_0\n",
      "INFO:dispatcher:Successfully registered operation with OpID 0 and name O_gen_0\n",
      "--------------- DEBUG: call before hold(0) at 0.0\n",
      "--------------- DEBUG: call after hold(0) at 0.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 0.0 are [System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 1 and name J_gen_1\n",
      "INFO:dispatcher:Successfully registered operation with OpID 1 and name O_gen_1\n",
      "--------------- DEBUG: call before hold(0) at 7200.0\n",
      "--------------- DEBUG: call after hold(0) at 7200.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 7200.0 are [System (type: Resource, custom_id: 1, name: Machine_env_5)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 1, name: Machine_env_5) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 1, name: Machine_env_5)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 2 and name J_gen_2\n",
      "INFO:dispatcher:Successfully registered operation with OpID 2 and name O_gen_2\n",
      "--------------- DEBUG: call before hold(0) at 14400.0\n",
      "--------------- DEBUG: call after hold(0) at 14400.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 14400.0 are [System (type: Resource, custom_id: 2, name: Machine_env_7)]\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 2, name: Machine_env_7) is 0:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2) with machine group (machine) System (type: Resource, custom_id: 2, name: Machine_env_7)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 3 and name J_gen_3\n",
      "INFO:dispatcher:Successfully registered operation with OpID 3 and name O_gen_3\n",
      "--------------- DEBUG: call before hold(0) at 21600.0\n",
      "--------------- DEBUG: call after hold(0) at 21600.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 21600.0 are (System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5))\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 7:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 6:00:00, ExecutionSystemID: 1, SGI: 1) ID 0 with [(datetime.datetime(2023, 11, 21, 7, 0), datetime.timedelta(seconds=25200))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- DEBUG: call before hold(0) at 25200.0\n",
      "--------------- DEBUG: call after hold(0) at 25200.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "INFO:dispatcher:Successfully registered job with JobID 4 and name J_gen_4\n",
      "INFO:dispatcher:Successfully registered operation with OpID 4 and name O_gen_4\n",
      "--------------- DEBUG: call before hold(0) at 28800.0\n",
      "--------------- DEBUG: call after hold(0) at 28800.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1)\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Available stations at 28800.0 are (System (type: Resource, custom_id: 0, name: Machine_env_3), System (type: Resource, custom_id: 1, name: Machine_env_5))\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] WIP LOAD TIME of target_station=System (type: Resource, custom_id: 0, name: Machine_env_3) is 7:00:00\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) with machine group (machine) System (type: Resource, custom_id: 0, name: Machine_env_3)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 5:00:00, ExecutionSystemID: 1, SGI: 1) ID 3 with [(datetime.datetime(2023, 11, 21, 14, 0), datetime.timedelta(seconds=28800))]\n",
      "--------------- DEBUG: call before hold(0) at 50400.0\n",
      "--------------- DEBUG: call after hold(0) at 50400.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR SEQUENCING\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) ID 1 with [(datetime.datetime(2023, 11, 21, 18, 0), datetime.timedelta(seconds=57600))]\n",
      "--------------- DEBUG: call before hold(0) at 64800.0\n",
      "--------------- DEBUG: call after hold(0) at 64800.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 7:00:00, ExecutionSystemID: 1, SGI: 2) ID 2 with [(datetime.datetime(2023, 11, 21, 19, 0), datetime.timedelta(seconds=54000))]\n",
      "--------------- DEBUG: call before hold(0) at 68400.0\n",
      "--------------- DEBUG: call after hold(0) at 68400.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n",
      "DEBUG:dispatcher:Update databases for OP Operation(ProcTime: 9:00:00, ExecutionSystemID: 1, SGI: 1) ID 4 with [(datetime.datetime(2023, 11, 22, 2, 0), datetime.timedelta(seconds=64800))]\n",
      "--------------- DEBUG: call before hold(0) at 93600.0\n",
      "--------------- DEBUG: call after hold(0) at 93600.0\n",
      "INFO:dispatcher:[DISPATCHER: Dispatcher(env: base)] REQUEST TO DISPATCHER FOR ALLOCATION\n",
      "DEBUG:dispatcher:[DISPATCHER: Dispatcher(env: base)] Next operation is None with machine group (machine) System (type: Resource, custom_id: sink, name: Sink_env_1)\n"
     ]
    }
   ],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:infstrct:Successful finalisation of the state information for all resource objects.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env.finalise_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System (type: Resource, custom_id: 2, name: Machine_env_7)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>job</th>\n",
       "      <th>name</th>\n",
       "      <th>job_type</th>\n",
       "      <th>prio</th>\n",
       "      <th>total_proc_time</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_0)</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>Job</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>-11 days, 21:00:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_1)</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>Job</td>\n",
       "      <td>8</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>-10 days, 8:00:00</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_2)</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>Job</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 07:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>-10 days, 9:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_3)</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>Job</td>\n",
       "      <td>9</td>\n",
       "      <td>0 days 05:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>1 day, 1:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>-10 days, 4:00:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_4)</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>Job</td>\n",
       "      <td>12</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>1 day, 8:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>-10 days, 16:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id            job     name job_type prio  total_proc_time   \n",
       "job_id                                                                    \n",
       "0           None  Job (J_gen_0)  J_gen_0      Job    1  0 days 06:00:00  \\\n",
       "1           None  Job (J_gen_1)  J_gen_1      Job    8  0 days 09:00:00   \n",
       "2           None  Job (J_gen_2)  J_gen_2      Job    5  0 days 07:00:00   \n",
       "3           None  Job (J_gen_3)  J_gen_3      Job    9  0 days 05:00:00   \n",
       "4           None  Job (J_gen_4)  J_gen_4      Job   12  0 days 09:00:00   \n",
       "\n",
       "              creation_date         release_date planned_starting_date   \n",
       "job_id                                                                   \n",
       "0       2023-11-21 00:00:00  2023-11-21 00:00:00   2023-11-20 06:00:00  \\\n",
       "1       2023-11-21 02:00:00  2023-11-21 02:00:00   2023-11-20 06:00:00   \n",
       "2       2023-11-21 04:00:00  2023-11-21 04:00:00   2023-11-20 06:00:00   \n",
       "3       2023-11-21 06:00:00  2023-11-21 06:00:00   2023-11-20 06:00:00   \n",
       "4       2023-11-21 08:00:00  2023-11-21 08:00:00   2023-11-20 06:00:00   \n",
       "\n",
       "       actual_starting_date starting_date_deviation  planned_ending_date   \n",
       "job_id                                                                     \n",
       "0       2023-11-21 00:00:00                18:00:00  2023-12-01 10:00:00  \\\n",
       "1       2023-11-21 02:00:00                20:00:00  2023-12-01 10:00:00   \n",
       "2       2023-11-21 04:00:00                22:00:00  2023-12-01 10:00:00   \n",
       "3       2023-11-21 07:00:00          1 day, 1:00:00  2023-12-01 10:00:00   \n",
       "4       2023-11-21 14:00:00          1 day, 8:00:00  2023-12-01 10:00:00   \n",
       "\n",
       "         actual_ending_date ending_date_deviation lead_time   state  \n",
       "job_id                                                               \n",
       "0       2023-11-21 07:00:00    -11 days, 21:00:00   7:00:00  FINISH  \n",
       "1       2023-11-21 18:00:00     -10 days, 8:00:00  16:00:00  FINISH  \n",
       "2       2023-11-21 19:00:00     -10 days, 9:00:00  15:00:00  FINISH  \n",
       "3       2023-11-21 14:00:00     -10 days, 4:00:00   8:00:00  FINISH  \n",
       "4       2023-11-22 02:00:00    -10 days, 16:00:00  18:00:00  FINISH  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.job_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>op</th>\n",
       "      <th>name</th>\n",
       "      <th>prio</th>\n",
       "      <th>execution_system</th>\n",
       "      <th>execution_system_custom_id</th>\n",
       "      <th>execution_system_name</th>\n",
       "      <th>execution_system_type</th>\n",
       "      <th>...</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 6:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 7:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 5:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id job_name custom_id   \n",
       "op_id                              \n",
       "0           0  J_gen_0      None  \\\n",
       "1           1  J_gen_1      None   \n",
       "2           2  J_gen_2      None   \n",
       "3           3  J_gen_3      None   \n",
       "4           4  J_gen_4      None   \n",
       "\n",
       "                                                      op     name  prio   \n",
       "op_id                                                                     \n",
       "0      Operation(ProcTime: 6:00:00, ExecutionSystemID...  O_gen_0  None  \\\n",
       "1      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_1  None   \n",
       "2      Operation(ProcTime: 7:00:00, ExecutionSystemID...  O_gen_2  None   \n",
       "3      Operation(ProcTime: 5:00:00, ExecutionSystemID...  O_gen_3  None   \n",
       "4      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_4  None   \n",
       "\n",
       "                                        execution_system   \n",
       "op_id                                                      \n",
       "0      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...  \\\n",
       "1      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "2      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "3      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "4      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "\n",
       "      execution_system_custom_id   \n",
       "op_id                              \n",
       "0                              1  \\\n",
       "1                              1   \n",
       "2                              1   \n",
       "3                              1   \n",
       "4                              1   \n",
       "\n",
       "                                   execution_system_name   \n",
       "op_id                                                      \n",
       "0      <bound method System.name of System (type: Pro...  \\\n",
       "1      <bound method System.name of System (type: Pro...   \n",
       "2      <bound method System.name of System (type: Pro...   \n",
       "3      <bound method System.name of System (type: Pro...   \n",
       "4      <bound method System.name of System (type: Pro...   \n",
       "\n",
       "      execution_system_type  ...        creation_date         release_date   \n",
       "op_id                        ...                                             \n",
       "0            ProductionArea  ...  2023-11-21 00:00:00  2023-11-21 00:00:00  \\\n",
       "1            ProductionArea  ...  2023-11-21 02:00:00  2023-11-21 02:00:00   \n",
       "2            ProductionArea  ...  2023-11-21 04:00:00  2023-11-21 04:00:00   \n",
       "3            ProductionArea  ...  2023-11-21 06:00:00  2023-11-21 06:00:00   \n",
       "4            ProductionArea  ...  2023-11-21 08:00:00  2023-11-21 08:00:00   \n",
       "\n",
       "      planned_starting_date actual_starting_date starting_date_deviation   \n",
       "op_id                                                                      \n",
       "0                      None  2023-11-21 00:00:00                    None  \\\n",
       "1                      None  2023-11-21 02:00:00                    None   \n",
       "2                      None  2023-11-21 04:00:00                    None   \n",
       "3                      None  2023-11-21 07:00:00                    None   \n",
       "4                      None  2023-11-21 14:00:00                    None   \n",
       "\n",
       "      planned_ending_date   actual_ending_date ending_date_deviation   \n",
       "op_id                                                                  \n",
       "0                    None  2023-11-21 07:00:00                  None  \\\n",
       "1                    None  2023-11-21 18:00:00                  None   \n",
       "2                    None  2023-11-21 19:00:00                  None   \n",
       "3                    None  2023-11-21 14:00:00                  None   \n",
       "4                    None  2023-11-22 02:00:00                  None   \n",
       "\n",
       "      lead_time   state  \n",
       "op_id                    \n",
       "0       7:00:00  FINISH  \n",
       "1      16:00:00  FINISH  \n",
       "2      15:00:00  FINISH  \n",
       "3       8:00:00  FINISH  \n",
       "4      18:00:00  FINISH  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.op_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.653846153888889"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.stat_monitor.wei_avg_WIP_level_time / Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769230769230769"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.stat_monitor.wei_avg_WIP_level_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs [Timedelta]</th>\n",
       "      <th>abs [seconds]</th>\n",
       "      <th>rel [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLOCKED</th>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAILED</th>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAUSED</th>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROCESSING</th>\n",
       "      <td>0 days 07:00:00</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>26.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SETUP</th>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>30.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAITING</th>\n",
       "      <td>0 days 11:00:00</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>42.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           abs [Timedelta]  abs [seconds]    rel [%]\n",
       "BLOCKED    0 days 00:00:00            0.0   0.000000\n",
       "FAILED     0 days 00:00:00            0.0   0.000000\n",
       "PAUSED     0 days 00:00:00            0.0   0.000000\n",
       "PROCESSING 0 days 07:00:00        25200.0  26.923077\n",
       "SETUP      0 days 08:00:00        28800.0  30.769231\n",
       "WAITING    0 days 11:00:00        39600.0  42.307692"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.stat_monitor.state_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INIT': datetime.timedelta(0),\n",
       " 'BLOCKED': datetime.timedelta(0),\n",
       " 'TEMP': datetime.timedelta(0),\n",
       " 'FINISH': datetime.timedelta(0),\n",
       " 'WAITING': datetime.timedelta(seconds=39600),\n",
       " 'FAILED': datetime.timedelta(0),\n",
       " 'SETUP': datetime.timedelta(seconds=28800),\n",
       " 'PAUSED': datetime.timedelta(0),\n",
       " 'PROCESSING': datetime.timedelta(seconds=25200)}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst.stat_monitor.state_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>name</th>\n",
       "      <th>res_type</th>\n",
       "      <th>state</th>\n",
       "      <th>station_group_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source</td>\n",
       "      <td>{}</td>\n",
       "      <td>Source_env_0</td>\n",
       "      <td>Source</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sink</td>\n",
       "      <td>{}</td>\n",
       "      <td>Sink_env_1</td>\n",
       "      <td>Sink</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_2</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_3</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_4</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_5</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>{}</td>\n",
       "      <td>Buffer_env_6</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>Machine_env_7</td>\n",
       "      <td>Machine</td>\n",
       "      <td>FINISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id resource           name res_type   state  station_group_id\n",
       "res_id                                                                     \n",
       "0         source       {}   Source_env_0   Source  FINISH                 0\n",
       "1           sink       {}     Sink_env_1     Sink  FINISH                 1\n",
       "2             10       {}   Buffer_env_2   Buffer  FINISH                 2\n",
       "3              0       {}  Machine_env_3  Machine  FINISH                 2\n",
       "4             11       {}   Buffer_env_4   Buffer  FINISH                 2\n",
       "5              1       {}  Machine_env_5  Machine  FINISH                 2\n",
       "6             12       {}   Buffer_env_6   Buffer  FINISH                 3\n",
       "7              2       {}  Machine_env_7  Machine  FINISH                 3"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infstruct_mgr.res_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>job</th>\n",
       "      <th>name</th>\n",
       "      <th>job_type</th>\n",
       "      <th>prio</th>\n",
       "      <th>total_proc_time</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_0)</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>Job</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>-11 days, 21:00:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_1)</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>Job</td>\n",
       "      <td>8</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>-10 days, 8:00:00</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_2)</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>Job</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 07:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>-10 days, 9:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_3)</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>Job</td>\n",
       "      <td>9</td>\n",
       "      <td>0 days 05:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>1 day, 1:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>-10 days, 4:00:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_4)</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>Job</td>\n",
       "      <td>12</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>1 day, 8:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>-10 days, 16:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id            job     name job_type prio  total_proc_time   \n",
       "job_id                                                                    \n",
       "0           None  Job (J_gen_0)  J_gen_0      Job    1  0 days 06:00:00  \\\n",
       "1           None  Job (J_gen_1)  J_gen_1      Job    8  0 days 09:00:00   \n",
       "2           None  Job (J_gen_2)  J_gen_2      Job    5  0 days 07:00:00   \n",
       "3           None  Job (J_gen_3)  J_gen_3      Job    9  0 days 05:00:00   \n",
       "4           None  Job (J_gen_4)  J_gen_4      Job   12  0 days 09:00:00   \n",
       "\n",
       "              creation_date         release_date planned_starting_date   \n",
       "job_id                                                                   \n",
       "0       2023-11-21 00:00:00  2023-11-21 00:00:00   2023-11-20 06:00:00  \\\n",
       "1       2023-11-21 02:00:00  2023-11-21 02:00:00   2023-11-20 06:00:00   \n",
       "2       2023-11-21 04:00:00  2023-11-21 04:00:00   2023-11-20 06:00:00   \n",
       "3       2023-11-21 06:00:00  2023-11-21 06:00:00   2023-11-20 06:00:00   \n",
       "4       2023-11-21 08:00:00  2023-11-21 08:00:00   2023-11-20 06:00:00   \n",
       "\n",
       "       actual_starting_date starting_date_deviation  planned_ending_date   \n",
       "job_id                                                                     \n",
       "0       2023-11-21 00:00:00                18:00:00  2023-12-01 10:00:00  \\\n",
       "1       2023-11-21 02:00:00                20:00:00  2023-12-01 10:00:00   \n",
       "2       2023-11-21 04:00:00                22:00:00  2023-12-01 10:00:00   \n",
       "3       2023-11-21 07:00:00          1 day, 1:00:00  2023-12-01 10:00:00   \n",
       "4       2023-11-21 14:00:00          1 day, 8:00:00  2023-12-01 10:00:00   \n",
       "\n",
       "         actual_ending_date ending_date_deviation lead_time   state  \n",
       "job_id                                                               \n",
       "0       2023-11-21 07:00:00    -11 days, 21:00:00   7:00:00  FINISH  \n",
       "1       2023-11-21 18:00:00     -10 days, 8:00:00  16:00:00  FINISH  \n",
       "2       2023-11-21 19:00:00     -10 days, 9:00:00  15:00:00  FINISH  \n",
       "3       2023-11-21 14:00:00     -10 days, 4:00:00   8:00:00  FINISH  \n",
       "4       2023-11-22 02:00:00    -10 days, 16:00:00  18:00:00  FINISH  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.job_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>op</th>\n",
       "      <th>name</th>\n",
       "      <th>prio</th>\n",
       "      <th>execution_system</th>\n",
       "      <th>execution_system_custom_id</th>\n",
       "      <th>execution_system_name</th>\n",
       "      <th>execution_system_type</th>\n",
       "      <th>...</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 6:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 7:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 5:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id job_name custom_id   \n",
       "op_id                              \n",
       "0           0  J_gen_0      None  \\\n",
       "1           1  J_gen_1      None   \n",
       "2           2  J_gen_2      None   \n",
       "3           3  J_gen_3      None   \n",
       "4           4  J_gen_4      None   \n",
       "\n",
       "                                                      op     name  prio   \n",
       "op_id                                                                     \n",
       "0      Operation(ProcTime: 6:00:00, ExecutionSystemID...  O_gen_0  None  \\\n",
       "1      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_1  None   \n",
       "2      Operation(ProcTime: 7:00:00, ExecutionSystemID...  O_gen_2  None   \n",
       "3      Operation(ProcTime: 5:00:00, ExecutionSystemID...  O_gen_3  None   \n",
       "4      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_4  None   \n",
       "\n",
       "                                        execution_system   \n",
       "op_id                                                      \n",
       "0      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...  \\\n",
       "1      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "2      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "3      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "4      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "\n",
       "      execution_system_custom_id   \n",
       "op_id                              \n",
       "0                              1  \\\n",
       "1                              1   \n",
       "2                              1   \n",
       "3                              1   \n",
       "4                              1   \n",
       "\n",
       "                                   execution_system_name   \n",
       "op_id                                                      \n",
       "0      <bound method System.name of System (type: Pro...  \\\n",
       "1      <bound method System.name of System (type: Pro...   \n",
       "2      <bound method System.name of System (type: Pro...   \n",
       "3      <bound method System.name of System (type: Pro...   \n",
       "4      <bound method System.name of System (type: Pro...   \n",
       "\n",
       "      execution_system_type  ...        creation_date         release_date   \n",
       "op_id                        ...                                             \n",
       "0            ProductionArea  ...  2023-11-21 00:00:00  2023-11-21 00:00:00  \\\n",
       "1            ProductionArea  ...  2023-11-21 02:00:00  2023-11-21 02:00:00   \n",
       "2            ProductionArea  ...  2023-11-21 04:00:00  2023-11-21 04:00:00   \n",
       "3            ProductionArea  ...  2023-11-21 06:00:00  2023-11-21 06:00:00   \n",
       "4            ProductionArea  ...  2023-11-21 08:00:00  2023-11-21 08:00:00   \n",
       "\n",
       "      planned_starting_date actual_starting_date starting_date_deviation   \n",
       "op_id                                                                      \n",
       "0                      None  2023-11-21 00:00:00                    None  \\\n",
       "1                      None  2023-11-21 02:00:00                    None   \n",
       "2                      None  2023-11-21 04:00:00                    None   \n",
       "3                      None  2023-11-21 07:00:00                    None   \n",
       "4                      None  2023-11-21 14:00:00                    None   \n",
       "\n",
       "      planned_ending_date   actual_ending_date ending_date_deviation   \n",
       "op_id                                                                  \n",
       "0                    None  2023-11-21 07:00:00                  None  \\\n",
       "1                    None  2023-11-21 18:00:00                  None   \n",
       "2                    None  2023-11-21 19:00:00                  None   \n",
       "3                    None  2023-11-21 14:00:00                  None   \n",
       "4                    None  2023-11-22 02:00:00                  None   \n",
       "\n",
       "      lead_time   state  \n",
       "op_id                    \n",
       "0       7:00:00  FINISH  \n",
       "1      16:00:00  FINISH  \n",
       "2      15:00:00  FINISH  \n",
       "3       8:00:00  FINISH  \n",
       "4      18:00:00  FINISH  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.op_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System (type: Resource, custom_id: 1, name: Machine_env_5)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachInst = infstruct_mgr.lookup_subsystem_info(\n",
    "    subsystem_type='Resource',\n",
    "    lookup_property='custom_id',\n",
    "    lookup_val=1\n",
    ")\n",
    "MachInst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WIP level number of jobs: 0.6154\n",
      "Average WIP level load time: 9.8462\n"
     ]
    }
   ],
   "source": [
    "mon = MachInst.stat_monitor\n",
    "print(f'Average WIP level number of jobs: {mon.wei_avg_WIP_level_num:.4f}')\n",
    "print(f'Average WIP level load time: {mon.wei_avg_WIP_level_time / Timedelta(hours=1):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid",
          "shape": "vh",
          "width": 3
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2023-11-21T00:00:00",
          "2023-11-21T02:00:00",
          "2023-11-21T18:00:00",
          "2023-11-22T02:00:00",
          "2023-11-22T02:00:00"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          16,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "orange",
           "dash": "dot",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 9.846153846111111,
          "y1": 9.846153846111111,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "WIP Level Time of System (type: Resource, custom_id: 1, name: Machine_env_5)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "WIP Level Time [time units]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = mon.draw_WIP_level(use_num_jobs_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INIT': datetime.timedelta(0),\n",
       " 'BLOCKED': datetime.timedelta(0),\n",
       " 'TEMP': datetime.timedelta(0),\n",
       " 'FINISH': datetime.timedelta(0),\n",
       " 'WAITING': datetime.timedelta(seconds=36000),\n",
       " 'FAILED': datetime.timedelta(0),\n",
       " 'SETUP': datetime.timedelta(seconds=25200),\n",
       " 'PAUSED': datetime.timedelta(0),\n",
       " 'PROCESSING': datetime.timedelta(seconds=32400)}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.state_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "state=%{x}<br>total time [hours]=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "BLOCKED",
          "FAILED",
          "FINISH",
          "INIT",
          "PAUSED",
          "PROCESSING",
          "SETUP",
          "TEMP",
          "WAITING"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          0,
          9,
          7,
          0,
          10
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "State Time Distribution of System (type: Resource, custom_id: 1, name: Machine_env_5)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "state"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "total time [hours]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = mon.draw_state_bar_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "state=%{label}<br>total time [hours]=%{value}<extra></extra>",
         "labels": [
          "PROCESSING",
          "SETUP",
          "WAITING"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "type": "pie",
         "values": [
          9,
          7,
          10
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "State Time Distribution of System (type: Resource, custom_id: 1, name: Machine_env_5)"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = mon.draw_state_pie_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fill level: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>0 days 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sim_time         duration  level\n",
       "0  2023-11-21 02:00:00  0 days 02:00:00      0\n",
       "1  2023-11-22 02:00:00  1 days 00:00:00      0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buff = list(MachInst.buffers)[0]\n",
    "buffmon = buff.stat_monitor\n",
    "print(f'Average fill level: {buffmon.wei_avg_fill_level}')\n",
    "buffmon.level_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid",
          "shape": "vh",
          "width": 3
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2023-11-21T00:00:00",
          "2023-11-21T02:00:00",
          "2023-11-22T02:00:00"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "orange",
           "dash": "dot",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0,
          "y1": 0,
          "yref": "y"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 20,
          "y1": 20,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Fill Level of System (type: Resource, custom_id: 11, name: Buffer_env_4)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "fill level [-]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = buffmon.draw_fill_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 11, 21, 0, 0)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.datetime0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1, seconds=7200)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.cycle_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>job</th>\n",
       "      <th>name</th>\n",
       "      <th>job_type</th>\n",
       "      <th>prio</th>\n",
       "      <th>total_proc_time</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_0)</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>Job</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>-11 days, 21:00:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_1)</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>Job</td>\n",
       "      <td>8</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>-10 days, 8:00:00</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_2)</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>Job</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 07:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>-10 days, 9:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_3)</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>Job</td>\n",
       "      <td>9</td>\n",
       "      <td>0 days 05:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>1 day, 1:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>-10 days, 4:00:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Job (J_gen_4)</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>Job</td>\n",
       "      <td>12</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>1 day, 8:00:00</td>\n",
       "      <td>2023-12-01 10:00:00</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>-10 days, 16:00:00</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id            job     name job_type prio  total_proc_time   \n",
       "job_id                                                                    \n",
       "0           None  Job (J_gen_0)  J_gen_0      Job    1  0 days 06:00:00  \\\n",
       "1           None  Job (J_gen_1)  J_gen_1      Job    8  0 days 09:00:00   \n",
       "2           None  Job (J_gen_2)  J_gen_2      Job    5  0 days 07:00:00   \n",
       "3           None  Job (J_gen_3)  J_gen_3      Job    9  0 days 05:00:00   \n",
       "4           None  Job (J_gen_4)  J_gen_4      Job   12  0 days 09:00:00   \n",
       "\n",
       "              creation_date         release_date planned_starting_date   \n",
       "job_id                                                                   \n",
       "0       2023-11-21 00:00:00  2023-11-21 00:00:00   2023-11-20 06:00:00  \\\n",
       "1       2023-11-21 02:00:00  2023-11-21 02:00:00   2023-11-20 06:00:00   \n",
       "2       2023-11-21 04:00:00  2023-11-21 04:00:00   2023-11-20 06:00:00   \n",
       "3       2023-11-21 06:00:00  2023-11-21 06:00:00   2023-11-20 06:00:00   \n",
       "4       2023-11-21 08:00:00  2023-11-21 08:00:00   2023-11-20 06:00:00   \n",
       "\n",
       "       actual_starting_date starting_date_deviation  planned_ending_date   \n",
       "job_id                                                                     \n",
       "0       2023-11-21 00:00:00                18:00:00  2023-12-01 10:00:00  \\\n",
       "1       2023-11-21 02:00:00                20:00:00  2023-12-01 10:00:00   \n",
       "2       2023-11-21 04:00:00                22:00:00  2023-12-01 10:00:00   \n",
       "3       2023-11-21 07:00:00          1 day, 1:00:00  2023-12-01 10:00:00   \n",
       "4       2023-11-21 14:00:00          1 day, 8:00:00  2023-12-01 10:00:00   \n",
       "\n",
       "         actual_ending_date ending_date_deviation lead_time   state  \n",
       "job_id                                                               \n",
       "0       2023-11-21 07:00:00    -11 days, 21:00:00   7:00:00  FINISH  \n",
       "1       2023-11-21 18:00:00     -10 days, 8:00:00  16:00:00  FINISH  \n",
       "2       2023-11-21 19:00:00     -10 days, 9:00:00  15:00:00  FINISH  \n",
       "3       2023-11-21 14:00:00     -10 days, 4:00:00   8:00:00  FINISH  \n",
       "4       2023-11-22 02:00:00    -10 days, 16:00:00  18:00:00  FINISH  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.job_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>op</th>\n",
       "      <th>name</th>\n",
       "      <th>prio</th>\n",
       "      <th>execution_system</th>\n",
       "      <th>execution_system_custom_id</th>\n",
       "      <th>execution_system_name</th>\n",
       "      <th>execution_system_type</th>\n",
       "      <th>...</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>release_date</th>\n",
       "      <th>planned_starting_date</th>\n",
       "      <th>actual_starting_date</th>\n",
       "      <th>starting_date_deviation</th>\n",
       "      <th>planned_ending_date</th>\n",
       "      <th>actual_ending_date</th>\n",
       "      <th>ending_date_deviation</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>J_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 6:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_0</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_1</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 18:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>J_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 7:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_2</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 04:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 19:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>J_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 5:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_3</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>2023-11-21 06:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>J_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>Operation(ProcTime: 9:00:00, ExecutionSystemID...</td>\n",
       "      <td>O_gen_4</td>\n",
       "      <td>None</td>\n",
       "      <td>{2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bound method System.name of System (type: Pro...</td>\n",
       "      <td>ProductionArea</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>2023-11-21 08:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-21 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-22 02:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>FINISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id job_name custom_id   \n",
       "op_id                              \n",
       "0           0  J_gen_0      None  \\\n",
       "1           1  J_gen_1      None   \n",
       "2           2  J_gen_2      None   \n",
       "3           3  J_gen_3      None   \n",
       "4           4  J_gen_4      None   \n",
       "\n",
       "                                                      op     name  prio   \n",
       "op_id                                                                     \n",
       "0      Operation(ProcTime: 6:00:00, ExecutionSystemID...  O_gen_0  None  \\\n",
       "1      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_1  None   \n",
       "2      Operation(ProcTime: 7:00:00, ExecutionSystemID...  O_gen_2  None   \n",
       "3      Operation(ProcTime: 5:00:00, ExecutionSystemID...  O_gen_3  None   \n",
       "4      Operation(ProcTime: 9:00:00, ExecutionSystemID...  O_gen_4  None   \n",
       "\n",
       "                                        execution_system   \n",
       "op_id                                                      \n",
       "0      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...  \\\n",
       "1      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "2      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "3      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "4      {2: {2: {}, 3: {}, 4: {}, 5: {}}, 3: {6: {}, 7...   \n",
       "\n",
       "      execution_system_custom_id   \n",
       "op_id                              \n",
       "0                              1  \\\n",
       "1                              1   \n",
       "2                              1   \n",
       "3                              1   \n",
       "4                              1   \n",
       "\n",
       "                                   execution_system_name   \n",
       "op_id                                                      \n",
       "0      <bound method System.name of System (type: Pro...  \\\n",
       "1      <bound method System.name of System (type: Pro...   \n",
       "2      <bound method System.name of System (type: Pro...   \n",
       "3      <bound method System.name of System (type: Pro...   \n",
       "4      <bound method System.name of System (type: Pro...   \n",
       "\n",
       "      execution_system_type  ...        creation_date         release_date   \n",
       "op_id                        ...                                             \n",
       "0            ProductionArea  ...  2023-11-21 00:00:00  2023-11-21 00:00:00  \\\n",
       "1            ProductionArea  ...  2023-11-21 02:00:00  2023-11-21 02:00:00   \n",
       "2            ProductionArea  ...  2023-11-21 04:00:00  2023-11-21 04:00:00   \n",
       "3            ProductionArea  ...  2023-11-21 06:00:00  2023-11-21 06:00:00   \n",
       "4            ProductionArea  ...  2023-11-21 08:00:00  2023-11-21 08:00:00   \n",
       "\n",
       "      planned_starting_date actual_starting_date starting_date_deviation   \n",
       "op_id                                                                      \n",
       "0                      None  2023-11-21 00:00:00                    None  \\\n",
       "1                      None  2023-11-21 02:00:00                    None   \n",
       "2                      None  2023-11-21 04:00:00                    None   \n",
       "3                      None  2023-11-21 07:00:00                    None   \n",
       "4                      None  2023-11-21 14:00:00                    None   \n",
       "\n",
       "      planned_ending_date   actual_ending_date ending_date_deviation   \n",
       "op_id                                                                  \n",
       "0                    None  2023-11-21 07:00:00                  None  \\\n",
       "1                    None  2023-11-21 18:00:00                  None   \n",
       "2                    None  2023-11-21 19:00:00                  None   \n",
       "3                    None  2023-11-21 14:00:00                  None   \n",
       "4                    None  2023-11-22 02:00:00                  None   \n",
       "\n",
       "      lead_time   state  \n",
       "op_id                    \n",
       "0       7:00:00  FINISH  \n",
       "1      16:00:00  FINISH  \n",
       "2      15:00:00  FINISH  \n",
       "3       8:00:00  FINISH  \n",
       "4      18:00:00  FINISH  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispatcher.op_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLOCKED': datetime.timedelta(0),\n",
      " 'FAILED': datetime.timedelta(0),\n",
      " 'FINISH': datetime.timedelta(0),\n",
      " 'INIT': datetime.timedelta(0),\n",
      " 'PAUSED': datetime.timedelta(0),\n",
      " 'PROCESSING': datetime.timedelta(seconds=21600),\n",
      " 'SETUP': datetime.timedelta(seconds=3600),\n",
      " 'TEMP': datetime.timedelta(0),\n",
      " 'WAITING': datetime.timedelta(0)}\n"
     ]
    }
   ],
   "source": [
    "job = dispatcher.get_job_obj_by_prop(val=0)\n",
    "pprint(job.stat_monitor.state_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation 1\n",
      "State Times:\n",
      "{'BLOCKED': datetime.timedelta(0),\n",
      " 'FAILED': datetime.timedelta(0),\n",
      " 'FINISH': datetime.timedelta(0),\n",
      " 'INIT': datetime.timedelta(0),\n",
      " 'PAUSED': datetime.timedelta(0),\n",
      " 'PROCESSING': datetime.timedelta(seconds=21600),\n",
      " 'SETUP': datetime.timedelta(seconds=3600),\n",
      " 'TEMP': datetime.timedelta(0),\n",
      " 'WAITING': datetime.timedelta(0)}\n",
      "Target Station Group:\n",
      "System (type: StationGroup, custom_id: 1, name: StationGroup_env_2)\n",
      "Setup Time: 1:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('\\nOperation 2\\nState Times:')\\npprint(op2.stat_monitor.state_times)\\nprint(f'Target Station Group:\\n{op2.target_station_group}')\\nprint(f'Setup Time: {op2.setup_time}')\\n\""
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op1 = job.operations[0]\n",
    "#op2 = job.operations[1]\n",
    "\n",
    "print('Operation 1\\nState Times:')\n",
    "pprint(op1.stat_monitor.state_times)\n",
    "print(f'Target Station Group:\\n{op1.target_station_group}')\n",
    "print(f'Setup Time: {op1.setup_time}')\n",
    "\"\"\"\n",
    "print('\\nOperation 2\\nState Times:')\n",
    "pprint(op2.stat_monitor.state_times)\n",
    "print(f'Target Station Group:\\n{op2.target_station_group}')\n",
    "print(f'Setup Time: {op2.setup_time}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T00:00:00",
          "2023-11-21T07:00:00",
          "2023-11-21T14:00:00",
          "2023-11-21T02:00:00",
          "2023-11-21T04:00:00"
         ],
         "customdata": [
          [
           "J_gen_0",
           0,
           1,
           null,
           null,
           null,
           "P0DT6H0M0S",
           "P0DT1H0M0S",
           "P0DT7H0M0S"
          ],
          [
           "J_gen_3",
           0,
           1,
           null,
           null,
           null,
           "P0DT5H0M0S",
           "P0DT2H0M0S",
           "P0DT7H0M0S"
          ],
          [
           "J_gen_4",
           0,
           1,
           null,
           null,
           null,
           "P0DT9H0M0S",
           "P0DT3H0M0S",
           "P0DT12H0M0S"
          ],
          [
           "J_gen_1",
           1,
           1,
           null,
           null,
           null,
           "P0DT9H0M0S",
           "P0DT7H0M0S",
           "P0DT16H0M0S"
          ],
          [
           "J_gen_2",
           2,
           1,
           null,
           null,
           null,
           "P0DT7H0M0S",
           "P0DT8H0M0S",
           "P0DT15H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>execution_system_custom_id=%{customdata[2]}<br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_0",
          "J_gen_3",
          "J_gen_4",
          "J_gen_1",
          "J_gen_2"
         ],
         "legendgroup": "1",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          25200000,
          25200000,
          43200000,
          57600000,
          54000000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_3",
          "Machine_env_3",
          "Machine_env_3",
          "Machine_env_5",
          "Machine_env_7"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "title": {
          "text": "execution_system_custom_id"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "type": "date"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "target_station_name"
         },
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = dispatcher.draw_gantt_chart(use_custom_proc_station_id=False, \n",
    "                                  sort_by_proc_station=True, \n",
    "                                  group_by_exec_system=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T00:00:00"
         ],
         "customdata": [
          [
           "J_gen_0",
           0,
           1,
           null,
           null,
           null,
           "P0DT6H0M0S",
           "P0DT1H0M0S",
           "P0DT7H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>execution_system_custom_id=%{customdata[2]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_0"
         ],
         "legendgroup": "J_gen_0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_0",
         "offsetgroup": "J_gen_0",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          25200000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_3"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T07:00:00"
         ],
         "customdata": [
          [
           "J_gen_3",
           0,
           1,
           null,
           null,
           null,
           "P0DT5H0M0S",
           "P0DT2H0M0S",
           "P0DT7H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>execution_system_custom_id=%{customdata[2]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_3"
         ],
         "legendgroup": "J_gen_3",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_3",
         "offsetgroup": "J_gen_3",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          25200000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_3"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T14:00:00"
         ],
         "customdata": [
          [
           "J_gen_4",
           0,
           1,
           null,
           null,
           null,
           "P0DT9H0M0S",
           "P0DT3H0M0S",
           "P0DT12H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>execution_system_custom_id=%{customdata[2]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_4"
         ],
         "legendgroup": "J_gen_4",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_4",
         "offsetgroup": "J_gen_4",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          43200000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_3"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T02:00:00"
         ],
         "customdata": [
          [
           "J_gen_1",
           1,
           1,
           null,
           null,
           null,
           "P0DT9H0M0S",
           "P0DT7H0M0S",
           "P0DT16H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>execution_system_custom_id=%{customdata[2]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_1"
         ],
         "legendgroup": "J_gen_1",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_1",
         "offsetgroup": "J_gen_1",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          57600000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_5"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "base": [
          "2023-11-21T04:00:00"
         ],
         "customdata": [
          [
           "J_gen_2",
           2,
           1,
           null,
           null,
           null,
           "P0DT7H0M0S",
           "P0DT8H0M0S",
           "P0DT15H0M0S"
          ]
         ],
         "hovertemplate": "<b>%{hovertext}</b><br><br>actual_starting_date=%{base}<br>actual_ending_date=%{x}<br>target_station_name=%{y}<br>target_station_custom_id=%{customdata[1]}<br>execution_system_custom_id=%{customdata[2]}<br>prio=%{customdata[3]}<br>planned_starting_date=%{customdata[4]}<br>planned_ending_date=%{customdata[5]}<br>proc_time=%{customdata[6]}<br>setup_time=%{customdata[7]}<br>order_time=%{customdata[8]}<extra></extra>",
         "hovertext": [
          "J_gen_2"
         ],
         "legendgroup": "J_gen_2",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "J_gen_2",
         "offsetgroup": "J_gen_2",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          54000000
         ],
         "xaxis": "x",
         "y": [
          "Machine_env_7"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "title": {
          "text": "job_name"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "type": "date"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "target_station_name"
         },
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = dispatcher.draw_gantt_chart(use_custom_proc_station_id=False, \n",
    "                                  sort_by_proc_station=True,\n",
    "                                  group_by_exec_system=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Load Objects**\n",
    "\n",
    "*Changes for station groups:*\n",
    "- operations now contain station identifiers instead of machine identifiers\n",
    "- operation registration in the dispatcher now assigns station groups rather than specific machines\n",
    "- allocation request in the dispatcher now chooses between machines in the associated machine group; if there is only one (single-machine case) then there are no parallel machines\n",
    "- allocation request also returns associated buffers **--> buffer management implemented in Dispatcher**\n",
    "\n",
    "*Buffers:*\n",
    "\n",
    "~~3 ways to implement buffers with station groups~~:\n",
    "1. one buffer for the whole group\n",
    "1. one buffer for each machine\n",
    "1. mix case: buffer for each machine plus one station group buffer\n",
    "\n",
    "**Station groups are accessed to obtain processing stations which have associated buffers --> nothing changes compared to the current behaviour**\n",
    "\n",
    "*Job creation:*\n",
    "- now each job must contain a list of station group identifiers instead of machine identifiers\n",
    "- for random generation there has to be information about the order of station groups and how many station groups exist\n",
    "    - currently implemented: each job passes each machine\n",
    "    - next step: each job passes each machine group, so the random order now consists of a permutation of the station group identifiers instead of the machine identifiers --> information available in the station group database of the environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dispatcher'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dispatcher:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        env: SimulationEnvironment,\n",
    "        priority_rule: str = 'FIFO',\n",
    "        allocation_rule: str = 'RANDOM',\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dispatcher class for given environment (only one dispatcher for each environment)\n",
    "        - different functions to monitor all jobs in the environment\n",
    "        - jobs report back their states to the dispatcher\n",
    "        \"\"\"\n",
    "        \n",
    "        # job data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._job_prop: dict[str, type] = {\n",
    "            'job_id': int,\n",
    "            'custom_id': object,\n",
    "            'job': object,\n",
    "            'name': str,\n",
    "            'job_type': str,\n",
    "            'prio': object,\n",
    "            #'total_proc_time': float,\n",
    "            #'creation_date': float,\n",
    "            #'release_date': float,\n",
    "            #'entry_date': float,\n",
    "            #'exit_date': float\n",
    "            #'lead_time': float,\n",
    "            'total_proc_time': object,\n",
    "            'creation_date': object,\n",
    "            'release_date': object,\n",
    "            'planned_starting_date': object,\n",
    "            #'entry_date': object,\n",
    "            'actual_starting_date': object,\n",
    "            'starting_date_deviation': object,\n",
    "            #'exit_date': object,\n",
    "            'planned_ending_date': object,\n",
    "            'actual_ending_date': object,\n",
    "            'ending_date_deviation': object,\n",
    "            'lead_time': object,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._job_db: DataFrame = pd.DataFrame(columns=list(self._job_prop.keys()))\n",
    "        self._job_db: DataFrame = self._job_db.astype(self._job_prop)\n",
    "        self._job_db: DataFrame = self._job_db.set_index('job_id')\n",
    "        # properties by which a object can be obtained from the job database\n",
    "        self._job_lookup_props: set[str] = set(['job_id', 'custom_id', 'name'])\n",
    "        # properties which can be updated after creation\n",
    "        self._job_update_props: set[str] = set([\n",
    "            'prio',\n",
    "            'creation_date',\n",
    "            'release_date',\n",
    "            #'entry_date',\n",
    "            'planned_starting_date',\n",
    "            'actual_starting_date',\n",
    "            'starting_date_deviation',\n",
    "            #'exit_date',\n",
    "            'planned_ending_date',\n",
    "            'actual_ending_date',\n",
    "            'ending_date_deviation',\n",
    "            'lead_time',\n",
    "            'state',\n",
    "        ])\n",
    "        \n",
    "        # operation data base as simple Pandas DataFrame\n",
    "        # column data types\n",
    "        self._op_prop: dict[str, type] = {\n",
    "            'op_id': int,\n",
    "            'job_id': int,\n",
    "            'job_name': str,\n",
    "            'custom_id': object,\n",
    "            'op': object,\n",
    "            'name': str,\n",
    "            'prio': object,\n",
    "            'execution_system': object,\n",
    "            'execution_system_custom_id': object,\n",
    "            'execution_system_name': str,\n",
    "            'execution_system_type': str,\n",
    "            'target_station_custom_id': object,\n",
    "            'target_station_name': str,\n",
    "            'proc_time': object,\n",
    "            'setup_time': object,\n",
    "            'order_time': object,\n",
    "            'creation_date': object,\n",
    "            'release_date': object,\n",
    "            #'entry_date': object,\n",
    "            'planned_starting_date': object,\n",
    "            'actual_starting_date': object,\n",
    "            'starting_date_deviation': object,\n",
    "            #'exit_date': object,\n",
    "            'planned_ending_date': object,\n",
    "            'actual_ending_date': object,\n",
    "            'ending_date_deviation': object,\n",
    "            'lead_time': object,\n",
    "            'state': str,\n",
    "        }\n",
    "        self._op_db: DataFrame = pd.DataFrame(columns=list(self._op_prop.keys()))\n",
    "        self._op_db: DataFrame = self._op_db.astype(self._op_prop)\n",
    "        self._op_db: DataFrame = self._op_db.set_index('op_id')\n",
    "        # properties by which a object can be obtained from the operation database\n",
    "        self._op_lookup_props: set[str] = set(['op_id', 'job_id', 'custom_id', 'name', 'machine'])\n",
    "        # properties which can be updated after creation\n",
    "        self._op_update_props: set[str] = set([\n",
    "            'prio',\n",
    "            'target_station_custom_id',\n",
    "            'target_station_name',\n",
    "            'creation_date',\n",
    "            'release_date',\n",
    "            #'entry_date',\n",
    "            #'planned_starting_date',\n",
    "            'actual_starting_date',\n",
    "            'starting_date_deviation',\n",
    "            #'exit_date',\n",
    "            #'planned_ending_date',\n",
    "            'actual_ending_date',\n",
    "            'ending_date_deviation',\n",
    "            'lead_time',\n",
    "            'state',\n",
    "        ])\n",
    "        \n",
    "        # register in environment and get EnvID\n",
    "        self._env = env\n",
    "        self._env.register_dispatcher(self)\n",
    "        \n",
    "        ####################################\n",
    "        # managing IDs\n",
    "        self._id_types = set(['job', 'op'])\n",
    "        self._job_id_counter: ObjectID = 0\n",
    "        self._op_id_counter: ObjectID = 0\n",
    "        \n",
    "        # priority rules\n",
    "        self._priority_rules: set[str] = set([\n",
    "            'FIFO',\n",
    "            'LIFO',\n",
    "            'SPT',\n",
    "            'LPT',\n",
    "            'SST',\n",
    "            'LST',\n",
    "            'PRIO',\n",
    "        ])\n",
    "        # set current priority rule\n",
    "        if priority_rule not in self._priority_rules:\n",
    "            raise ValueError(f\"Priority rule {priority_rule} unknown. Must be one of {self._priority_rules}\")\n",
    "        else:\n",
    "            self._curr_prio_rule = priority_rule\n",
    "            \n",
    "        # allocation rule\n",
    "        self._allocation_rules: set[str] = set([\n",
    "            'RANDOM',\n",
    "            'UTILISATION',\n",
    "            'WIP_LOAD_TIME',\n",
    "            'WIP_LOAD_JOBS',\n",
    "            'AGENT',\n",
    "        ])\n",
    "        # set current allocation rule\n",
    "        if allocation_rule not in self._allocation_rules:\n",
    "            raise ValueError(f\"Allocation rule {allocation_rule} unknown. Must be one of {self._allocation_rules}\")\n",
    "        else:\n",
    "            self._curr_alloc_rule = allocation_rule\n",
    "            \n",
    "        # [STATS] cycle time\n",
    "        self._cycle_time: Timedelta = Timedelta()\n",
    "        \n",
    "        self.np_rnd_gen: NPRandomGenerator = np.random.default_rng(seed=42)\n",
    "    \n",
    "    ### DATA MANAGEMENT\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Dispatcher(env: {self.env.name()})\"\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def curr_prio_rule(self) -> str:\n",
    "        return self._curr_prio_rule\n",
    "    \n",
    "    @curr_prio_rule.setter\n",
    "    def curr_prio_rule(\n",
    "        self,\n",
    "        rule: str,\n",
    "    ) -> None:\n",
    "        if rule not in self._priority_rules:\n",
    "            raise ValueError(f\"Priority rule {rule} unknown. Must be one of {self._priority_rules}\")\n",
    "        else:\n",
    "            self._curr_prio_rule = rule\n",
    "            logger_dispatcher.info(f\"Changed priority rule to {rule}\")\n",
    "    \n",
    "    def possible_prio_rules(self) -> set[str]:\n",
    "        return self._priority_rules\n",
    "    \n",
    "    @property\n",
    "    def curr_alloc_rule(self) -> str:\n",
    "        return self._curr_alloc_rule\n",
    "    \n",
    "    @curr_alloc_rule.setter\n",
    "    def curr_alloc_rule(\n",
    "        self,\n",
    "        rule: str,\n",
    "    ) -> None:\n",
    "        if rule not in self._allocation_rules:\n",
    "            raise ValueError(f\"Allocation rule {rule} unknown. Must be one of {self._allocation_rules}\")\n",
    "        else:\n",
    "            self._curr_alloc_rule = rule\n",
    "            logger_dispatcher.info(f\"Changed allocation rule to {rule}\")\n",
    "            \n",
    "    def possible_alloc_rules(self) -> set[str]:\n",
    "        return self._allocation_rules\n",
    "    \n",
    "    def _obtain_load_obj_id(\n",
    "        self,\n",
    "        load_type: str,\n",
    "    ) -> ObjectID:\n",
    "        \"\"\"Simple counter function for managing operation IDs\"\"\"\n",
    "        # assign id and set counter up\n",
    "        \n",
    "        if load_type not in self._id_types:\n",
    "            raise ValueError(f\"Given type {type} not valid. Choose from '{self._id_types}'\")\n",
    "        \n",
    "        match load_type:\n",
    "            case 'job':\n",
    "                ident_no = self._job_id_counter\n",
    "                self._job_id_counter += 1\n",
    "            case 'op':\n",
    "                ident_no = self._op_id_counter\n",
    "                self._op_id_counter += 1\n",
    "        \n",
    "        return ident_no\n",
    "    \n",
    "    @property\n",
    "    def cycle_time(self) -> Timedelta:\n",
    "        return self._cycle_time\n",
    "    \n",
    "    def _calc_cycle_time(self) -> None:\n",
    "        \"\"\"\n",
    "        Obtaining the current cycle time of all operations\n",
    "        \"\"\"\n",
    "        self._cycle_time: Timedelta = self._op_db['actual_ending_date'].max() - self._env.starting_datetime\n",
    "    \n",
    "    ### JOBS ###\n",
    "    def register_job(\n",
    "        self,\n",
    "        obj: Job,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) -> tuple[SimulationEnvironment, ObjectID, str]:\n",
    "        \"\"\"\n",
    "        registers an job object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated jobs\n",
    "        \"\"\"\n",
    "        # obtain id\n",
    "        job_id = self._obtain_load_obj_id(load_type='job')\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'J_gen_{job_id}'\n",
    "        \n",
    "        # time of creation\n",
    "        #creation_date = self.env.now()\n",
    "        creation_date = self.env.t_as_dt()\n",
    "        \n",
    "        # new entry for job data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'job_id': [job_id],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'job': [obj],\n",
    "                                'name': [name],\n",
    "                                'job_type': [obj.job_type],\n",
    "                                'prio': [obj.prio],\n",
    "                                'total_proc_time': [obj.total_proc_time],\n",
    "                                'creation_date': [creation_date],\n",
    "                                'release_date': [obj.time_release],\n",
    "                                #'entry_date': [obj.time_entry],\n",
    "                                'planned_starting_date': [obj.time_planned_starting],\n",
    "                                'actual_starting_date': [obj.time_actual_starting],\n",
    "                                'starting_date_deviation': [obj.starting_date_deviation],\n",
    "                                #'exit_date': [obj.time_exit],\n",
    "                                'planned_ending_date': [obj.time_planned_ending],\n",
    "                                'actual_ending_date': [obj.time_actual_ending],\n",
    "                                'ending_date_deviation': [obj.ending_date_deviation],\n",
    "                                'lead_time': [obj.lead_time],\n",
    "                                'state': [state]})\n",
    "        new_entry = new_entry.astype(self._job_prop)\n",
    "        new_entry = new_entry.set_index('job_id')\n",
    "        self._job_db = pd.concat([self._job_db, new_entry])\n",
    "        \n",
    "        logger_dispatcher.info(f\"Successfully registered job with JobID {job_id} and name {name}\")\n",
    "        \n",
    "        # write job information directly\n",
    "        obj.time_creation = creation_date\n",
    "        \n",
    "        # return current env, job ID, job name\n",
    "        return self._env, job_id, name\n",
    "    \n",
    "    def update_job_db(\n",
    "        self,\n",
    "        job: Job,\n",
    "        property: str,\n",
    "        val: float | str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        updates the information of a job for a given property\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_update_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_update_props}\")\n",
    "        # None type value can not be set\n",
    "        if val is None:\n",
    "            raise TypeError(\"The set value can not be of type >>None<<.\")\n",
    "        \n",
    "        self._job_db.at[job.job_id, property] = val\n",
    "    \n",
    "    def release_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the release of the given job\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        job.time_release = current_time\n",
    "        job.is_released = True\n",
    "        self.update_job_db(job=job, property='release_date', val=job.time_release)\n",
    "    \n",
    "    def enter_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the start of the given job on the first Processing Station\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        # starting time processing\n",
    "        job.time_actual_starting = current_time\n",
    "        \n",
    "        # starting times\n",
    "        if job.time_planned_starting is not None:\n",
    "            job.starting_date_deviation = job.time_actual_starting - job.time_planned_starting\n",
    "            self.update_job_db(job=job, property='starting_date_deviation', val=job.starting_date_deviation)\n",
    "        \n",
    "        # update operation database\n",
    "        self.update_job_db(job=job, property='actual_starting_date', val=job.time_actual_starting)\n",
    "    \n",
    "    def finish_job(\n",
    "        self,\n",
    "        job: Job,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the exit of the given job\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        # [STATS]\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        #job.time_exit = current_time\n",
    "        job.time_actual_ending = current_time\n",
    "        job.is_finished = True\n",
    "        #job.lead_time = job.time_exit - job.time_release\n",
    "        job.lead_time = job.time_actual_ending - job.time_release\n",
    "        \n",
    "        # ending times\n",
    "        if job.time_planned_ending is not None:\n",
    "            job.ending_date_deviation = job.time_actual_ending - job.time_planned_ending\n",
    "            self.update_job_db(job=job, property='ending_date_deviation', val=job.ending_date_deviation)\n",
    "        \n",
    "        # update databases\n",
    "        self.update_job_state(job=job, state='FINISH')\n",
    "        #self.update_job_db(job=job, property='exit_date', val=job.time_exit)\n",
    "        self.update_job_db(job=job, property='actual_ending_date', val=job.time_actual_ending)\n",
    "        self.update_job_db(job=job, property='lead_time', val=job.lead_time)\n",
    "        # [MONITOR] finalise stats\n",
    "        job.stat_monitor.finalise_stats()\n",
    "    \n",
    "    def update_job_process_info(\n",
    "        self,\n",
    "        job: Job,\n",
    "        preprocess: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        method to write necessary information of the job and its current operation before and after processing,\n",
    "        invoked by Infrastructure Objects\n",
    "        \"\"\"\n",
    "        # get current operation of the job instance\n",
    "        current_op = job.current_op\n",
    "        # before processing\n",
    "        if preprocess:\n",
    "            # operation enters Processing Station\n",
    "            #self.release_operation(op=current_op)\n",
    "            \n",
    "            # if first operation if given job add job's starting information\n",
    "            if job.num_finished_ops == 0:\n",
    "                self.enter_job(job=job)\n",
    "            \n",
    "            self.enter_operation(op=current_op)\n",
    "            ############# ENTRY OF JOB\n",
    "            #current_op.start_time = self.env.now()\n",
    "        # after processing\n",
    "        else:\n",
    "            # finalise current op\n",
    "            #logger_dispatcher.debug(f\"OP {current_op} is finalised\")\n",
    "            self.finish_operation(op=current_op)\n",
    "            #current_op.finalise()\n",
    "            job.num_finished_ops += 1\n",
    "    \n",
    "    def update_job_state(\n",
    "        self,\n",
    "        job: Job,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a job in the job database\"\"\"\n",
    "        # update state tracking of the job instance\n",
    "        job.stat_monitor.set_state(state=state)\n",
    "        # update job database\n",
    "        self.update_job_db(job=job, property='state', val=state)\n",
    "        # only update operation state if it is not finished\n",
    "        # operations are finished by post-process call to their 'finalise' method\n",
    "        \n",
    "        # update state of the corresponding operation\n",
    "        if job.current_op is not None:\n",
    "            self.update_operation_state(op=job.current_op, state=state)\n",
    "    \n",
    "    def get_next_operation(\n",
    "        self,\n",
    "        job: Job,\n",
    "        ) -> Operation | None:\n",
    "        \"\"\"\n",
    "        get next operation of given job\n",
    "        \"\"\"\n",
    "        # last operation information\n",
    "        job.last_op = job.current_op\n",
    "        job.last_proc_time = job.current_proc_time\n",
    "        job.last_setup_time = job.current_setup_time\n",
    "        job.last_order_time = job.current_order_time\n",
    "        # current operation information\n",
    "        if job.open_operations:\n",
    "            op = job.open_operations.popleft()\n",
    "            job.current_proc_time = op.proc_time\n",
    "            job.current_setup_time = op.setup_time\n",
    "            job.current_order_time = op.order_time\n",
    "            # only reset job prio if there are OP-wise defined priorities\n",
    "            if job.op_wise_prio:\n",
    "                job.prio = op.prio # use setter function to catch possible errors\n",
    "                self.update_job_db(job=job, property='prio', val=job.prio)\n",
    "            if job.op_wise_starting_date:\n",
    "                job.time_planned_starting = op.time_planned_starting\n",
    "                self.update_job_db(job=job, property='planned_starting_date', val=job.time_planned_starting)\n",
    "            if job.op_wise_ending_date:\n",
    "                job.time_planned_ending = op.time_planned_ending\n",
    "                self.update_job_db(job=job, property='planned_ending_date', val=job.time_planned_ending)\n",
    "        else:\n",
    "            op = None\n",
    "            job.current_proc_time = None\n",
    "            job.current_setup_time = None\n",
    "            job.current_order_time = None\n",
    "        \n",
    "        job.current_op = op\n",
    "        \n",
    "        return op\n",
    "    \n",
    "    ### OPERATIONS ###\n",
    "    def register_operation(\n",
    "        self,\n",
    "        obj: Operation,\n",
    "        exec_system_identifier: CustomID,\n",
    "        target_station_group_identifier: CustomID | None,\n",
    "        custom_identifier: CustomID | None,\n",
    "        name: str | None,\n",
    "        state: str,\n",
    "    ) -> ObjectID:\n",
    "        \"\"\"\n",
    "        registers an operation object in the dispatcher instance by assigning an unique id and \n",
    "        adding the object to the associated operations\n",
    "        \n",
    "        obj: operation to register\n",
    "        machine_identifier: custom ID of the associated machine (user interface)\n",
    "        custom_identifier: custom identifier of the operation \n",
    "            (kept for consistency reasons, perhaps remove later)\n",
    "        name: assigned name the operation\n",
    "        status: for future features if status of operations is tracked\n",
    "        \n",
    "        outputs:\n",
    "        op_id: assigned operation ID\n",
    "        name: assigned name\n",
    "        machine: corresponding machine infrastructure object\n",
    "        \"\"\"\n",
    "        # infrastructure manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        \n",
    "        # obtain id\n",
    "        op_id = self._obtain_load_obj_id(load_type='op')\n",
    "        # time of creation\n",
    "        #creation_date = self.env.now()\n",
    "        creation_date = self.env.t_as_dt()\n",
    "        \n",
    "        # custom name\n",
    "        if name is None:\n",
    "            name = f'O_gen_{op_id}'\n",
    "            \n",
    "        # setup time\n",
    "        setup_time: float = 0.\n",
    "        if obj.setup_time is not None:\n",
    "            setup_time = obj.setup_time\n",
    "        \n",
    "        # corresponding execution system in which the operation is performed\n",
    "        # no pre-determined assignment of processing stations\n",
    "        global EXEC_SYSTEM_TYPE\n",
    "        exec_system = infstruct_mgr.lookup_subsystem_info(\n",
    "                                                    subsystem_type=EXEC_SYSTEM_TYPE,\n",
    "                                                    lookup_property='custom_id',\n",
    "                                                    lookup_val=exec_system_identifier)\n",
    "        # if target station group is specified, get instance\n",
    "        target_station_group: StationGroup | None = None\n",
    "        if target_station_group_identifier is not None:\n",
    "            target_station_group = infstruct_mgr.lookup_subsystem_info(\n",
    "                                                    subsystem_type='StationGroup',\n",
    "                                                    lookup_property='custom_id',\n",
    "                                                    lookup_val= target_station_group_identifier)\n",
    "            # validity check: only target stations allowed which are \n",
    "            # part of the current execution system\n",
    "            if target_station_group.system_id not in exec_system:\n",
    "                raise ValueError(f\"{target_station_group} is not part of {exec_system}. \\\n",
    "                    Mismatch between execution system and associated station groups.\")\n",
    "        \n",
    "        # new entry for operation data base\n",
    "        new_entry: DataFrame = pd.DataFrame({\n",
    "                                'op_id': [op_id],\n",
    "                                'job_id': [obj.job_id],\n",
    "                                'job_name': [obj.job.name()],\n",
    "                                'custom_id': [custom_identifier],\n",
    "                                'op': [obj],\n",
    "                                'name': [name],\n",
    "                                'prio': [obj.prio],\n",
    "                                'execution_system': [exec_system],\n",
    "                                'execution_system_custom_id': [exec_system.custom_identifier],\n",
    "                                'execution_system_name': [exec_system.name],\n",
    "                                'execution_system_type': [exec_system.subsystem_type],\n",
    "                                'target_station_custom_id': [None],\n",
    "                                'target_station_name': [None],\n",
    "                                'proc_time': [obj.proc_time],\n",
    "                                'setup_time': [setup_time],\n",
    "                                'order_time': [obj.order_time],\n",
    "                                'creation_date': [creation_date],\n",
    "                                'release_date': [obj.time_release],\n",
    "                                #'entry_date': [obj.time_entry],\n",
    "                                'planned_starting_date': [obj.time_planned_starting],\n",
    "                                'actual_starting_date': [obj.time_actual_starting],\n",
    "                                'starting_date_deviation': [obj.starting_date_deviation],\n",
    "                                #'exit_date': [obj.time_exit],\n",
    "                                'planned_ending_date': [obj.time_planned_ending],\n",
    "                                'actual_ending_date': [obj.time_actual_ending],\n",
    "                                'ending_date_deviation': [obj.ending_date_deviation],\n",
    "                                'lead_time': [obj.lead_time],\n",
    "                                'state': [state]})\n",
    "        new_entry: DataFrame = new_entry.astype(self._op_prop)\n",
    "        new_entry = new_entry.set_index('op_id')\n",
    "        self._op_db = pd.concat([self._op_db, new_entry])\n",
    "        \n",
    "        logger_dispatcher.info(f\"Successfully registered operation with OpID {op_id} and name {name}\")\n",
    "        \n",
    "        # write operation information directly\n",
    "        obj.name = name\n",
    "        obj.target_exec_system = exec_system\n",
    "        obj.target_station_group = target_station_group\n",
    "        obj.time_creation = creation_date\n",
    "        \n",
    "        # return operation ID\n",
    "        return op_id\n",
    "    \n",
    "    def update_operation_db(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        property: str,\n",
    "        val: float | str,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        updates the information of a job for a given property\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._op_update_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._op_update_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        self._op_db.at[op.op_id, property] = val\n",
    "    \n",
    "    def update_operation_state(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        state: str,\n",
    "    ) -> None:\n",
    "        \"\"\"method to update the state of a operation in the operation database\"\"\"\n",
    "        # update state tracking of the operation instance\n",
    "        op.stat_monitor.set_state(state=state)\n",
    "        # update operation database\n",
    "        self.update_operation_db(op=op, property='state', val=state)\n",
    "\n",
    "    def release_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "        target_station: ProcessingStation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the release of the given operation\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        # release time\n",
    "        op.time_release = current_time\n",
    "        op.is_released = True\n",
    "        # update operation database\n",
    "        # release date\n",
    "        self.update_operation_db(op=op, property='release_date', val=op.time_release)\n",
    "        # target station: custom identifier + name\n",
    "        self.update_operation_db(\n",
    "                    op=op, property='target_station_custom_id', \n",
    "                    val=target_station.custom_identifier)\n",
    "        self.update_operation_db(\n",
    "                    op=op, property='target_station_name', \n",
    "                    val=target_station.name())\n",
    "    \n",
    "    def enter_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the start of the given operation on a Processing Station\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        # starting time processing\n",
    "        #op.time_entry = current_time\n",
    "        op.time_actual_starting = current_time\n",
    "        \n",
    "        # starting times\n",
    "        if op.time_planned_starting is not None:\n",
    "            op.starting_date_deviation = op.time_actual_starting - op.time_planned_starting\n",
    "            self.update_operation_db(op=op, property='starting_date_deviation', val=op.starting_date_deviation)\n",
    "        \n",
    "        # update operation database\n",
    "        #self.update_operation_db(op=op, property='entry_date', val=op.time_entry)\n",
    "        self.update_operation_db(op=op, property='actual_starting_date', val=op.time_actual_starting)\n",
    "     \n",
    "    def finish_operation(\n",
    "        self,\n",
    "        op: Operation,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        used to signal the finalisation of the given operation\n",
    "        necessary for time statistics\n",
    "        \"\"\"\n",
    "        #current_time = self.env.now()\n",
    "        current_time = self.env.t_as_dt()\n",
    "        # [STATE] finished\n",
    "        op.is_finished = True\n",
    "        # [STATS] end + lead time\n",
    "        #op.time_exit = current_time\n",
    "        op.time_actual_ending = current_time\n",
    "        #op.lead_time = op.time_exit - op.time_release\n",
    "        op.lead_time = op.time_actual_ending - op.time_release\n",
    "        \n",
    "        # ending times\n",
    "        if op.time_planned_ending is not None:\n",
    "            op.ending_date_deviation = op.time_actual_ending - op.time_planned_ending\n",
    "            self.update_operation_db(op=op, property='ending_date_deviation', val=op.ending_date_deviation)\n",
    "        \n",
    "        # update databases\n",
    "        #logger_dispatcher.debug(f\"Update databases for OP {op} ID {op.op_id} with [{op.time_exit, op.lead_time}]\")\n",
    "        logger_dispatcher.debug(f\"Update databases for OP {op} ID {op.op_id} with [{op.time_actual_ending, op.lead_time}]\")\n",
    "        self.update_operation_state(op=op, state='FINISH')\n",
    "        #self.update_operation_db(op=op, property='exit_date', val=op.time_exit)\n",
    "        self.update_operation_db(op=op, property='actual_ending_date', val=op.time_actual_ending)\n",
    "        self.update_operation_db(op=op, property='lead_time', val=op.lead_time)\n",
    "        \n",
    "        # [MONITOR] finalise stats\n",
    "        op.stat_monitor.finalise_stats()\n",
    "    \n",
    "    ### PROPERTIES ###\n",
    "    @property\n",
    "    def job_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered jobs in the environment\n",
    "        \"\"\"\n",
    "        return self._job_db\n",
    "    \n",
    "    @property\n",
    "    def op_db(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        obtain a current overview of registered operations in the environment\n",
    "        \"\"\"\n",
    "        return self._op_db\n",
    "\n",
    "    #@lru_cache(maxsize=200)\n",
    "    def get_job_obj_by_prop(\n",
    "        self, \n",
    "        val: ObjectID | CustomID | str,\n",
    "        property: str = 'job_id',\n",
    "        target_prop: str = 'job',\n",
    "    ) -> Job:\n",
    "        \"\"\"\n",
    "        obtain a job object from the dispatcher by its property and corresponding value\n",
    "        properties: job_id, custom_id, name\n",
    "        \"\"\"\n",
    "        # check if property is a filter criterion\n",
    "        if property not in self._job_lookup_props:\n",
    "            raise IndexError(f\"Property '{property}' is not allowed. Choose from {self._job_lookup_props}\")\n",
    "        # None type value can not be looked for\n",
    "        if val is None:\n",
    "            raise TypeError(\"The lookup value can not be of type 'None'.\")\n",
    "        \n",
    "        # filter resource database for prop-value pair\n",
    "        if property == 'job_id':\n",
    "            # direct indexing for ID property; job_id always unique, no need for duplicate check\n",
    "            try:\n",
    "                temp1: Job = self._job_db.at[val, target_prop]\n",
    "                return temp1\n",
    "            except KeyError:\n",
    "                raise IndexError(f\"There were no jobs found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "        else:\n",
    "            temp1: Series = self._job_db.loc[self._job_db[property] == val, target_prop]\n",
    "            # check for empty search result, at least one result necessary\n",
    "            if len(temp1) == 0:\n",
    "                raise IndexError(f\"There were no jobs found for the property '{property}' \\\n",
    "                                with the value '{val}'\")\n",
    "            # check for multiple entries with same prop-value pair\n",
    "            ########### PERHAPS CHANGE NECESSARY\n",
    "            ### multiple entries but only one returned --> prone to errors\n",
    "            elif len(temp1) > 1:\n",
    "                # warn user\n",
    "                logger_dispatcher.warning(f\"CAUTION: There are multiple jobs which share the \\\n",
    "                            same value '{val}' for the property '{property}'. \\\n",
    "                            Only the first entry is returned.\")\n",
    "            \n",
    "            return temp1.iat[0]\n",
    "    \n",
    "    ### ROUTING LOGIC ###\n",
    "    \n",
    "    \n",
    "    def request_job_allocation(\n",
    "        self,\n",
    "        job: Job,\n",
    "        agent: bool,\n",
    "    ) -> InfrastructureObject:\n",
    "        \"\"\"\n",
    "        request an allocation decision for the given job \n",
    "        (determine the next processing station on which the job shall be placed)\n",
    "        \n",
    "        1. obtaining the target station group\n",
    "        2. select from target station group (e.g. calling RL agent for that group)\n",
    "        3. return target station (InfrastructureObject)\n",
    "        \n",
    "        requester: output side infrastructure object\n",
    "        request for: infrastructure object instance\n",
    "        \"\"\"\n",
    "        # SIGNALING ALLOCATION DECISION\n",
    "        # (ONLY IF PARALLEL PROCESSING STATIONS EXIST)\n",
    "        ## theoretically: obtaining next operation --> information about machine group -->\n",
    "        ## based on machine group: choice of corresponding allocation agent -->\n",
    "        ## preparing feature vectors as input --> trigger agent decision -->\n",
    "        ## map decision to processing station\n",
    "        \n",
    "        logger_dispatcher.info(f\"[DISPATCHER: {self}] REQUEST TO DISPATCHER FOR ALLOCATION\")\n",
    "        # set environment signal for ALLOCATION\n",
    "        self._env.set_dispatching_signal(sequencing=False, reset=False)\n",
    "        #self._env.main().activate()\n",
    "        #yield job.hold(0)\n",
    "        \n",
    "        ## REWORK: NEW TOP-DOWN-APPROACH\n",
    "        # routing of jobs is now organized in a hierarchical fashion and can be described\n",
    "        # for each hierarchy level separately\n",
    "        # routing in Production Areas --> Station Groups --> Processing Stations\n",
    "        # so each job must contain information about the production areas and the corresponding station groups\n",
    "        \n",
    "        ## choice from station group stays as method\n",
    "        # routing essentially depending on production areas --> JOB FROM AREA TO AREA\n",
    "        # NOW DIFFERENTIATE:\n",
    "        ### ~~(1) choice between station groups of the current area~~\n",
    "        #           placement on machines outside the station group not possible\n",
    "        ### (2) choice between processing stations of the current area\n",
    "        #           placement on machines outside the station group possible, \n",
    "        #           but the stations could be filtered by their station group IDs\n",
    "        ### --> (2) as implemented solution\n",
    "        \n",
    "        \n",
    "        # get the next operation of the job\n",
    "        #next_op = job.get_next_operation()\n",
    "        next_op = self.get_next_operation(job=job)\n",
    "        if next_op is not None:\n",
    "            # get target execution system ((sub)system type) (defined by the global variable EXEC_SYSTEM_TYPE)\n",
    "            target_exec_system = next_op.target_exec_system\n",
    "            # get target station group\n",
    "            target_station_group = next_op.target_station_group\n",
    "           \n",
    "            ##### PROCEDURE AGENT DECISION\n",
    "            # build feature vector of the target station collection + given job instance\n",
    "            # go into target station choice...\n",
    "            ### ADD OBTAINED TARGET STATION GROUP\n",
    "            logger_dispatcher.debug(f\"[DISPATCHER: {self}] Next operation {next_op}\")\n",
    "            target_station = self._choose_target_station_from_exec_system(\n",
    "                                            exec_system=target_exec_system,\n",
    "                                            job=job,\n",
    "                                            target_station_group=target_station_group)\n",
    "            # check feasibility of the target station\n",
    "            feasible = self._env.check_feasible_agent_alloc(\n",
    "                                            target_station=target_station,\n",
    "                                            op=next_op)\n",
    "            if not feasible:\n",
    "                raise RuntimeError((f\"The choosen {target_station} is not feasible \"\n",
    "                    f\"for {next_op}\"))\n",
    "            \n",
    "            # ADDITIONAL: check if more than one station possible\n",
    "            # check if agent available --> CHOICE METHOD\n",
    "            ## agent registration in corresponding system (prod_area: allocation, resource: sequencing)\n",
    "            # ...\n",
    "            \n",
    "            # with allocation request operation is released\n",
    "            self.release_operation(op=next_op, target_station=target_station)\n",
    "        # all operations done, look for sinks\n",
    "        else:\n",
    "            infstruct_mgr = self.env.infstruct_mgr\n",
    "            sinks = infstruct_mgr.sinks\n",
    "            # [PERHAPS CHANGE IN FUTURE]\n",
    "            # use first sink of the registered ones\n",
    "            target_station = sinks[0]\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] Next operation is {next_op} with machine group (machine) {target_station}\")\n",
    "        # reset environment signal for ALLOCATION\n",
    "        self._env.set_dispatching_signal(sequencing=False, reset=True)\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def _choose_target_station_from_exec_system(\n",
    "        self,\n",
    "        exec_system: System,\n",
    "        job: Job,\n",
    "        target_station_group: StationGroup | None = None,\n",
    "    ) -> ProcessingStation:\n",
    "        \"\"\"REWORK Choosing a target station from a given collection of processing stations\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stations : Iterable[ProcessingStation]\n",
    "            collection of processing stations from which the target station should be obtained\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ProcessingStation\n",
    "            station object on which the job should be placed\n",
    "        \"\"\"\n",
    "        # 3 options:\n",
    "        # (1) choice between processing stations of the current area\n",
    "        #       --> only agent\n",
    "        # (2) choice between station groups of the current area\n",
    "        #       --> [OPTIONAL] only agent\n",
    "        # (3) choice between processing stations of the current station group\n",
    "        #       --> other allocation rules: the chosen target station \n",
    "        #           automatically fulfils feasibility\n",
    "        \n",
    "        # obtain the lowest level systems (only ProcessingStations) of \n",
    "        # that area or station group\n",
    "        if target_station_group is not None and self._curr_alloc_rule != 'AGENT':\n",
    "            # preselection of station group only with allocation rules other than >>AGENT<<\n",
    "            stations = target_station_group.lowest_level_subsystems(only_processing_stations=True)\n",
    "        else:\n",
    "            # choose from whole production area (>>AGENT<< always)\n",
    "            stations = exec_system.lowest_level_subsystems(only_processing_stations=True)\n",
    "        \n",
    "        # infrastructure manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        # [KPIs] calculate necessary information for decision making\n",
    "        # put all associated processing stations of that group in 'TEMP' state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=stations, reset_temp=False)\n",
    "        \n",
    "        # available stations\n",
    "        ## AGENT can choose from all stations, not only available ones\n",
    "        ## availability of processing stations is checked in the feasibility method\n",
    "        if self._curr_alloc_rule != 'AGENT':\n",
    "            # choose only from available processing stations\n",
    "            candidates: list[ProcessingStation] = [ps for ps in stations if ps.stat_monitor.is_available]\n",
    "            # if there are no available ones: use all stations\n",
    "            if candidates:\n",
    "                avail_stations = candidates\n",
    "            else:\n",
    "                avail_stations = stations\n",
    "        else:\n",
    "            # check agent availability\n",
    "            exec_system.check_alloc_agent()\n",
    "            # get agent from execution system\n",
    "            agent = exec_system.alloc_agent\n",
    "            ### CALL BUILDING FEATURE VECTOR ###\n",
    "            # procedure:\n",
    "            # (0) Gym reset (startup phase)\n",
    "            # (1) build feature vector [in this branch]\n",
    "            # (2) pause simulation run (by creating an conditional loop)\n",
    "            # (3) send observation / built feature vector \n",
    "            #     to Gym-Env (through agent property --> 'feat_vec')\n",
    "            #     call: internal or external?\n",
    "            # (4) get agent decision from Gym-Env (call to step function)\n",
    "            # (5) write decision back to agent as property\n",
    "            # (6) continue simulation with written action (should resume in this branch)\n",
    "            # (7) in same time step:\n",
    "            # (7.1) check feasible action\n",
    "            # (7.2) calculate reward (implemented in agent)\n",
    "            # (7.3) jump to (1) and use this feature vector as observation at (2)\n",
    "            \n",
    "            # indicate that request is being done\n",
    "            # must be blocking\n",
    "            agent.request_decision(disposable_job=job)\n",
    "            #agent.activate()\n",
    "            \n",
    "            # main problem:\n",
    "            # execution flow is not interrupted in salabim, thus program\n",
    "            # execution continues --> env.step() method only finalises if next event is reached\n",
    "            # to use salabim's internal handling the creation of an event is necessary, which is\n",
    "            # only possible by using salabim's modelling techniques\n",
    "            # problem: techniques can be used solely by salabim components\n",
    "            \n",
    "            # possible solution: use modelling flow before dispatcher call, placeholder: self.hold(0)\n",
    "            # tested execution flow with hold(0): creates events at the same point in time\n",
    "            # --> idea:\n",
    "            # call dispatcher method to evaluate allocation rule -> ret: True (agent) False (otherwise)\n",
    "            # if agent: set flags and build feature vector\n",
    "            # yield self.hold(0) from calling component\n",
    "            # env.step() should stop after execution of flag setting at point self.hold(0)\n",
    "            # which allows the external loop to terminate and trigger an agent decision\n",
    "            ## decision saved in agent properties\n",
    "            # resume execution: should finally obtain the target station object ('request_job_allocation')\n",
    "            ## standard way if no agent decision, otherwise use agent properties\n",
    "            \n",
    "            # inside method: set flags, build feature vector\n",
    "            # agent obtains associated stations by the connected ProductionArea and its subsystems\n",
    "            #agent.build_feat_vec(disposable_job=job)\n",
    "            print(f'{agent.feat_vec=}')\n",
    "            #time.sleep(5)\n",
    "            while not agent.RL_decision_done:\n",
    "                # wait for agent decision\n",
    "                # when decision is done in Gym Env: communicate decision by\n",
    "                # calling agent's method 'set_decision'\n",
    "                \n",
    "                # SIMULATE ACTION CHOICE\n",
    "                # deterministic by user input\n",
    "                #stat_idx = input(\"Please enter a target station index:\")\n",
    "                #stat_idx = int(stat_idx)\n",
    "                # random\n",
    "                stat_idx = self.np_rnd_gen.integers(0,3)\n",
    "                \n",
    "                # set agent decision\n",
    "                agent.set_decision(action=stat_idx)\n",
    "                \n",
    "                #pass\n",
    "            \n",
    "            \n",
    "            # stop simulation at this point\n",
    "            #self._env.main().activate()\n",
    "            \n",
    "            #   --> implement in agent class\n",
    "            #logger_dispatcher.debug(f\"[DISPATCHER: {self}] Build feature vector for allocation agent {agent}\")\n",
    "            # TEST ONLY: make tuple out of all stations\n",
    "            # all stations are available\n",
    "            # stations separately not necessary because agent already has information about associated target resources\n",
    "            avail_stations = tuple(stations)\n",
    "            # LATER: generation in dedicated method to build feature vector\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] Available stations at {self.env.now()} are {avail_stations}\")\n",
    "        \n",
    "        # apply different strategies to select a station out of the station group\n",
    "        match self._curr_alloc_rule:\n",
    "            case 'RANDOM':\n",
    "                # [RANDOM CHOICE]\n",
    "                target_station: ProcessingStation = random.choice(avail_stations)\n",
    "            case 'UTILISATION':\n",
    "                # [UTILISATION]\n",
    "                # choose the station with the lowest utilisation to time\n",
    "                target_station: ProcessingStation = min(avail_stations, key=attrgetter('stat_monitor.utilisation'))\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] Utilisation of {target_station=} is {target_station.stat_monitor.utilisation:.4f}\")\n",
    "            case 'WIP_LOAD_TIME':\n",
    "                # WIP as load/processing time, choose station with lowest WIP\n",
    "                target_station: ProcessingStation = min(avail_stations, key=attrgetter('stat_monitor.WIP_load_time'))\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD TIME of {target_station=} is {target_station.stat_monitor.WIP_load_time}\")\n",
    "            case 'WIP_LOAD_JOBS':\n",
    "                # WIP as number of associated jobs, choose station with lowest WIP\n",
    "                target_station: ProcessingStation = min(avail_stations, key=attrgetter('stat_monitor.WIP_load_num_jobs'))\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD NUM JOBS of {target_station=} is {target_station.stat_monitor.WIP_load_time:.2f}\")\n",
    "            case 'AGENT':\n",
    "                # request decision with previously built feature vector\n",
    "                # get index value for target station out of tuple\n",
    "                # [ONLY TEST] simulate agent decision by user input\n",
    "                # only if more than one station\n",
    "                \"\"\"\n",
    "                if len(avail_stations) > 1:\n",
    "                    pprint(f\"The available stations are:\\n {avail_stations}\")\n",
    "                    #stat_idx = input(\"Please enter a target station index:\")\n",
    "                    #stat_idx = int(stat_idx)\n",
    "                    stat_idx = agent.action\n",
    "                    target_station = avail_stations[stat_idx]\n",
    "                else:\n",
    "                    target_station = avail_stations[0]\n",
    "                \"\"\"\n",
    "                stat_idx = agent.action\n",
    "                target_station = avail_stations[stat_idx]\n",
    "                \n",
    "        # feasibility check in the request job allocation method after the target station is returned\n",
    "        \n",
    "        # [KPIs] reset all associated processing stations of that group to their original state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=stations, reset_temp=True)\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def _choose_target_station_from_collection(\n",
    "        self,\n",
    "        stations: Iterable[ProcessingStation],\n",
    "    ) -> ProcessingStation:\n",
    "        \"\"\"Choosing a target station from a given collection of processing stations\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stations : Iterable[ProcessingStation]\n",
    "            collection of processing stations from which the target station should be obtained\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ProcessingStation\n",
    "            station object on which the job should be placed\n",
    "        \"\"\"\n",
    "        \n",
    "        # infrastructure manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        \n",
    "        # [KPIs] calculate necessary information for decision making\n",
    "        # put all associated processing stations of that group in 'TEMP' state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=stations, reset_temp=False)\n",
    "        \n",
    "        # choose only from available processing stations\n",
    "        candidates = [ps for ps in stations if ps.stat_monitor.is_available]\n",
    "        # check if there are available processing stations\n",
    "        # if not: use all stations\n",
    "        if candidates:\n",
    "            avail_stations = candidates\n",
    "        else:\n",
    "            avail_stations = stations\n",
    "        \n",
    "        logger_dispatcher.debug(f\"[DISPATCHER: {self}] Available stations at {self.env.now()} are {avail_stations}\")\n",
    "        \n",
    "        # apply different strategies to select a station out of the station group\n",
    "        match self._curr_alloc_rule:\n",
    "            case 'RANDOM':\n",
    "                # [RANDOM CHOICE]\n",
    "                target_station: ProcessingStation = random.choice(avail_stations)\n",
    "            case 'UTILISATION':\n",
    "                # [UTILISATION]\n",
    "                # choose the station with the lowest utilisation to time\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.utilisation'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] Utilisation of {target_station=} is {target_station.stat_monitor.utilisation:.4f}\")\n",
    "            case 'WIP_LOAD_TIME':\n",
    "                # WIP as load/processing time, choose station with lowest WIP\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.WIP_load_time'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD TIME of {target_station=} is {target_station.stat_monitor.WIP_load_time:.2f}\")\n",
    "            case 'WIP_LOAD_JOBS':\n",
    "                # WIP as number of associated jobs, choose station with lowest WIP\n",
    "                temp = sorted(avail_stations, key=attrgetter('stat_monitor.WIP_load_num_jobs'), reverse=True)\n",
    "                target_station: ProcessingStation = temp.pop()\n",
    "                logger_dispatcher.debug(f\"[DISPATCHER: {self}] WIP LOAD NUM JOBS of {target_station=} is {target_station.stat_monitor.WIP_load_time:.2f}\")\n",
    "            case 'AGENT':\n",
    "                # CHECK: agent available\n",
    "                pass\n",
    "        \n",
    "        # [KPIs] reset all associated processing stations of that group to their original state\n",
    "        infstruct_mgr.res_objs_temp_state(res_objs=stations, reset_temp=True)\n",
    "        \n",
    "        return target_station\n",
    "    \n",
    "    def request_job_sequencing(\n",
    "        self,\n",
    "        req_obj: ProcessingStation,\n",
    "    ) -> tuple[Job, float, float]:\n",
    "        \"\"\"\n",
    "        request a sequencing decision for a given queue of the requesting resource\n",
    "        requester: input side processing stations\n",
    "        request for: job instance\n",
    "        \n",
    "        req_obj: requesting object (ProcessingStation)\n",
    "        \"\"\"\n",
    "        # SIGNALING SEQUENCING DECISION\n",
    "        # (ONLY IF MULTIPLE JOBS IN THE QUEUE EXIST)\n",
    "        ## theoretically: get logic queue of requesting object --> information about feasible jobs -->\n",
    "        ## [*] choice of sequencing agent (based on which properties?) --> preparing feature vector as input -->\n",
    "        ## trigger agent decision --> map decision to feasible jobs\n",
    "        ## [*] use implemented priority rules as intermediate step\n",
    "        \n",
    "        logger_dispatcher.info(f\"[DISPATCHER: {self}] REQUEST TO DISPATCHER FOR SEQUENCING\")\n",
    "        # set environment signal for SEQUENCING\n",
    "        self._env.set_dispatching_signal(sequencing=True, reset=False)\n",
    "        \n",
    "        # get logic queue of requesting object\n",
    "        # contains all feasible jobs for this resource\n",
    "        logic_queue = req_obj.logic_queue\n",
    "        # get job from logic queue with currently defined priority rule\n",
    "        job = self.seq_priority_rule(queue=logic_queue)\n",
    "        # reset environment signal for SEQUENCING\n",
    "        self._env.set_dispatching_signal(sequencing=True, reset=True)\n",
    "        \n",
    "        return job, job.current_proc_time, job.current_setup_time\n",
    "    \n",
    "    def seq_priority_rule(\n",
    "        self,\n",
    "        queue: Queue,\n",
    "    ) -> Job:\n",
    "        \"\"\"apply priority rules to a pool of jobs\"\"\"\n",
    "        match self._curr_prio_rule:\n",
    "            # first in, first out\n",
    "            case 'FIFO':\n",
    "                # salabim queue pops first entry if no index is specified, \n",
    "                # not last like in Python\n",
    "                job = queue.pop()\n",
    "            # last in, last out\n",
    "            case 'LIFO':\n",
    "                # salabim queue pops first entry if no index is specified, \n",
    "                # not last like in Python\n",
    "                job = queue.pop(-1)\n",
    "            # shortest processing time\n",
    "            case 'SPT':\n",
    "                # choose job with shortest processing time\n",
    "                temp = queue.as_list()\n",
    "                job: Job = min(temp, key=attrgetter('current_proc_time'))\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "            # longest processing time\n",
    "            case 'LPT':\n",
    "                # choose job with longest processing time\n",
    "                temp = queue.as_list()\n",
    "                job: Job = max(temp, key=attrgetter('current_proc_time'))\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "            # shortest setup time\n",
    "            case 'SST':\n",
    "                # choose job with shortest setup time\n",
    "                temp = queue.as_list()\n",
    "                job: Job = min(temp, key=attrgetter('current_setup_time'))\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "            # longest setup time\n",
    "            case 'LST':\n",
    "                # choose job with longest setup time\n",
    "                temp = queue.as_list()\n",
    "                job: Job = max(temp, key=attrgetter('current_setup_time'))\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "            case 'PRIO':\n",
    "                # choose job with highest priority\n",
    "                temp = queue.as_list()\n",
    "                job: Job = max(temp, key=attrgetter('prio'))\n",
    "                # remove job from original queue\n",
    "                queue.remove(job)\n",
    "        \n",
    "        return job\n",
    "    \n",
    "    ### ANALYSE ###\n",
    "    def draw_gantt_chart(\n",
    "        self,\n",
    "        use_custom_proc_station_id: bool = True,\n",
    "        sort_by_proc_station: bool = False,\n",
    "        sort_ascending: bool = True,\n",
    "        group_by_exec_system: bool = False,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'gantt_chart',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        draw a Gantt chart based on the dispatcher's operation database\n",
    "        use_custom_machine_id: whether to use the custom IDs of the processing station (True) or its name (False)\n",
    "        sort_by_proc_station: whether to sort by processing station property (True) or by job name (False) \\\n",
    "            default: False\n",
    "        sort_ascending: whether to sort in ascending (True) or descending order (False) \\\n",
    "            default: True\n",
    "        use_duration: plot each operation with its scheduled duration instead of the delta time \\\n",
    "            between start and end; if there were no interruptions both methods return the same results \\\n",
    "            default: False\n",
    "        \"\"\"\n",
    "        # filter operation DB for relevant information\n",
    "        filter_items: list[str] = [\n",
    "            'job_name',\n",
    "            'target_station_custom_id',\n",
    "            'target_station_name',\n",
    "            'execution_system',\n",
    "            'execution_system_custom_id',\n",
    "            'prio',\n",
    "            #'entry_date',\n",
    "            'planned_starting_date',\n",
    "            'actual_starting_date',\n",
    "            #'exit_date',\n",
    "            'planned_ending_date',\n",
    "            'actual_ending_date',\n",
    "            'proc_time',\n",
    "            'setup_time',\n",
    "            'order_time',\n",
    "        ]\n",
    "        \n",
    "        hover_data: dict[str, str | bool] = {\n",
    "            'job_name': False,\n",
    "            'target_station_custom_id': True,\n",
    "            'execution_system_custom_id': True,\n",
    "            'prio': True,\n",
    "            #'entry_date': True,\n",
    "            'planned_starting_date': True,\n",
    "            'actual_starting_date': True,\n",
    "            #'exit_date': True,\n",
    "            'planned_ending_date': True,\n",
    "            'actual_ending_date': True,\n",
    "            'proc_time': True,\n",
    "            'setup_time': True,\n",
    "            'order_time': True,\n",
    "        }\n",
    "        \n",
    "        #hover_template: str = \"proc_time: %{proc_time|%d:%H:%M:%S}\"\n",
    "        \n",
    "        df = self._op_db.filter(items=filter_items)\n",
    "        # calculate delta time between start and end\n",
    "        # Timedelta\n",
    "        #df['delta'] = df['exit_date'] - df['entry_date']\n",
    "        df['delta'] = df['actual_ending_date'] - df['actual_starting_date']\n",
    "        \n",
    "        # sorting\n",
    "        sort_key: str = ''\n",
    "        # choose relevant processing station property\n",
    "        proc_station_prop: str = ''\n",
    "        if use_custom_proc_station_id:\n",
    "            proc_station_prop = 'target_station_custom_id'\n",
    "        else:\n",
    "            proc_station_prop = 'target_station_name'\n",
    "        \n",
    "        # check if sorting by processing station is wanted and custom ID should be used or not\n",
    "        if sort_by_proc_station:\n",
    "            sort_key = proc_station_prop\n",
    "        else:\n",
    "            sort_key = 'job_name' \n",
    "        \n",
    "        df = df.sort_values(by=sort_key, ascending=sort_ascending, kind='stable')\n",
    "        \n",
    "        # group by value\n",
    "        if group_by_exec_system:\n",
    "            group_by_key = 'execution_system_custom_id'\n",
    "        else:\n",
    "            group_by_key = 'job_name'\n",
    "        \n",
    "        # build Gantt chart with Plotly Timeline\n",
    "        fig: PlotlyFigure = px.timeline(\n",
    "            df, \n",
    "            #x_start='entry_date',\n",
    "            x_start='actual_starting_date',\n",
    "            #x_end='exit_date',\n",
    "            x_end='actual_ending_date',\n",
    "            y=proc_station_prop, \n",
    "            color=group_by_key,\n",
    "            hover_name='job_name',\n",
    "            hover_data=hover_data,\n",
    "        )\n",
    "        fig.update_yaxes(type='category', autorange='reversed')\n",
    "        #fig.update_traces(hovertemplate=hover_template)\n",
    "        \n",
    "        \"\"\"\n",
    "        fig.update_xaxes(type='linear')\n",
    "\n",
    "        # reset axis scale for every figure element\n",
    "        # https://stackoverflow.com/questions/66078893/plotly-express-timeline-for-gantt-chart-with-integer-xaxis\n",
    "        for d in fig.data:\n",
    "            try:\n",
    "                # convert to integer if property is of that type in the database\n",
    "                filt_val = int(d.name)\n",
    "            except ValueError:\n",
    "                filt_val = d.name\n",
    "            filt = df[group_by_key] == filt_val\n",
    "            d.x = df.loc[filt, 'delta']\n",
    "        \"\"\"\n",
    "\n",
    "        fig.show()\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def draw_gantt_chart_old(\n",
    "        self,\n",
    "        use_custom_proc_station_id: bool = True,\n",
    "        sort_by_proc_station: bool = False,\n",
    "        sort_ascending: bool = True,\n",
    "        group_by_exec_system: bool = False,\n",
    "        save_img: bool = False,\n",
    "        save_html: bool = False,\n",
    "        file_name: str = 'gantt_chart',\n",
    "    ) -> PlotlyFigure:\n",
    "        \"\"\"\n",
    "        draw a Gantt chart based on the dispatcher's operation database\n",
    "        use_custom_machine_id: whether to use the custom IDs of the processing station (True) or its name (False)\n",
    "        sort_by_proc_station: whether to sort by processing station property (True) or by job name (False) \\\n",
    "            default: False\n",
    "        sort_ascending: whether to sort in ascending (True) or descending order (False) \\\n",
    "            default: True\n",
    "        use_duration: plot each operation with its scheduled duration instead of the delta time \\\n",
    "            between start and end; if there were no interruptions both methods return the same results \\\n",
    "            default: False\n",
    "        \"\"\"\n",
    "        # filter operation DB for relevant information\n",
    "        filter_items: list[str] = [\n",
    "            'job_name',\n",
    "            'target_station_custom_id',\n",
    "            'target_station_name',\n",
    "            'execution_system',\n",
    "            'execution_system_custom_id',\n",
    "            'prio',\n",
    "            'entry_date',\n",
    "            'exit_date',\n",
    "            'proc_time',\n",
    "            'setup_time',\n",
    "            'order_time',\n",
    "        ]\n",
    "        \n",
    "        hover_data: dict[str, str | bool] = {\n",
    "            'job_name': False,\n",
    "            'target_station_custom_id': True,\n",
    "            'execution_system_custom_id': True,\n",
    "            'prio': True,\n",
    "            'entry_date': True,\n",
    "            'exit_date': True,\n",
    "            'proc_time': True,\n",
    "            'setup_time': True,\n",
    "            'order_time': True,\n",
    "        }\n",
    "        \n",
    "        df = self._op_db.filter(items=filter_items)\n",
    "        # calculate delta time between start and end\n",
    "        # Timedelta\n",
    "        df['delta'] = df['exit_date'] - df['entry_date']\n",
    "        \n",
    "        # sorting\n",
    "        sort_key: str = ''\n",
    "        # choose relevant processing station property\n",
    "        proc_station_prop: str = ''\n",
    "        if use_custom_proc_station_id:\n",
    "            proc_station_prop = 'target_station_custom_id'\n",
    "        else:\n",
    "            proc_station_prop = 'target_station_name'\n",
    "        \n",
    "        # check if sorting by processing station is wanted and custom ID should be used or not\n",
    "        if sort_by_proc_station:\n",
    "            sort_key = proc_station_prop\n",
    "        else:\n",
    "            sort_key = 'job_name' \n",
    "        \n",
    "        df = df.sort_values(by=sort_key, ascending=sort_ascending, kind='stable')\n",
    "        \n",
    "        # group by value\n",
    "        if group_by_exec_system:\n",
    "            group_by_key = 'execution_system_custom_id'\n",
    "        else:\n",
    "            group_by_key = 'job_name'\n",
    "        \n",
    "        # build Gantt chart with Plotly Timeline\n",
    "        fig: PlotlyFigure = px.timeline(\n",
    "            df, \n",
    "            x_start='entry_date', \n",
    "            x_end='exit_date', \n",
    "            y=proc_station_prop, \n",
    "            color=group_by_key,\n",
    "            hover_name='job_name',\n",
    "            hover_data=hover_data,\n",
    "        )\n",
    "        fig.update_yaxes(type='category', autorange='reversed')\n",
    "        fig.update_xaxes(type='linear')\n",
    "\n",
    "        # reset axis scale for every figure element\n",
    "        # https://stackoverflow.com/questions/66078893/plotly-express-timeline-for-gantt-chart-with-integer-xaxis\n",
    "        for d in fig.data:\n",
    "            try:\n",
    "                # convert to integer if property is of that type in the database\n",
    "                filt_val = int(d.name)\n",
    "            except ValueError:\n",
    "                filt_val = d.name\n",
    "            filt = df[group_by_key] == filt_val\n",
    "            d.x = df.loc[filt, 'delta']\n",
    "\n",
    "        fig.show()\n",
    "        \n",
    "        if save_html:\n",
    "            file = f'{file_name}.html'\n",
    "            fig.write_html(file)\n",
    "        \n",
    "        if save_img:\n",
    "            file = f'{file_name}.svg'\n",
    "            fig.write_image(file)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def finalise(self) -> None:\n",
    "        \"\"\"\n",
    "        method to be called at the end of the simulation run by \n",
    "        the environment's \"finalise_sim\" method\n",
    "        \"\"\"\n",
    "        self._calc_cycle_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feasibility Check of Agent decisions**\n",
    "\n",
    "- some agent decisions are sampled, particularly at the beginning of training procedure\n",
    "- non-feasible actions possible --> check/evaluation by program\n",
    "- check necessary for reward calculation\n",
    "\n",
    "*technology:*\n",
    "- some jobs can only be performed on specific machines\n",
    "- way to define technological capabilities\n",
    "- examples:\n",
    "    - by station groups:\n",
    "        - job has **one** station group assigned --> only this station group is allowed, *other choices are not feasible* --> **technological feasibility automatically described**\n",
    "        - job has **one** station group assigned --> this group is *recommendation*, other groups in the area are automatically allowed\n",
    "        - job has **multiple** station groups assigned with **one** preference --> multiple stations are allowed, but also planning value which *should* be used --> **technological feasibility automatically described, enhanced description**\n",
    "- caveats:\n",
    "    - by station group:\n",
    "        - **only one allowed**: performance metrics (agent reward) depend on job mix; job mix which favours one station group lowers utilisation of others\n",
    "        - ~~**only one as recommendation**: all other machines possible, other information about technological restrictions necessary~~ --> **too complicated**\n",
    "        - **multiple groups allowed**: differing reward designs for recommended groups and alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change ``machine_identifier`` to ``station_group_identifier``\n",
    "- ``target_machine`` to ``target_station_group``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        job: Job,\n",
    "        exec_system_identifier: CustomID,\n",
    "        proc_time: Timedelta,\n",
    "        setup_time: Timedelta | None = None,\n",
    "        target_station_group_identifier: CustomID | None = None,\n",
    "        prio: int | None = None,\n",
    "        planned_starting_date: Datetime | None = None,\n",
    "        planned_ending_date: Datetime | None = None,\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'WAITING',\n",
    "            'SETUP',\n",
    "            'PROCESSING',\n",
    "            'BLOCKED',\n",
    "            'FAILED',\n",
    "            'PAUSED',\n",
    "        ),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ADD DESCRIPTION\n",
    "        \"\"\"\n",
    "        # !!!!!!!!! perhaps processing times in future multiple entries depending on associated machine\n",
    "        # change of input format necessary, currently only one machine for each operation\n",
    "        # no differing processing times for different machines or groups\n",
    "        \n",
    "        # initialise parent class if available\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # assert operation information\n",
    "        self._dispatcher = dispatcher\n",
    "        self._job = job\n",
    "        self._job_id = job.job_id\n",
    "        self._exec_system_identifier = exec_system_identifier\n",
    "        self._target_station_group_identifier = target_station_group_identifier\n",
    "        \n",
    "        # [STATS] Monitoring\n",
    "        self._stat_monitor = Monitor(env=self._dispatcher.env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # process information\n",
    "        # [STATS]\n",
    "        # time characteristics\n",
    "        self.proc_time = proc_time\n",
    "        self.setup_time = setup_time\n",
    "        if self.setup_time is not None:\n",
    "            self.order_time = self.proc_time + self.setup_time\n",
    "        else:\n",
    "            self.order_time = self.proc_time\n",
    "        # inter-process time characteristics\n",
    "        # time of release\n",
    "        #self.time_release: float = 0.\n",
    "        self.time_release: Datetime = Datetime.min\n",
    "        # time of first operation starting point\n",
    "        self.time_actual_starting: Datetime = Datetime.min\n",
    "        # starting date deviation\n",
    "        self.starting_date_deviation: Timedelta | None = None\n",
    "        # time of last operation ending point\n",
    "        self.time_actual_ending: Datetime = Datetime.min\n",
    "        # ending date deviation\n",
    "        self.ending_date_deviation: Timedelta | None = None\n",
    "        # lead time\n",
    "        #self.lead_time: float = 0.\n",
    "        self.lead_time: Datetime = Datetime.min\n",
    "        # starting and end dates\n",
    "        self.time_planned_starting = planned_starting_date\n",
    "        self.time_planned_ending = planned_ending_date\n",
    "        # in future setting starting points in advance possible\n",
    "        self.is_finished: bool = False\n",
    "        self.is_released: bool = False\n",
    "        # priority, default: -1 --> no prio set\n",
    "        self._prio = prio\n",
    "        \n",
    "        ########### adding machine instances\n",
    "        ### perhaps adding machine sets if multiple machines possible (machine groups)\n",
    "        # assignment of machine instance by dispatcher\n",
    "        # from dispatcher: op_id, name, target_machine\n",
    "        # register operation instance\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        \n",
    "        # REWORK: only return OpID, other properties directly written by dispatcher method\n",
    "        # add target station group by station group identifier\n",
    "        self.name: str | None = None\n",
    "        self.target_exec_system: System | None = None\n",
    "        self.target_station_group: StationGroup | None = None\n",
    "        self.time_creation: Datetime | None = None\n",
    "        \n",
    "        self._op_id = self.dispatcher.register_operation(\n",
    "                                        obj=self, \n",
    "                                        exec_system_identifier=self._exec_system_identifier,\n",
    "                                        target_station_group_identifier=target_station_group_identifier,\n",
    "                                        custom_identifier=custom_identifier, name=name, \n",
    "                                        state=current_state)\n",
    "        \n",
    "        \"\"\"\n",
    "        (self._op_id, self.name,\n",
    "         self.target_exec_system,\n",
    "         self.time_creation) = self.dispatcher.register_operation(\n",
    "                                                        obj=self, \n",
    "                                                        exec_system_identifier=self._exec_system_identifier,\n",
    "                                                        custom_identifier=custom_identifier, name=name, \n",
    "                                                        state=current_state)\n",
    "        \"\"\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return (f'Operation(ProcTime: {self.proc_time}, ExecutionSystemID: {self._exec_system_identifier}, '\n",
    "                f'SGI: {self._target_station_group_identifier})')    \n",
    "    \n",
    "    @property   \n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    @property\n",
    "    def op_id(self) -> ObjectID:\n",
    "        return self._op_id\n",
    "    \n",
    "    @property\n",
    "    def job(self) -> Job:\n",
    "        return self._job\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> ObjectID:\n",
    "        return self._job_id\n",
    "    \n",
    "    @property\n",
    "    def exec_system_identifier(self) -> CustomID:\n",
    "        return self._exec_system_identifier\n",
    "    \n",
    "    @property\n",
    "    def target_station_group_identifier(self) -> CustomID | None:\n",
    "        return self._target_station_group_identifier\n",
    "    \n",
    "    @property\n",
    "    def prio(self) -> int:\n",
    "        return self._prio\n",
    "    \n",
    "    @prio.setter\n",
    "    def prio(\n",
    "        self,\n",
    "        new_prio: int,\n",
    "    ) -> None:\n",
    "        \"\"\"setting of priority\n",
    "        prio can be initialized as None, \n",
    "        but every change has to be an integer value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_prio : int\n",
    "            new priority which should be set\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            if other types are provided\n",
    "        \"\"\"\n",
    "        if not isinstance(new_prio, int):\n",
    "            raise TypeError((f\"The type of {new_prio} must be >>int<<, but \"\n",
    "                             f\"it is {type(new_prio)}\"))\n",
    "        else:\n",
    "            self._prio = new_prio\n",
    "            # REWORK changing OP prio must change job prio but only if op is job's current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Job(sim.Component):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dispatcher: Dispatcher,\n",
    "        exec_systems_order: Sequence[CustomID],\n",
    "        proc_times: Sequence[Timedelta],\n",
    "        target_stations_order: Sequence[CustomID | None] | None = None,\n",
    "        setup_times: Sequence[Timedelta | None] | None = None,\n",
    "        prio: int | Sequence[int] | None = None,\n",
    "        planned_starting_date: Datetime | Sequence[Datetime] | None = None,\n",
    "        planned_ending_date: Datetime | Sequence[Datetime] | None = None,\n",
    "        custom_identifier: CustomID | None = None,\n",
    "        name: str | None = None,\n",
    "        state: str = 'INIT',\n",
    "        possible_states: Iterable[str] = (\n",
    "            'INIT',\n",
    "            'FINISH',\n",
    "            'WAITING',\n",
    "            'SETUP',\n",
    "            'PROCESSING', \n",
    "            'BLOCKED', \n",
    "            'FAILED', \n",
    "            'PAUSED',\n",
    "        ),\n",
    "        additional_info: dict[str, CustomID] | None = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        ADD DESCRIPTION\n",
    "        \"\"\"\n",
    "        # add not provided information\n",
    "        # target station identifiers\n",
    "        #if target_stations_order is None:\n",
    "        if isinstance(target_stations_order, Sequence):\n",
    "            op_target_stations = target_stations_order\n",
    "        else:\n",
    "            op_target_stations: list[None] = [None] * len(exec_systems_order)\n",
    "        # setup times\n",
    "        if setup_times is None:\n",
    "            setup_times: list[None] = [None] * len(proc_times)\n",
    "        \n",
    "        # prio\n",
    "        self.op_wise_prio: bool = False\n",
    "        self._prio: int | None = None\n",
    "        if isinstance(prio, Sequence):\n",
    "            op_prios = prio\n",
    "            # job prio later set by 'get_next_operation' method\n",
    "            self.op_wise_prio = True\n",
    "        else:\n",
    "            # job priority applies to all operations\n",
    "            # priority, default: None --> no prio set\n",
    "            op_prios: list[None] = [None] * len(proc_times)\n",
    "            # set job priority as a whole\n",
    "            self._prio = prio\n",
    "        \n",
    "        # planned dates\n",
    "        self.op_wise_starting_date: bool = False\n",
    "        self.op_wise_ending_date: bool = False\n",
    "        self.time_planned_starting: Datetime | None = None\n",
    "        self.time_planned_ending: Datetime | None = None\n",
    "        if isinstance(planned_starting_date, Sequence):\n",
    "            # operation-wise defined starting dates\n",
    "            op_starting_dates = planned_starting_date\n",
    "            # job starting date later set by 'get_next_operation' method\n",
    "            self.op_starting_dates = True\n",
    "        else:\n",
    "            # only job-wise defined starting date\n",
    "            op_starting_dates: list[None] = [None] * len(proc_times)\n",
    "            self.time_planned_starting = planned_starting_date\n",
    "        if isinstance(planned_ending_date, Sequence):\n",
    "            # operation-wise defined starting dates\n",
    "            op_ending_dates = planned_ending_date\n",
    "            # job ending date later set by 'get_next_operation' method\n",
    "            self.op_wise_ending_date = True\n",
    "        else:\n",
    "            # only job-wise defined starting date\n",
    "            op_ending_dates: list[None] = [None] * len(proc_times)\n",
    "            self.time_planned_ending = planned_ending_date\n",
    "        \n",
    "        ### VALIDITY CHECK ###\n",
    "        # length of provided identifiers and lists must match\n",
    "        if len(target_stations_order) != len(exec_systems_order):\n",
    "            raise ValueError((\"The number of target stations must match \"\n",
    "                \"the number of execution systems.\"))\n",
    "        if len(proc_times) != len(exec_systems_order):\n",
    "            raise ValueError((\"The number of processing times must match \"\n",
    "                \"the number of execution systems.\"))\n",
    "        if len(setup_times) != len(proc_times):\n",
    "            raise ValueError((f\"The number of setup times must match \"\n",
    "                \"the number of processing times.\"))\n",
    "        if len(op_prios) != len(proc_times):\n",
    "            raise ValueError((\"The number of operation priorities must match \"\n",
    "                \"the number of processing times.\"))\n",
    "        if len(op_starting_dates) != len(proc_times):\n",
    "            raise ValueError((\"The number of operation starting dates must match \"\n",
    "                \"the number of processing times.\"))\n",
    "        if len(op_ending_dates) != len(proc_times):\n",
    "            raise ValueError((\"The number of operation ending dates must match \"\n",
    "                \"the number of processing times.\"))\n",
    "        \n",
    "        ### BASIC INFORMATION ###\n",
    "        # assert job information\n",
    "        self.custom_identifier = custom_identifier\n",
    "        self.job_type: str = 'Job'\n",
    "        self._dispatcher = dispatcher\n",
    "        # sum of the proc times of each operation\n",
    "        #self.total_proc_time: float = sum(proc_times)\n",
    "        self.total_proc_time: Timedelta = sum(proc_times, Timedelta())\n",
    "        \n",
    "        # inter-process job state parameters\n",
    "        # first operation scheduled --> released job\n",
    "        self.is_released: bool = False\n",
    "        # job's next operation is disposable\n",
    "        # true for each new job, maybe reworked in future for jobs with\n",
    "        # a start date later than creation date\n",
    "        self.is_disposable: bool = True\n",
    "        # add job to disposable ones\n",
    "        #ret = self.dispatcher.add_disposable_job(self)\n",
    "        # last operation ended --> finished job\n",
    "        self.is_finished: bool = False\n",
    "        \n",
    "        # inter-process time characteristics\n",
    "        # time of release\n",
    "        #self.time_release: float = 0.\n",
    "        self.time_release: Datetime = Datetime.min\n",
    "        # time of first operation starting point\n",
    "        self.time_actual_starting: Datetime = Datetime.min\n",
    "        # starting date deviation\n",
    "        self.starting_date_deviation: Timedelta | None = None\n",
    "        # time of last operation ending point\n",
    "        self.time_actual_ending: Datetime = Datetime.min\n",
    "        # ending date deviation\n",
    "        self.ending_date_deviation: Timedelta | None = None\n",
    "        # lead time\n",
    "        #self.lead_time: float = 0.\n",
    "        self.lead_time: Datetime = Datetime.min\n",
    "        # time of creation\n",
    "        #self.time_creation: float = 0.\n",
    "        self.time_creation: Datetime = Datetime.min\n",
    "        \n",
    "        # current resource location\n",
    "        self._current_resource: InfrastructureObject | None = None\n",
    "        \n",
    "        # [STATS] Monitoring\n",
    "        self._stat_monitor = Monitor(env=self._dispatcher.env, obj=self, init_state=state, \n",
    "                                possible_states=possible_states, **kwargs)\n",
    "        \n",
    "        # register job instance\n",
    "        current_state = self._stat_monitor.get_current_state()\n",
    "        \n",
    "        env, self._job_id, name = self._dispatcher.register_job(\n",
    "                                                    obj=self, custom_identifier=self.custom_identifier,\n",
    "                                                    name=name, state=current_state)\n",
    "        \n",
    "        # intialize base class\n",
    "        super().__init__(env=env, name=name, process='', **kwargs)\n",
    "        \n",
    "        ### OPERATIONS ##\n",
    "        self.operations: deque[Operation] = deque()\n",
    "        \n",
    "        for idx, op_proc_time in enumerate(proc_times):\n",
    "            op = Operation(\n",
    "                dispatcher=self._dispatcher,\n",
    "                job=self,\n",
    "                proc_time=op_proc_time,\n",
    "                setup_time=setup_times[idx],\n",
    "                exec_system_identifier=exec_systems_order[idx],\n",
    "                target_station_group_identifier=op_target_stations[idx],\n",
    "                prio=op_prios[idx],\n",
    "                planned_starting_date=op_starting_dates[idx],\n",
    "                planned_ending_date=op_ending_dates[idx],\n",
    "            )\n",
    "            self.operations.append(op)\n",
    "        \n",
    "        self.open_operations = self.operations.copy()\n",
    "        self.total_num_ops: int = len(self.operations)\n",
    "        self.num_finished_ops: int = 0\n",
    "        # current and last OP: properties set by method \"get_next_operation\"\n",
    "        \"\"\"\n",
    "        self._last_op: Operation | None = None\n",
    "        self._last_proc_time: Timedelta | None = None\n",
    "        self._last_setup_time: Timedelta | None = None\n",
    "        self._last_order_time: Timedelta | None = None\n",
    "        self._current_op: Operation | None = None\n",
    "        self._current_proc_time: Timedelta | None = None\n",
    "        self._current_setup_time: Timedelta | None = None\n",
    "        self._current_order_time: Timedelta | None = None\n",
    "        \"\"\"\n",
    "        self.last_op: Operation | None = None\n",
    "        self.last_proc_time: Timedelta | None = None\n",
    "        self.last_setup_time: Timedelta | None = None\n",
    "        self.last_order_time: Timedelta | None = None\n",
    "        self.current_op: Operation | None = None\n",
    "        self.current_proc_time: Timedelta | None = None\n",
    "        self.current_setup_time: Timedelta | None = None\n",
    "        self.current_order_time: Timedelta | None = None\n",
    "        \n",
    "        # ------- NOT IMPLEMENTED YET -------\n",
    "        # rank-like property, set if job enters the infrastructure object\n",
    "        # acts like a counter to allow easy sorting even if queue order is not maintained\n",
    "        self._obj_entry_idx: int | None = None\n",
    "        \n",
    "        ### ADDITIONAL INFORMATION ###\n",
    "        self.additional_info = additional_info\n",
    "    \n",
    "    @property\n",
    "    def dispatcher(self) -> Dispatcher:\n",
    "        return self._dispatcher\n",
    "    \n",
    "    @property\n",
    "    def stat_monitor(self) -> Monitor:\n",
    "        return self._stat_monitor\n",
    "    \n",
    "    @property\n",
    "    def job_id(self) -> ObjectID:\n",
    "        return self._job_id\n",
    "    \n",
    "    @property\n",
    "    def prio(self) -> int:\n",
    "        return self._prio\n",
    "    \n",
    "    @prio.setter\n",
    "    def prio(\n",
    "        self,\n",
    "        new_prio: int,\n",
    "    ) -> None:\n",
    "        \"\"\"setting of priority\n",
    "        prio can be initialized as None, \n",
    "        but every change has to be an integer value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_prio : int\n",
    "            new priority which should be set\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            if other types are provided\n",
    "        \"\"\"\n",
    "        if not isinstance(new_prio, int):\n",
    "            raise TypeError((f\"The type of {new_prio} must be >>int<<, but \"\n",
    "                             f\"it is {type(new_prio)}\"))\n",
    "        else:\n",
    "            self._prio = new_prio\n",
    "    \n",
    "    @property\n",
    "    def obj_entry_idx(self) -> int | None:\n",
    "        \"\"\"\n",
    "        returns the entry index which is set by each infrastructure object\n",
    "        \"\"\"\n",
    "        return self._obj_entry_idx\n",
    "    \n",
    "    @property\n",
    "    def current_resource(self) -> InfrastructureObject | None:\n",
    "        \"\"\"\n",
    "        returns the current resource on which the job lies\n",
    "        \"\"\"\n",
    "        return self._current_resource\n",
    "\n",
    "    @current_resource.setter\n",
    "    def current_resource(\n",
    "        self,\n",
    "        obj: InfrastructureObject\n",
    "    ) -> None:\n",
    "        \"\"\"setting the current resource object which must be of type InfrastructureObject\"\"\"\n",
    "        if not isinstance(obj, InfrastructureObject):\n",
    "            raise TypeError(f\"From {self}: Object >>{obj}<< muste be of type 'InfrastructureObject'\")\n",
    "        else:\n",
    "            self._current_resource = obj\n",
    "    \"\"\"\n",
    "    def get_next_operation(self) -> Operation | None:\n",
    "        \n",
    "        get next operation\n",
    "        \n",
    "        # last operation information\n",
    "        self._last_op = self._current_op\n",
    "        self._last_proc_time = self._current_proc_time\n",
    "        self._last_setup_time = self._current_setup_time\n",
    "        self._last_order_time = self._current_order_time\n",
    "        # current operation information\n",
    "        if self.open_operations:\n",
    "            op = self.open_operations.popleft()\n",
    "            self._current_proc_time = op.proc_time\n",
    "            self._current_setup_time = op.setup_time\n",
    "            self._current_order_time = op.order_time\n",
    "            # only reset job prio if there are OP-wise defined priorities\n",
    "            if self.op_wise_prio:\n",
    "                self.prio = op.prio # use setter function to catch possible errors\n",
    "                \n",
    "            if self.op_wise_starting_date:\n",
    "                self.time_planned_starting = op.time_planned_starting\n",
    "            if self.op_wise_ending_date:\n",
    "                self.time_planned_ending = op.time_planned_ending\n",
    "        else:\n",
    "            op = None\n",
    "            self._current_proc_time = None\n",
    "            self._current_setup_time = None\n",
    "            self._current_order_time = None\n",
    "        \n",
    "        self._current_op = op\n",
    "        \n",
    "        return op\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def has_job_id(\n",
    "        self,\n",
    "        job_id: ObjectID,\n",
    "    ) -> bool:\n",
    "        \n",
    "        checks whether the current job has the given id\n",
    "        \n",
    "        if self._job_id == job_id:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        assoc_system: System,\n",
    "        agent_type: str,\n",
    "    ) -> None:\n",
    "        # basic information\n",
    "        self._agent_type = agent_type.upper()\n",
    "        \n",
    "        # associated system\n",
    "        self._assoc_system, self._env = assoc_system.register_agent(\n",
    "                                    agent=self,\n",
    "                                    agent_type=self._agent_type)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def assoc_system(self) -> System:\n",
    "        return self._assoc_system\n",
    "    \n",
    "    @property\n",
    "    def agent_type(self) -> str:\n",
    "        return self._agent_type\n",
    "    \n",
    "    @property\n",
    "    def env(self) -> SimulationEnvironment:\n",
    "        return self._env\n",
    "    \n",
    "    def build_feat_vec(self):\n",
    "        \"\"\"\n",
    "        building feature vector for prediction\n",
    "        has to be implemented in child classes\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(f\"No feature vector building method for {self} of type {self.__class__.__name__} defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Allocation Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllocationAgent(Agent):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # init base class\n",
    "        super().__init__(agent_type='ALLOC', **kwargs)\n",
    "        \n",
    "        # get associated systems\n",
    "        self._assoc_infstrct_objs = \\\n",
    "            self._assoc_system.lowest_level_subsystems(only_processing_stations=True)\n",
    "            \n",
    "        # RL related properties\n",
    "        self.feat_vec: npt.NDArray[np.float32] | None = None\n",
    "        \n",
    "        # execution control\n",
    "        # flag to indicate that action was obtained from RL backend\n",
    "        # indicator for internal loop\n",
    "        self._RL_decision_done: bool = False\n",
    "        # indicator for external loop in Gym Env\n",
    "        self._RL_decision_request: bool = False\n",
    "        # action chosen by RL agent\n",
    "        self._action: 'Action' | None = None\n",
    "        \n",
    "        \"\"\"\n",
    "        # sync state\n",
    "        self._RL_decision_done_state: State = sim.State(f'sync_{self.name()}_done')\n",
    "        self._RL_decision_request_state: State = sim.State(f'sync_{self.name()}_request')\n",
    "        \"\"\"\n",
    "        \n",
    "    @property\n",
    "    def RL_decision_done(self) -> bool:\n",
    "        return self._RL_decision_done\n",
    "    \n",
    "    @property\n",
    "    def RL_decision_request(self) -> bool:\n",
    "        return self._RL_decision_request\n",
    "    \n",
    "    @property\n",
    "    def action(self) -> 'Action':\n",
    "        return self._action\n",
    "    \n",
    "    def update_assoc_infstrct_objs(self) -> None:\n",
    "        # get associated systems\n",
    "        self._assoc_infstrct_objs = \\\n",
    "            self._assoc_system.lowest_level_subsystems(only_processing_stations=True)\n",
    "            \n",
    "    def request_decision(\n",
    "        self,\n",
    "        disposable_job: Job,\n",
    "    ) -> None:\n",
    "        # for each request, decision not done yet\n",
    "        # indicator for internal loop\n",
    "        self._RL_decision_done = False\n",
    "        # set flag indicating an request was made\n",
    "        # indicator for external loop in Gym Env\n",
    "        self._RL_decision_request = True\n",
    "        \n",
    "        # build feature vector\n",
    "        self.feat_vec = self._build_feat_vec(disposable_job=disposable_job)\n",
    "        \n",
    "        logger_agents.debug((f\"[REQUEST Agent]: Set {self._RL_decision_done=}, \"\n",
    "                             f\"{self._RL_decision_request=}\"))\n",
    "    \n",
    "    def set_decision(\n",
    "        self,\n",
    "        action: 'Action',\n",
    "    ) -> None:\n",
    "        # get action from RL agent\n",
    "        self._action = action\n",
    "        # decision done\n",
    "        # indicator for internal loop\n",
    "        self._RL_decision_done = True\n",
    "        # reset request indicator\n",
    "        # indicator for external loop in Gym Env\n",
    "        self._RL_decision_request = False\n",
    "        \n",
    "        logger_agents.debug((f\"[DECISION SET Agent]: Set {self._action=}, \"\n",
    "                             f\"{self._RL_decision_done=}, {self._RL_decision_request=}\"))\n",
    "    \n",
    "    # REWORK\n",
    "    def _build_feat_vec(\n",
    "        self,\n",
    "        disposable_job: Job,\n",
    "    ) -> 'FeatureVector':\n",
    "        \n",
    "        # resources\n",
    "        # needed properties\n",
    "        # station group, availability, WIP_time\n",
    "        for i, res in enumerate(self._assoc_infstrct_objs):\n",
    "            # T1 build feature vector for one machine\n",
    "            monitor = res.stat_monitor\n",
    "            # station group identifier should be the system's one \n",
    "            # because custom IDs can be non-numeric which is bad for an agent\n",
    "            # use only first identifier although multiple values are possible\n",
    "            res_SGI: ObjectID = list(res.supersystems_ids)[0]\n",
    "            # availability: boolean to integer\n",
    "            avail = int(monitor.is_available)\n",
    "            # WIP_time in hours\n",
    "            WIP_time: float = monitor.WIP_load_time / Timedelta(hours=1)\n",
    "            \n",
    "            temp1: tuple[ObjectID, int, float] = (res_SGI, avail, WIP_time)\n",
    "            temp2 = np.array(temp1)\n",
    "            \n",
    "            if i == 0:\n",
    "                arr = temp2\n",
    "            else:\n",
    "                arr = np.concatenate((arr, temp2))\n",
    "        \n",
    "        # job\n",
    "        # needed properties\n",
    "        # order time, target station group ID\n",
    "        order_time: float = disposable_job.current_order_time / Timedelta(hours=1)\n",
    "        job_SGI = disposable_job.current_op.target_station_group_identifier\n",
    "        # SGI is type CustomID, but system ID (ObjectID) is needed\n",
    "        # lookup system ID by custom ID in Infrastructure Manager\n",
    "        infstruct_mgr = self.env.infstruct_mgr\n",
    "        system_id = infstruct_mgr.lookup_system_ID(\n",
    "            subsystem_type='StationGroup',\n",
    "            custom_ID=job_SGI,\n",
    "        )\n",
    "        temp1: tuple[float, ObjectID] = (order_time, system_id)\n",
    "        temp2 = np.array(temp1)\n",
    "        \n",
    "        # concat job information\n",
    "        arr = np.concatenate((arr, temp2))\n",
    "        \n",
    "        \n",
    "        #self.feat_vec = arr\n",
    "        \n",
    "        # REWORK: simulate agent decision making in Gym Env\n",
    "        #time.sleep(7)\n",
    "        #self._RL_decision_done = True\n",
    "        \n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequencing Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencingAgent(Agent):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__(agent_type='SEQ', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ag = SequencingAgent(assoc_system=group_prod2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link Collection**\n",
    "\n",
    "- [Environment](#environment)\n",
    "- [Machine](#machine)\n",
    "- [Dispatcher](#dispatcher)\n",
    "- [Operation](#operation)\n",
    "- [Job](#job)\n",
    "- [Logic Test](#logic_test)\n",
    "\n",
    "\n",
    "[Jump to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"MachineBreakdownTest\"></a>\n",
    "\n",
    "# Check interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = sim.Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMachine(sim.Component):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.proc_time = 8.\n",
    "        \n",
    "    def process(self):\n",
    "        yield self.passivate()\n",
    "        \n",
    "        print(f\"Processing time machine = {self.proc_time}; start processing at {self.env.now()}\")\n",
    "        \n",
    "        yield self.hold(self.proc_time)\n",
    "        \n",
    "        print(f\"Processing finished at {self.env.now()}\")\n",
    "        \n",
    "        \n",
    "class Interruptor(sim.Component):\n",
    "    \n",
    "    def __init__(self, machine, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.machine = machine\n",
    "        self.time_till_failure = 2.\n",
    "        self.breakdown_time = 3.\n",
    "        \n",
    "    def process(self):\n",
    "        machine = self.machine\n",
    "        machine.activate()\n",
    "        \n",
    "        yield self.hold(self.time_till_failure)\n",
    "        \n",
    "        print(f\"Interrupt machine at {self.env.now()} for time units {self.breakdown_time}\")\n",
    "        machine.interrupt()\n",
    "        \n",
    "        yield self.hold(self.breakdown_time)\n",
    "        \n",
    "        print(f\"Resume machine at {self.env.now()}\")\n",
    "        machine.resume()\n",
    "        \n",
    "        yield self.passivate()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = TestMachine(env=env)\n",
    "failure = Interruptor(machine=machine, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time machine = 8.0; start processing at 0.0\n",
      "Interrupt machine at 2.0 for time units 3.0\n",
      "Resume machine at 5.0\n",
      "Processing finished at 11.0\n"
     ]
    }
   ],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine.status.value_duration('interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine.status.value_duration('scheduled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
